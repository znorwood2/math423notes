<?xml version='1.0' encoding='utf-8'?>

<pretext xml:lang="en-US" xmlns:xi="http://www.w3.org/2001/XInclude">

  <docinfo>
    <macros>
      \newcommand{\R}{\mathbb R}
      \newcommand{\N}{\mathbb N}
      \renewcommand{\Re}{\operatorname{Re}}
      \renewcommand{\Im}{\operatorname{Im}}
      \newcommand{\C}{\mathbb{C}}
      \newcommand {\bH}{\mathbb{H}}
      \newcommand {\bF} {\mathbf{F}}
      \newcommand {\bG} {\mathbf{G}}
      \newcommand {\bN} {\mathbf{N}}
      \newcommand {\bT} {\mathbf{T}}
      \newcommand{\abs}[1]{\left| #1 \right|}
      \newcommand{\angs}[1]{\langle #1 \rangle}
      \newcommand\set[2]{\left\{ #1 : #2 \right\}}
      \renewcommand{\bar}{\overline}
      \newcommand{\Arg}{\operatorname{Arg}}
      \newcommand{\Log}{\operatorname{Log}}
      \newcommand{\Res}{\operatorname*{Res}}
      \newcommand{\wo}{\smallsetminus}
      \newcommand{\angleop}{\operatorname{angle}}
      \newcommand {\grad} {\nabla}
      \newcommand {\eps} {\epsilon}
    </macros>
    <latex-image-preamble>
      \usepackage{tikz}
      \usetikzlibrary {calc}
      \usetikzlibrary {decorations.markings}
    </latex-image-preamble>
  </docinfo>

  <book xml:id="my-great-book">
    <title>Complex Analysis</title>
    <subtitle>Course notes for Math 423 at UNL</subtitle>

    <frontmatter xml:id="frontmatter">
      <titlepage>
        <author>
          <personname>Zach Norwood</personname>
          <department>Department of Mathematics</department>
          <institution>University of Nebraska-Lincoln</institution>
        </author>
        <date>
          <today />
        </date>
      </titlepage>

      <colophon>

        <website>
          <name>
            <c>example.org</c>
          </name>
          <address>https://example.org</address>
        </website>

        <copyright>
          <year>2020<ndash />2023</year>
          <holder>You</holder>
          <shortlicense> 
            This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit <url href="http://creativecommons.org/licenses/by-sa/4.0/" visual="creativecommons.org/licenses/by-sa/4.0"> CreativeCommons.org</url>
          </shortlicense>
        </copyright>
      </colophon>
    </frontmatter>

    <chapter xml:id="ch-intro">
      <title>Complex pre-calculus</title>

      <section xml:id="section-arithmetic">
        <title>Basic arithmetic and geometry</title>
        <definition xml:id="def-complex-number">
          <statement>
            <p>
              A <term>complex number</term> is just an ordered pair <m>(x,y)</m> of real numbers.
              But we write <m>x+iy</m> instead of <m>(x,y)</m>.
            </p>

            <p>
              We call <m>x</m> the <term>real part</term> of <m>z</m> and denote it by <m>x = \Re(z)</m>.
              We call <m>y</m> the <term>imaginary part</term> of <m>z</m> and denote it by <m>\Im(z)</m>.
            </p>
            <aside>
              <p>
                Notice that <m>\Re(z)</m> and <m>\Im(z)</m> are real numbers! 
              </p>
            </aside>

            <p>
              We write <m>\C</m> for the set of complex numbers.
            </p>
            <aside>
              <p>
             So yes, <m>\C</m>  is just <m>\R\times\R</m>.
             But we <em>think</em> of complex numbers as being <em>more than</em> just points in the plane,
             and it is useful to have notation to reflect this different mode of thinking.
              </p>
            </aside>
          </statement>
        </definition>
        <observation>
          <title>Innocuous but important fact</title>
          <p>
            Two complex numbers <m>z</m> and <m>w</m> are equal if and only if they have the 
            same real and imaginary parts! In other words...
          <me>
            z = w \quad\text{ iff }\quad \Re(z) = \Re(w) \text{ and } \Im(z) = \Im(w).
          </me>
        </p>
        </observation>
       <!-- https://www.geogebra.org/calculator/rx5rfurz-->
       <figure>
        <caption>GeoGebra: the real and imaginary parts of a complex number</caption>
        <interactive xml:id="geogebra-Re-Im" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="Re-Im" surface="geogebra" material="rx5rfurz" aspect="1:1">
              setCoordSystem(-4,4,-4,4);
          <!--    centerView((0,0)); -->
              <!--enableShiftDragZoom(false);-->
            </slate>
            <instructions>
                <p>Drag the point <m>z</m> around, and see how <m>\Re(z)</m> and <m>\Im(z)</m> change.</p>
            </instructions>
        </interactive>
      </figure> 
        <p>
          We add complex numbers by adding their real and imaginary parts independently:
        </p>
        <me>
          (a+ib) + (c+id) = (a+c) + i(b+d).
        </me>
        <p>
          Notice that this is the same as ordinary addition of points (thought of as vectors) in <m>\R^2</m>:
        </p>        
        <me>
          (a,b) + (c,d) = (a+c, b+d).
        </me>
<!--        https://www.geogebra.org/calculator/xpmdn6w4
-->     
<figure>
  <caption>GeoGebra: complex addition</caption>
  <interactive xml:id="geogebra-addition" platform="geogebra" width="80%" aspect="1:1">
      <slate xml:id="addition" surface="geogebra" material="xpmdn6w4" aspect="1:1">
        setCoordSystem(-2,5,-2,5);
    <!--    centerView((0,0)); -->
        <!--enableShiftDragZoom(false);-->
      </slate>
      <instructions>
          <p>Drag points <m>z</m> and <m>w</m>, and watch how <m>z+w</m> changes.</p>
      </instructions>
  </interactive>
</figure> 
        <p>
          Because complex numbers are simply points in the plane, added in the familiar way, we can import a lot of our knowledge
          of geometry and multi-variable calculus to our study of complex numbers.
        </p>
        <p>
          But something must be new! We multiply complex numbers using the following definition,
          motivated by treating <m>i</m> as an indeterminant and then simplifying using <m>i^2 = -1</m>.
        </p>
        <aside>
          <p>
            On your own, you should expand <m>(a+bx)(c+dx)</m> and then simplify by assuming <m>x^2 = -1</m>.
          </p>
        </aside>
        <me>
          (a + ib)(c + id) = (ac - bd) + i(ad + bc)
        </me>
        <p>
        This operation is totally new. Later we will do some work to understand better what is going on.
        You can go ahead and try to get a feel for things by dragging <m>z</m> and <m>w</m> around on this GeoGebra graph,
        though.
        </p>
        <figure>
          <caption>GeoGebra: complex multiplications</caption>
          <interactive xml:id="geogebra-SAS" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="SAS" surface="geogebra" material="nm9tw2mj" aspect="1:1">
                setCoordSystem(-5,5,-5,5);
            <!--    centerView((0,0)); -->
                enableShiftDragZoom(false);
              </slate>
              <instructions>
                  <p>Drag points <m>z</m> and <m>w</m>, and watch how <m>zw</m> changes.</p>
              </instructions>
          </interactive>
        </figure>
<!--        <interactive geogebra="nm9tw2mj"></interactive> -->
<!--        <iframe src="https://www.geogebra.org/calculator/b2us9kvy?embed" width="800" height="600" allowfullscreen style="border: 1px solid #e4e4e4;border-radius: 4px;" frameborder="0"></iframe> -->
        <p>
          We identify the real number <m>x</m> with the complex number <m>x+i0</m>, corresponding to the point <m>(x,0)</m> on the <m>x</m>-axis.
          It would be very upsetting if the new complex addition and multiplication we've defined were inconsistent with regular operations on real numbers; luckily this is not the case.
        </p>
        <observation>
          <p> Complex addition and multiplication restrict to ordinary addition and multiplication of real numbers: </p>
          <md>
            <mrow>(a+i0) + (c + i0) \amp = (a+c) + i0 </mrow>
            <mrow>(a+i0) \cdot (c+i0) \amp = (ac - 0) + i(0 + 0) </mrow>
          </md>
        </observation>
        <exercise>
          <p> Show directly from the definitions that complex addition and multiplication have the following properties. </p>
          <ol marker="(a)">
            <li><m>0+z = z</m> <p>(<m>0 = 0+0i</m> is an additive identity)</p></li>
            <li><m>1\cdot z = z</m> <p>(<m>1 = 1+0i</m> is a multiplicative identity)</p></li>
            <li> <m>z + w = w + z \text{ and } z\cdot w = w\cdot z</m> 
              <p> (additional and multiplication are commutative)</p></li>
            <li> <m>(z+w)+v = z+(w+v) \text{ and } (z w)v = z(wv)</m> <p>(addition and multiplication are associative)</p> </li>
            <li><m>z(w+v) = zw + zv</m> <p>(multiplication distributes over addition)</p></li>
          </ol>
        </exercise>
        <definition xml:id="def-modulus">
          <statement>
            <p>
              The <term>modulus</term> (aka complex absolute value) of a complex number <m>z = x+iy</m>
              is defined to be <m>\abs{z} = \sqrt{x^2 + y^2}</m>, its distance from the origin.
            </p>
            <p>
              The <term>conjugate</term> of a complex number <m>z = x+iy </m> is the complex number
              <m>\bar z = x - iy</m>.
              (In other words, the conjugate is defined by <m>\Re(\bar z) = \Re(z)</m> and <m>\Im(\bar z) = -\Im(z)</m>.)
            </p>
          </statement>
        </definition>
       <!-- <figure xml:id="fig-tikz-conjugate">
          <caption>A complex number and its conjugate</caption>
          <image width="15%" xml:id="conjugate">
        
        <latex-image >
          \begin {tikzpicture}
          \draw [-latex] (-1,0) to (4,0) node [above] {Re} ;
          \draw [-latex] (0,-3) to (0,4) node [right] {Im} ;
          \coordinate (z) at (3,2) ;
          \coordinate (zbar) at (3,-2) ;
          \fill (z) circle (2pt) ;
          \fill (zbar) circle (2pt) ;
          \node [above left] at (z) {$z$} ;
          \node [above left] at (zbar) {$\bar{z}$} ;
          \draw [dashed] (z) to (zbar) ;
         \end {tikzpicture}        
        </latex-image>
          </image>
        </figure>-->
        <figure>
          <caption>GeoGebra: conjugation</caption>
          <interactive xml:id="geogebra-conjugate" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="conjugate" surface="geogebra" material="adzdrq5d" aspect="1:1">
                setCoordSystem(-5,5,-5,5);
            <!--    centerView((0,0)); -->
                enableShiftDragZoom(false);
              </slate>
              <instructions>
                  <p>Drag the point <m>z</m>, and watch how <m>\bar z</m> changes. Contrast with <m>-z</m>.</p>
              </instructions>
          </interactive>
        </figure>
        <p>
          Since the modulus is just the usual distance from the origin, and addition of complex numbers
          is just vector addition, we inherit the triangle inequality from real analysis.
        </p>
        <lemma>
          <title>The Triangle Inequality</title>
          <p> <m>\abs{z + w} \le \abs{z} + \abs{w}</m> for all <m>z,w\in\C</m>.</p>
        </lemma>
        <p>Written in terms of <m>x</m> and <m>y</m>, the product of a complex number and its conjugate
        is a difference of squares: </p>
        <me>
          z\bar z = (x+iy)(x-iy) = x^2 - (iy)^2 = x^2 + y^2 = \abs{z}^2.
        </me>
        <p>Assuming that <m>z</m> is nonzero, we rearrange this equation to obtain a formula for <m>\frac{1}{z}</m>.</p>
        <lemma>
          <p>Every nonzero complex number has a multiplicative inverse given by either of the following equivalent formulas.</p>
          <md>
            <mrow>\frac{1}{z} \amp = \frac{\bar z}{\abs{z}^2}</mrow>
            <mrow>\frac{1}{x+iy} \amp = \frac{x - iy}{x^2 + y^2}</mrow>
          </md>
        </lemma>
        <!-- TODO: insert sage calculator for inverse -->
        <!--https://www.geogebra.org/calculator/x5dtff4z-->
        <figure>
          <caption>GeoGebra: reciprocal</caption>
          <interactive xml:id="geogebra-reciprocal" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="reciprocal" surface="geogebra" material="x5dtff4z" aspect="1:1">
                setCoordSystem(-3,3,-3,3);
            <!--    centerView((0,0)); -->
                enableShiftDragZoom(false);
              </slate>
              <instructions>
                  <p>Drag the point <m>z</m>, and watch how <m>\frac{1}{z}</m> changes. Contrast with <m>-z</m>.
                  For now, just observe that <m>\frac{1}{z}</m> gets close to <m>0</m> as <m>z</m> moves far away from <m>0</m>,
                and vice versa.</p>
              </instructions>
          </interactive>
        </figure>        
        <problem>
          <p>Prove that the following identities hold for all <m>z,w\in\C</m>.</p>
          <ol marker="(a)">
           <li> <m>\Re(z) = \displaystyle\frac{z+\bar z}{2}</m> </li>
           <li> <m>\Im(z) = \displaystyle\frac{z - \bar z}{2i}</m> </li>
           <li>
           <m>\bar{z+w} = \bar z + \bar w</m>  </li>
           <li>
           <m>\bar{zw} =  \bar z \cdot \bar w</m>  </li>
           <li>
           <m>\abs{z}^2 = z\cdot \bar z</m>  </li>
           <li>
           <m>\abs{zw} = \abs z \cdot \abs w</m>  </li>
           <li>
           <m>\abs{z+w}^2 = \abs{z}^2 + \abs{w}^2 + 2\Re(z\bar w)</m>  </li>
          </ol>
        </problem>
        <!-- TODO: add the rest of HW 1-->
        <p>It is clear from our definition that <m>\C</m> has something that <m>\R</m> does not:
        a square-root of <m>-1</m>!</p>
        <me>
          i^2 = (0+i\cdot 1)^2 = (0\cdot 0 - 1\cdot 1) + i(0 + 0) = -1.
        </me>
        <p>In fact, as we will show later, <m>\C</m> has roots of all non-constant polynomials.</p>
        <!-- TODO: add forward ref to FTA-->
        <theorem xml:id="theorem-fta">
          <title>Fundamental Theorem of Algebra</title>
          <p>Every polynomial <m>p(z)</m> with complex coefficients of degree <m>\ge 1</m>
          has a factorization</p>
          <me>
            p(z) = c(z-r_1)^{d_1}(z-r_2)^{d_2}\cdots (z-r_k)^{d_k}
          </me>
          <p>where the roots <m>r_j</m> are distinct, and <m>d_j\ge 1</m>.
          This factorization is unique up to permuting the factors.</p>
        </theorem>
        <p>This Theorem follows by induction on degree from...</p>
        <theorem>
          <p>Every nonconstant polynomial with complex coefficients has a complex root.</p>
        </theorem>
        <p>We will prove this later in the course! Even though it seems like (and is) a theorem of algebra,
          its proof really needs analytic tools. </p>
        <example><p>There is a complex solution to <m>z^7 + z^4 - i = \sqrt2</m>.</p></example>
      </section>
      <section xml:id="section-polar">
        <title>Polar representation and Euler's Formula</title>
        <p>As a point in the plane, a complex number has a polar representation: </p>
        <me> z = x+iy = r(\cos\theta + i\sin\theta) </me>
        <aside>
          <p> In precalculus you would've written <m>(x,y) = (r\cos\theta,r\sin\theta)</m>.
            This is the same thing, just written using 
           <m>x+iy</m> instead of <m>(x,y)</m>. </p>
        </aside>
        <!--https://www.geogebra.org/calculator/zzyx6g7r-->
        <figure>
          <caption>GeoGebra: polar representation</caption>
          <interactive xml:id="geogebra-polar-basic" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="polar-basic" surface="geogebra" material="zzyx6g7r" aspect="1:1">
                setCoordSystem(-2,4,-2,4);
            <!--    centerView((0,0)); -->
                enableShiftDragZoom(false);
              </slate>
              <instructions>
                  <p>Drag the point <m>z</m> and note the change in <m>r = \abs{z}</m> and <m>\theta = \arg{z}</m>.
                  <em>Warning:</em> This applet is showing the argument between <m>0</m> and <m>2\pi</m>, not the principal argument.</p>
              </instructions>
          </interactive>
        </figure>        
        <p>
          Notice that <m>r</m> is simply the modulus of <m>z</m>: <m>r = \abs{z}</m>.
          The angle <m>\theta</m> between the positive real axis and the ray <m>\overrightarrow{0z}</m>
          is called the <em>argument</em> of <m>z</m> and is denoted <m>\arg(z)</m>.
          Notice that <m>\arg(z)</m> is a multivalued function! Adding <m>2\pi</m> to <m>\theta</m> does
          not change <m>z</m>.
        </p>
        <definition xml:id="def-principal-arg">
          <statement>
            <p>The <term>principal argument</term> of a complex number <m>z</m>, denoted
            <m>\Arg(z)</m>, is the value of <m>\theta</m> that satisfies <m>-\pi \lt \theta \le \pi</m>.</p>
            </statement>
            <aside>
              <p>
                <em>Warning:</em> Some authors use the convention that <m>\Arg(z) \in [0,2\pi)</m>.
                Use caution when consulting other sources!
              </p>
            </aside>
        </definition>
        <p>So, for <m>z\in\C\wo\{0\}</m>, the possible values of <m>\arg(z)</m> are <m>\Arg(z) + 2\pi k</m>,
          where <m>k</m> can be any integer.</p>
        <example>
          <p>
          <m>\Arg(i) = \frac{\pi}{2}</m>, <m>\Arg(1-i) = -\frac{\pi}{4}</m>.
          </p>
        </example>
        <identity>
          <title>Euler's Formula</title>
          <p>For now we take the following as a <em>definition</em>; later we will see why it is justified.</p>
          <me>e^{i\theta} = \cos\theta + i\sin\theta \quad (\theta\in\R)</me>
        </identity>
        <!-- TODO: insert geogebra thing with slider for theta-->
        <p>Using Euler's Formula, we obtain the <em>exponential form</em> of the polar representation
          of <m>z</m>: </p> <me>z = re^{i\theta} = \abs{z}e^{i\arg(z)}</me>
        <example>
          <ul>
            <li><m>e^{i\pi} = \cos\pi + i\sin\pi = -1 + 0i = -1</m> </li>
            <li><m> e^{i\pi/2} = \cos(\pi/2) + i\sin(\pi/2) = 0 + i = i</m> </li>
            <li><m>e^{i\pi/4} = \frac{1}{\sqrt2} + i\frac{1}{\sqrt2} </m> </li>
          </ul>
        </example>
        <exercise>
          <p> Use trig identities to prove the following identities about <m>e^{i\theta}</m></p>
          <ol marker="(a)">
            <li><m>\abs{e^{i\theta}} = 1</m> </li>
            <li><m>\bar{e^{i\theta}} = e^{-i\theta}</m> </li>
            <li><m>\frac{1}{e^{i\theta}} = e^{-i\theta}</m> </li>
          </ol>
        </exercise>
        <observation>
          <p>Let's try applying Euler's Formula to <m>e^{i(\alpha+\beta)}</m> and then separately to <m>e^{i\alpha}e^{i\beta}</m>.</p>
          <me> e^{i(\alpha+\beta)} = \cos(\alpha + \beta) + i\sin(\alpha+\beta) </me>
          <me> e^{i\alpha}e^{i\beta} = (\cos(\alpha) + i\sin(\alpha))(\cos(\beta) + i\sin(\beta))
            = (\cos\alpha\cos\beta - \sin\alpha\sin\beta) + i(\cos\alpha\sin\beta + \cos\beta\sin\alpha) </me>
          <p> The results of these two activities ought to be the same, and indeed if we identify real and imaginary
            parts we obtain the familiar addition formulas for sine and cosine! </p>
          <md>
            <mrow>\cos(\alpha+\beta) \amp = \cos\alpha\cos\beta - \sin\alpha\sin\beta </mrow>
            <mrow>\sin(\alpha+\beta) \amp = \cos\alpha\sin\beta + \cos\beta\sin\alpha </mrow>
          </md>
          <aside>
           <p>
            This is a useful way to derive the addition formulas for sine and cosine without memorizing them.
            But the way we've presented things is a bit backward; in fact, it's the trig identities
            that allow us to conclude that <m>e^{i(\alpha+\beta)} = e^{i\alpha}e^{i\beta}</m>.
           </p>
          </aside>
        </observation>
        <exercise>
          <p> Use trig identities to prove the following faacts about the argument. </p>
          <ol marker="(a)">
           <li><m>\arg \bar z = -\arg z</m></li>
           <li><m>\arg (\frac{1}{z}) = -\arg z</m></li>
           <li><m>\arg(zw) = \arg(z) + \arg(w)</m></li>
          </ol>
        </exercise>
        <p>
         With the help of the polar representation, we are in a position to understand exactly
         how complex multiplication works. Writing <m>z = re^{i\theta}</m> and <m>w = se^{i\phi}</m>,
         we have
        </p>
        <me>
          zw = re^{i\theta}se^{i\phi} = rse^{i(\theta+\phi)}.
        </me>
        <p>So the product <m>zw</m> has modulus <m>\abs{z}\abs{w}</m> and argument <m>\arg z + \arg w</m>.</p>
        <!--https://www.geogebra.org/calculator/ss3raptn-->
        <figure>
          <caption>GeoGebra: multiplication in polar coordinates</caption>
          <interactive xml:id="geogebra-mult-polar" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="mult-polar" surface="geogebra" material="ss3raptn" aspect="1:1">
                setCoordSystem(-4,4,-4,4);
            <!--    centerView((0,0)); -->
                enableShiftDragZoom(false);
              </slate>
              <instructions>
                  <p>Drag the points <m>z</m> and <m>w</m> and note how <m>zw</m> changes.
                  <em>Warning:</em> This applet is showing the argument between <m>0</m> and <m>2\pi</m>, not the principal argument.</p>
              </instructions>
          </interactive>
        </figure>  
        <subsection xml:id="subsec-de-moivre">
          <title>De Moivre's Theorem</title>
          <p>We can identify real and imaginary parts in the following equation to obtain some trig identities.</p>
          <me>
            \cos(n\theta) + i\sin(n\theta) = e^{in\theta} = (e^{i\theta})^n = (\cos\theta + i\sin\theta)^n.
          </me>
          <p>
            Let's illustrate this by considering the example <m>n = 3</m>. Identifying real and imaginary parts of the equation
          </p>
          <me>
            (\cos\theta + i\sin\theta)^3 = \cos^3 \theta - 3\cos\theta\sin\theta + i(3\cos^2\theta\sin\theta - \sin^3\theta)
          </me>
          <p> gives </p>
          <md>
            <mrow> \cos(3\theta) \amp \cos^3\theta - 3\cos\theta\sin^2\theta </mrow>
            <mrow> \sin(3\theta) \amp 3\cos^2\theta\sin\theta - \sin^3\theta </mrow>
          </md>
        </subsection>
        <subsection>
          <title>Roots of unity</title>
          <p>
            It is a special case of the Fundamental Theorem of Algebra (<xref ref="theorem-fta"/>) that
            every nonzero complex number <m>w</m> has exactly <m>n</m> <m>n</m><sup>th</sup> roots,
            i.e., solutions <m>z</m> to <m>z^n = w</m>.
            The case <m>w = 1</m> is already interesting (and of particular importance), so let's start there. 
          </p>

          <p> 
            Finding the <m>n</m> solutions to <m>z^n = 1</m> is made easier by considering the various polar representations of <m>1</m>:
          </p>
          <md>
            <mrow> 1 \amp = \cdots = e^{-4\pi i} = e^{-2\pi i} = e^{0 i} = e^{2\pi i} = e^{4\pi i} = \cdots </mrow>
            <mrow>   \amp = e^{2\pi i k}, \quad k\in\mathbb{Z}</mrow>
          </md>
          <p>
            A reasonable guess (which turns out to be correct!) is that we can just
            divide the exponent on the righthand side by <m>n</m> to obtain the possible values of <m>1^{1/n}</m>.
          </p>
          <definition xml:id="def-roots-of-unity">
            <statement>
              <p>
                For an integer <m>n \ge 1</m>, the <term><m>n</m><sup>th</sup> roots of unity</term> 
                are the complex numbers <m>\omega_0,\dots, \omega_{n-1}</m>, where
              </p>
              <men xml:id="eqn-roots">
                \omega_k = e^{2\pi i k / n}.
              </men>
            </statement>
          </definition>
          <exercise>
            <p>
              Prove that the <m>n</m> numbers <m>\omega_0,\dots,\omega_{n-1}</m> listed in <xref ref="eqn-roots"/>
              are in fact <m>n</m> different numbers!
            </p>
            <p>
              Explain why they appear equally spaced around the unit circle <m>\abs{z} = 1</m>.
            </p>
          </exercise>
          <example>
            <p> The <m>4</m>th roots of unity are: </p>
            <md>
              <mrow> \omega_0 \amp e^{2\pi i 0 / 4} = 1</mrow>
              <mrow> \omega_1 \amp e^{2\pi i 1 / 4} = e^{\pi i / 2} = i</mrow>
              <mrow> \omega_2 \amp e^{2\pi i 2 / 4} = e^{\pi i} = -1</mrow>
              <mrow> \omega_3 \amp e^{2\pi i 3 / 4} = e^{(3\pi / 2) i} = -i</mrow>
            </md>
            <aside>
              <p>
                Don't forget Euler's Formula! E.g. 
                <md>
                  <mrow> e^{(3\pi/2)i} \amp = \cos(3\pi/2) + i \sin(3\pi/2) </mrow>
                  <mrow> \amp = 0 + i(-1) </mrow>
                  <mrow> \amp = -i </mrow>
                </md>.
              </p>
            </aside>
          </example>
<!-- TODO: Tikz picture of like 8th roots of unity or something-->
          <p>
            We can find the <m>n</m>th roots of any nonzero complex number <m>w = re^{i\theta}</m> in a similar way. 
            Suppose that <m>\theta</m> is, say, the principal argument of <m>w</m>, and consider the next <m>n-1</m> many
            arguments:
          </p>
          <me>
            w = re^{i\theta} = re^{i(\theta+2\pi)} = re^{i(\theta+4\pi)} = \cdots = re^{i(\theta+2(n-1)\pi)}.
          </me>
          <p>
            Now simply take each of these <m>n</m> different representations for <m>w</m> to the <m>1/n</m>th power
            to obtain the following list of <m>n</m>-many <m>n</m>th roots of <m>w</m>.
          </p>
          <me>
           r^{1/n}e^{i\theta/n}, r^{1/n}e^{i\theta/n + 2\pi i /n}, r^{1/n}e^{i\theta/n + 4\pi i / n}, \dots, r^{1/n}e^{i\theta/n + 2(n-1)\pi i / n}
          </me>
          <p>
            Oh, we could instead have obtained this list by finding the first <m>n</m>th root of <m>w</m>
            and multiplying by all the <m>n</m>th roots of unity!
            The <m>n</m>th roots of <m>w = re^{i\theta / n}</m> are...
          </p>
          <me>
            r^{1/n}e^{i\theta / n}, \omega_1r^{1/n}e^{i\theta / n}, \dots, \omega_{n-1}r^{1/n}e^{i\theta / n},
          </me>
          <p>
            where <m>\omega_0,\dots,\omega_{n-1}</m> are the <m>n</m>th roots of unity.
          </p>
          <!--https://www.geogebra.org/calculator/jzxwdqgr-->
          <figure>
            <caption>GeoGebra: nth roots</caption>
            <interactive xml:id="geogebra-nth-roots" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="nth-roots" surface="geogebra" material="jzxwdqgr" aspect="1:1">
                  setCoordSystem(-4,4,-4,4);
              <!--    centerView((0,0)); -->
                  enableShiftDragZoom(false);
                </slate>
                <instructions>
                    <p>Draw the point <m>w</m> around and watch its <m>6</m>th roots move.</p>
                </instructions>
            </interactive>
          </figure>  
          <example>
            <p>
              Let <m>a\in\R</m> be an unspecified real number. We are going to find the two square roots
              of the complex number <m>a+i</m> in cartesian form (<m>x+iy</m>).
            </p>
            <!--https://www.geogebra.org/calculator/dyexbgez-->
            <figure>
              <caption>GeoGebra: roots example</caption>
              <interactive xml:id="geogebra-roots-example" platform="geogebra" width="80%" aspect="1:1">
                  <slate xml:id="roots-example" surface="geogebra" material="dyexbgez" aspect="1:1">
                    setCoordSystem(-4,4,-4,4);
                <!--    centerView((0,0)); -->
                    enableShiftDragZoom(false);
                  </slate>
              </interactive>
            </figure>
            <p>Let's start by defining <m>r</m> and <m>\theta</m>.</p>
            <md>
              <mrow> r \amp = \abs{a+i} = \sqrt{a^2 + 1} </mrow>
              <mrow> \theta \amp = \Arg(a+i) </mrow>
            </md>
            <p>So, in polar form, <m>a+i</m> can be written as <m>re^{i(\theta + 2k\pi)}</m> for any <m>k\in\mathbb{Z}</m>.
              So we should be able to take <m>z_0 = (re^{i\theta})^{1/2} = r^{1/2}e^{i\theta/2}</m>
          and <m>z_1 = -z_0</m> as our two square-roots. But we still want them in rectangular coordinates, so
          we use Euler's Formula, some trig identities, and the fact that <m>\cos\theta = a/r</m>.</p>
          <md>
            <mrow>z_0 = \sqrt{r} e^{i\theta/2} \amp = \sqrt{r}(\cos(\theta/2) + i\sin(\theta/2)) </mrow>
            <mrow> \amp = \sqrt{r}\left(\sqrt{\frac{1+\cos\theta}{2}} + i \sqrt{\frac{1-\sin\theta}{2}}\right) </mrow>
            <mrow> \amp = \sqrt{r}\left(\sqrt{\frac12 (1+\frac{a}{r})} + i\sqrt{\frac{1}{2} (1 - \frac{a}{r})}\right)</mrow>
            <mrow> \amp = \frac{1}{\sqrt2}(\sqrt{r+a} + i\sqrt{r-a}) </mrow>
            <mrow> \amp = \frac{1}{\sqrt2}(\sqrt{\sqrt{a^2+1}+a} + i\sqrt{\sqrt{a^2+1}-a}) </mrow>
          </md>
          <p>The other square-root is <m>-z_0</m>.</p>
          </example>
        </subsection>
      </section>

      <section>
      <title>The Stereographic Projection</title>
        <p> For now, see the typed PDF posted to Canvas. Here are some visual tools: </p>
      <!--https://www.geogebra.org/calculator/svqnw7br-->
      <figure>
        <caption>GeoGebra: stereographic projection</caption>
        <interactive xml:id="geogebra-stereo-basic" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="stereo-basic" surface="geogebra" material="svqnw7br" aspect="1:1">
              <!--setCoordSystem(-4,4,-4,4);-->
          <!--    centerView((0,0)); -->
              enableShiftDragZoom(false);
            </slate>
        </interactive>
      </figure>
      <!--https://www.geogebra.org/calculator/uunuspte-->
      <figure>
        <caption>GeoGebra: stereographic projection in cross-section</caption>
        <interactive xml:id="geogebra-stereo-2d" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="stereo-2d" surface="geogebra" material="uunuspte" aspect="1:1">
              setCoordSystem(-4,4,-4,4);
          <!--    centerView((0,0)); -->
              enableShiftDragZoom(false);
            </slate>
          <instructions>
            <p> You can drag either <m>\bar Q</m> around the circle or <m>P</m> along the line. </p>
          </instructions>
        </interactive>
      </figure>
      </section>

      <section>
        <title> Some elementary functions </title>
        <p>
          The rest of the course will be devoted to studying functions of a complex variable,
          that is, functions <m>f\colon D\to\C</m> where <m>D \subseteq \C</m>.
          Because <m>\C</m> is inherently 2-dimensional, we cannot reasonably hope to graph 
          a complex-valued function in the way that we did for functions <m>\R\to\R</m> in calculus.
          Instead, we think of complex-valued functions geometrically as <em>transformations</em> of the plane.
          In trying to understand a particular function,
          we will pay special attention to how familiar geometric shapes like lines and circles
          are transformed.
        </p>
        <subsection xml:id="subsec-mult-add">
          <title>Multiplication and addition by a fixed number</title>
          <p>
            The most basic complex-valued functions simply take a <m>z\in\C</m>
            and add to it, or multiply it by, a fixed complex number <m>z_0</m>.
          </p>
          <!--https://www.geogebra.org/calculator/bp7edpuw-->
          <figure>
            <caption>GeoGebra: translation</caption>
            <interactive xml:id="geogebra-translation" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="translation" surface="geogebra" material="bp7edpuw" aspect="1:1">
                  setCoordSystem(-8,8,-8,8);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> Depicts the transformation <m>z\mapsto z + z_0</m>. You can change <m>z_0</m>. </p>
              </instructions>
            </interactive>
          </figure>
          <p>
            Addition by a fixed complex number <m>z_0</m> is just vector-translation.
            Remember that addition of complex numbers is just vector addition from multivariable calculus.
          </p>
          <!--https://www.geogebra.org/calculator/s7myaay7-->
          <figure>
            <caption>GeoGebra: multiplication by a fixed number</caption>
            <interactive xml:id="geogebra-mult-fixed" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="mult-fixed" surface="geogebra" material="s7myaay7" aspect="1:1">
                  setCoordSystem(-10,6,-8,8);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> Depicts the transformation <m>z\mapsto zz_0</m>. You can change <m>z_0</m>. </p>
              </instructions>
            </interactive>
          </figure>
          <p>
            Multiplication by a fixed complex number <m>z_0 = re^{i\theta}</m>
            is best thought of in polar coordinates, as the composite of two transformations.
            Notice that <m>z\mapsto rz</m>, for <m>r\in\R</m>, just scales every point in the plane by a factor
            of <m>r</m>. And the map <m>z\mapsto e^{i\theta}z</m>, for a fixed <m>\theta\in\R</m>,
            rotates the plane counterclockwise by <m>\theta</m> radians.
            So the map <m>z\mapsto re^{i\theta}z</m> is the composite of these two maps:
            it scales by a factor of <m>r</m> and rotates by <m>\theta</m> radians.
          </p>
          <!-- TODO: figure out how to knowl (=hide) this "exploration"-->
          <exploration>
            <p>  
            If you have seen some linear algebra, it is worth noting that scaling and rotating
            are linear maps! And you can analyze them using the tools of linear algebra.
            To do this, we first observe that the standard basis vectors <m>\begin {bmatrix} <![CDATA[1 \\ 0]]> \end {bmatrix}</m>
            and <m>\begin {bmatrix} <![CDATA[0 \\ 1]]> \end {bmatrix}</m>
            have (respectively) representations <m>1 = 1+0i</m> and <m>i = 0+1i</m> as complex numbers.
            Since the maps <m>z\mapsto rz</m> and <m>z\mapsto e^{i\theta}z</m>
            are both linear, their standard matrix representations can be found by looking at where they
            send the standard basis vectors.
            </p>
<!--            \begin{bmatrix}
<![CDATA[1 & 4 & 2 & 3 & 4\\]]>
<![CDATA[-3 & 2 & 0 & 1 & -2\\]]>
<![CDATA[1 & 6 & -3 & -1 & 5]]>
\end{bmatrix}
            <m>\begin {bmatrix} 1 \\ 0\end {bmatrix}</m>
            and <m>\begin {bmatrix} 0 \\ 1 \end {bmatrix}</m>-->
            <p>
              The more interesting of the two maps is the rotation map <m>z\mapsto e^{i\theta}z</m>,
              so let's see where it sends the standard basis vectors:
            </p>
            <md>
              <mrow> 1\cdot e^{i\theta} \amp = e^{i\theta} = \cos\theta + i\sin\theta </mrow>
              <mrow> i\cdot e^{i\theta} \amp = e^{i\pi/2}e^{i\theta} = \cos(\theta+\tfrac{\pi}{2}) + i\sin(\theta+\tfrac{\pi}{2}) 
                  = -\sin(\theta) + i\cos(\theta) </mrow>
            </md>
            <p>
              These two results give us the columns of the standard matrix of the linear transformation 
              <m> 1\cdot e^{i\theta} = e^{i\theta} = \cos\theta + i\sin\theta </m>:
            </p>
            <me>
              \begin{bmatrix}
              <![CDATA[\cos\theta & -\sin\theta\\]]>
              <![CDATA[\sin\theta & \cos\theta]]>
              \end{bmatrix}
            </me>
            <p>
              You might recognize this from linear algebra as a rotation matrix.
            </p>
          </exploration>
        </subsection>
        <subsection xml:id="subsec-square-function">
          <title>The Square Function</title>
          <p>
            One of the simplest nontrivial functions is the squaring function <m>f(z) = z^2</m>.
            As we will see in many of these examples, it is useful to consider the map in polar coordinates.
          </p>
          <me>
            f(z) = z^2 = (re^{i\theta})^2 = r^2 e^{i\cdot 2\theta}.
          </me>
          <p>
            In other words, the function <m>f</m> is defined by declaring <m>\abs{f(z)} = \abs{z}^2</m>
            and <m>\arg f(z) = 2\arg z</m>.
          </p>
          <p>
            The circle <m>\abs{z} = r_0</m> is mapped to the circle <m>\abs{z} = r_0^2</m>,
            traversed at double the angular velocity.
            In particular, the unit circle <m>\abs{z} = 1</m> is mapped to itself, but traversed twice.
          </p>
          <!--https://www.geogebra.org/calculator/rtq3fjvt-->
          <figure>
            <caption>GeoGebra: Squaring 1</caption>
            <interactive xml:id="geogebra-square-1" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="square-1" surface="geogebra" material="rtq3fjvt" aspect="1:1">
                  setCoordSystem(-20,20,-20,20);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> Depicts the transformation <m>z\mapsto z^2</m> and its effect on rays emanating from
                the origin and circles centered at the origin. </p>
              </instructions>
            </interactive>
          </figure>
          <!--https://www.geogebra.org/classic/zxscu7gg-->
          <figure>
            <caption>GeoGebra: Squaring 2</caption>
            <interactive xml:id="geogebra-square-2" platform="geogebra" width="200%" aspect="1363:811">
              <slate xml:id="square-2" surface="geogebra" material="zxscu7gg" aspect="1363:811">
                <!--width="1363px" height="811px"-->
                <!--setWidth(1440)  -->
                <!--setCoordSystem(-20,20,-20,20);-->
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
              </slate>
              <instructions>
                <p> <em>Warning:</em> This graphic differs a bit from the previous ones.
                At any moment in time, the graphic is showing you <m>z</m> on the left and <m>z^2</m> 
              on the right. Notice also that the scales of the two graphs are different.
             View <url href="https://www.geogebra.org/classic/zxscu7gg">on a separate page</url>. 
            </p>
              </instructions>
            </interactive>
          </figure>
          <!-- TODO: add thing about image of vertical line-->
        </subsection>
        <subsection xml:id="subsec-square-root">
          <title>The Square Root Function </title>
          <p>
            Every nonzero complex number should have two square-roots. The problem is that we
            want to choose one in a reasonable way. (We cannot simply choose the 'positive' one as we can
            with real numbers.)
            Looking in polar coordinates suggests that we should define
          </p>
          <me>
            \sqrt{z} = \sqrt{re^{i\theta}} = \sqrt{r} e^{i\theta/2}.
          </me>
          <p>
            (Notice that the square-root on the right is the ordinary positive square-root
            of the nonnegative real number <m>r</m>.)
          </p>
          <p>
            But a complex number <m>z</m> has many arguments <m>\theta</m>!
            The trouble comes from picking a particular <m>\theta</m>.
          </p>
          <!--https://www.geogebra.org/calculator/rnwzc4hk-->
          <figure xml:id="fig-geogebra-square-roots">
            <caption>GeoGebra: Square roots</caption>
            <interactive xml:id="geogebra-square-roots" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="square-roots" surface="geogebra" material="rnwzc4hk" aspect="1:1">
                  setCoordSystem(-10,10,-10,10);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> 
                 Drag <m>z</m> around and see how its two square-roots change. Notice that when 
                 <m>z</m> crosses the negative real axis, the two square-roots are flipped!
                 You can view a larger version of this <url href="https://www.geogebra.org/calculator/rnwzc4hk">here</url>.
                </p>
              </instructions>
            </interactive>
          </figure>
          <p>
            As you can see in <xref ref="fig-geogebra-square-roots"/>, using the principal argument
            for <m>\theta</m> introduces a discontinuity at every point along the negative real axis.
            To fix this, we take a <term>branch cut</term>.
          </p>
          <definition xml:id="def-principal-square-root">
            <statement>
              <p>
                The <term>principal branch</term> of the square-root function
                is the function <m>\C \wo (-\infty,0] \to \C</m> defined by
                <m>\sqrt{z} = \sqrt{\abs{z}} e^{i\Arg{z}/2}</m>.
              </p>
            </statement>
          </definition>
          <p>
            <em>Warning:</em> Negative real numbers still have complex square roots!!! They are excluded from
            the domain of the principal branch of the square-root function
            only to ensure that the function is continuous. More about this later.
          </p>
          <p>
            (In fact, the formula in <xref ref="def-principal-square-root"/> can be used to get a 
            square-root of a negative real number. Plugging in <m>z = -1 = 1\cdot e^{i\pi}</m>,
            we obtain <m>e^{i\pi / 2} = i</m> as a square-root of <m>-1</m>.)
          </p>

          <p>
            So the two square-roots of a complex number <m>z = re^{i\Arg(z)}</m>
            are <m>\sqrt r e^{i\Arg(z)/2}</m> and <m>-\sqrt r e^{i\Arg(z)/2}</m>.
            (The first of these is the principal branch of the square-root, as long as
            <m>z\notin (-\infty,0]</m>.)
          </p>
          <example>
            <me>
              \sqrt{i} = \sqrt{e^{i\pi/2}} = e^{i\pi/4} = \frac{1}{\sqrt2} + \frac{1}{\sqrt2}i.
            </me>
          </example>
          <!-- TODO: add a lot-->
        </subsection>
        <subsection xml:id="subsec-exponential">
          <title>The Complex Exponential</title>
          <p>
            Euler's Formula tells us how to exponentiate so-called <term>purely imaginary</term>
            numbers, that is numbers of the form <m>i y</m> where <m>y\in\R</m>.
            But what about other complex numbers? Well, just decompose <m>z</m> as <m>x+iy</m>,
            the sum of a real number <m>x</m> (which we know how to exponentiate) and a purely imaginary number <m>iy</m>:
          </p>
          <me>
            e^z = e^{x+iy} = e^x e^{iy} = e^x\cos(y) + ie^x \sin(y).
          </me>
          <p>
            In other words, <m>e^{x}e^{iy}</m> is the polar representation of <m>e^z</m>:
            <m>\abs{e^z} = e^x = e^{\Re z}</m> and <m>\arg(e^z) = y = \Im(z)</m>.
          </p>
          <observation>
            <!-- TODO insert observations-->
          </observation>
          <definition xml:id="def-period">
            <statement>
              <p>
                A complex number <m>\lambda</m> is a <term>period</term> of the function 
                <m>f\colon\C\to\C</m> if, for every <m>z\in\C</m>, we have <m>f(z) = f(z+\lambda)</m>.
                A function <m>f</m> is <term>periodic</term> if it has some nonzero period.
              </p>
            </statement>
          </definition>
          <proposition xml:id="prop-exp-periodic">
            <statement>
              <p>
                The complex exponential <m>z\mapsto e^z</m> is <m>2\pi i</m>-periodic.
              </p>
            </statement>
          </proposition>
          <proof>
            <p>
              For all <m>z = x+iy \in \C</m> we have:
            </p>
             <md>
               <mrow> e^{z+2\pi i} \amp = e^{x + i(y+2\pi)} </mrow>
               <mrow>              \amp = e^x (\cos(y+2\pi) + i\sin(y+2\pi)) </mrow>
               <mrow>  \amp = e^x (cos(y) + i\sin(y)) </mrow>
               <mrow> \amp = e^{x+iy} = e^z </mrow>
            </md>
          </proof>
          <example>
            <p>
              For every real number <m>r</m>, the quantity <m>e^{r+2\pi i} = e^r</m> is a real number.
            </p>
          </example>
          <!-- TODO: insert images of horizontal and vertical lines-->
          <!--https://www.geogebra.org/calculator/fnnem4tf-->
          <figure xml:id="fig-geogebra-exp">
            <caption>GeoGebra: The exponential map</caption>
            <interactive xml:id="geogebra-exponential" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="exponential" surface="geogebra" material="fnnem4tf" aspect="1:1">
                  setCoordSystem(-3,3,-3,3);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> 
                 Drag <m>z</m> around and see how <m>e^z</m> changes. 
                 Try dragging <m>z</m> up and down along the line <m>x = 1</m>,
                 or back and forth along the line <m>y = 1</m>.
                 You can view a larger version of this <url href="https://www.geogebra.org/calculator/fnnem4tf">here</url>.
                </p>
              </instructions>
            </interactive>
          </figure>
        </subsection>
        <p>
          We conclude from our previous discussion that the range of the exponential map
          <m>z\mapsto e^z</m> is <m>\C\wo\{0\}</m>. This leads us to wonder about defining a logarithm.
        </p>
        <subsection xml:id="subsec-log">
          <title>The complex logarithm</title>
          <p>
            We would like to define a log map <m>\C\wo\{0\} \to \C</m> that is inverse to the exponential.
            As we found with the square-root, we will have to make a branch cut in order to choose a specific
            log continuously, though.
          </p>
          <p>
            Given <m>z \ne 0</m>, we want to find a solution to the equation <m>z = e^w = e^{\Re w} e^{i\Im w}</m>.
            We need <m>\abs{z} = e^{\Re w}</m> and <m>\Im w = \arg z</m>. In fact we <em>must</em> have this;
            all logarithms of <m>z</m> take the form
            <me>
              \log z = \ln \abs z + i \arg z  
             </me>
             for some choice of <m>\arg z</m>.
            So all logarithms of <m>z</m> take the form
            <me>
              \log z = \ln \abs z + i\Arg z + i(2\pi m), \quad m\in\mathbb{Z}.
            </me>
          </p>
          <definition xml:id="def-principal-log">
            <statement>
              <p>
                The <term>principal branch of the log</term> is the function <m>\Log \colon \C\wo(-\infty,0]\to \C</m>
                defined by <m>\Log(z) = \ln\abs{z} + i\Arg z</m>.
              </p>
            </statement>
          </definition>
          <p>
            As with the square-root, we have to cut the domain in order for the function <m>\Log</m> to be continuous.
            And, as with the square-root, negative real numbers still have logarithms!
          </p>
          <!--https://www.geogebra.org/calculator/qegzawxm-->
          <figure xml:id="fig-geogebra-log">
            <caption>GeoGebra: The log</caption>
            <interactive xml:id="geogebra-log" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="log" surface="geogebra" material="qegzawxm" aspect="1:1">
                  setCoordSystem(-20,20,-20,20);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> 
                 Drag <m>z</m> around and see how <m>\Log(z)</m> and the other possible logs of <m>z</m> change. 
                 Notice that the principal choice <m>Log(z)</m> changes discontinuously as <m>z</m>
                 crosses the negative real axis.
                 You can view a larger version of this <url href="https://www.geogebra.org/calculator/qegzawxm">here</url>.
                </p>
              </instructions>
            </interactive>
          </figure>
          <example>
            <me>
              \Log(1+i) = \Log(\sqrt2 e^{i \pi / 4}) = \ln\sqrt2 + i\pi/4 \approx 0.35 + i\pi/4
            </me>
            <p>
              All possible logs of <m>1+i</m> are <m>\log(1+i) = \ln\sqrt2 + i\pi/4 + 2\pi m i</m>, <m>m\in\mathbb{Z}</m>.
            </p>
          </example>
          <!--TODO: add images of lines etc-->
          <!--TODO: add examples showing 2Log(z) ne Log(z^2)-->
        </subsection>
        <subsection xml:id="subsec-branches">
          <title>Branch cuts and branch points</title>
          <p>
            We can view the log, for example, as a multi-valued function on <m>\C\wo\{0\}</m>.
            Each time we use log, we need to choose a branch (often the principal one).
          </p>
          <definition xml:id="def-cts-branch">
            <statement>
              <p>
                If <m>U\subseteq\C\wo\{0\}</m> is an open set, then a <term>branch of the log</term>
                defined on <m>U</m> is a continuous function <m>f\colon U\to\C</m>
                for which <m>e^{f(z)} = z</m> for all <m>z\in U</m>.
              </p>
              <p>
                A <term>branch point</term> of a multi-valued function <m>f</m> is a point <m>p\in\C</m>
                such that, for every <m>\epsilon \gt 0</m>, the function cannot be 
                given a continuous single-valued definition on <m>B_\epsilon(p) \wo \{p\}</m>.
              </p>
            </statement>
          </definition>
          <p>
            <m>B_\epsilon(p) = \set{ z\in\C }{ \abs{z - p} \lt \epsilon</m> is the ball of radius
            <m>\epsilon</m> centered at <m>p</m>.
            Don't worry, we'll discuss these things in more detail in later sections.
          </p>
          <example>
            <p>
              <m>0</m> is a branch point of log.
            </p>
          </example>
          <example>
            <p>
              The function <m>f(z) = \sqrt{z(z-1)}</m> has two branch points, at <m>z = 0</m>
            and <m>z = 1</m>.
            </p>
            <!-- TODO: Say more!-->
          </example>
        </subsection>
        <subsection xml:id="subsec-power-functions">
          <title>General power functions</title>
          <p>
            Now that we have the log, we can define general power functions.
          </p>
          <definition xml:id="def-power-function">
            <statement>
              <p>
               For any <m>\alpha\in\mathbb{Z}</m>, the <term>principal branch of the power function</term>
               <m>z\mapsto z^\alpha</m> is the function <m>\C\wo (-\infty,0] \to \C</m> defined as follows.
               <me>
                z^\alpha = e^{\alpha \Log(z)}
               </me>
              </p>
            </statement>
          </definition>
          <example>
            <p>
              This agrees with our earlier definition of the principal branch of the square-root function:
            </p>
            <me>
              z^{1/2} = e^{\frac12 \Log z} = e^{\frac12 \ln \abs{z} + \frac12 i \Arg z}
              = \abs{z}^{1/2} e^{i\Arg z / 2}
            </me>
          </example>
          <example>
            <p>
              Let's find all possible values of <m>i^i</m>.
            </p>
            <me>
              i^i = e^{i \log i} = e^{i(\ln 1 + i \arg i)} = e^{-\arg i}.
            </me>
            <p>
              Since the possible values of <m>\arg i</m> are <m>\frac{\pi}{2} + 2\pi m</m>, <m>m\in\mathbb{Z}</m>,
              we have
            </p>
            <me>
              i^i = e^{-\pi/2} = e^{-5\pi / 2} = \cdots
            </me>
            <p>
              These are all real numbers!!!
            </p>
          </example>
        </subsection>
         <subsection xml:id="subsec-trig-functions">
           <title>Trig functions</title>
           <p>
            Standard trig functions can be defined in terms of the exponential.
          </p>
          <definition xml:id="def-sine-cosine">
            <statement>
              <p>
                Sine and cosine are defined at <em>all complex numbers</em> <m>z</m> as follows.
              </p>
              <me>
                \cos(z) = \frac{e^{iz} + e^{-iz}}{2} \quad \sin(z) = \frac{e^{iz} - e^{-iz}}{2i}
              </me>
            </statement>
          </definition>
          <aside>
            <p>
              Remember your Taylor Series from calculus? 
              Write down the Taylor series for the exponential function, centered at <m>0</m>,
              and plug in <m>iz</m> and simplify. Do the same thing but plug in <m>-iz</m> and simplify.
              You should be very close to a Taylor series for cosine.
            </p>
          </aside>
          <p>
            <alert>Warning:</alert> These definitions are motivated by Euler's Formula: e.g. for <m>x\in\R</m>,
          </p>
          <me>
            \cos(x) = \Re(e^{ix}) = \frac{e^{ix} + e^{-ix}}{2}.
          </me>
          <p>
            But <m>\cos(z) \ne \Re(e^{iz})</m> in general! In particular, the quantity on the right is real-valued, 
            whereas <m>\cos(z)</m> is not.
            And we can just expand out <m>e^{iz}</m> and examine its real and imaginary parts:
          </p>          
          <me>
            e^{iz} = e^{i(x+iy)} = e^{-y + ix} = e^{-y}(\cos x + i\sin x).
          </me>
          <p>
            So <m>\Re(e^{iz}) = e^{-y}\cos x</m>, which does not typically equal <m>\cos z</m>.
          </p>
          <p>
            The tangent function can be defined by <m>\tan z = \frac{\sin z}{\cos z}</m>,
            and hyperbolic trig functions can be defined similarly. You will explore all this on the homework.
          </p>
         </subsection>
      </section>
    </chapter>
    <chapter xml:id="ch-plane-topology">
      <title>Basic topology of the plane</title>
      <section xml:id="sec-regions">
        <title>Regions in the plane</title>
        <p>
          We need to survey some basic topology of the plane and introduce some definitions.
          This will be very familiar to some of you and less familiar to others.
          Rest assured that we will not do any serious <m>\epsilon</m>–<m>\delta</m> proofs in this course.
        </p>
        <definition xml:id="def-open">
          <statement>
            <p>
              For <m>\epsilon \gt 0</m> and <m>p\in\C</m> we define
              <me>
                B_\epsilon(p) = \set{z\in\C}{ \abs{z - p} \lt \epsilon},
              </me>
              the <term>ball</term> or disk of radius <m>\epsilon</m> centered at <m>p</m>.
            </p>
            <p>
              A set <m>U\subseteq \C</m> is <term>open</term> if for every <m>p\in U</m> there is
              <m>\epsilon \gt 0</m> for which <m>B_\epsilon(p) \subseteq U</m>.
              A set <m>F\subseteq \C</m> is <term>closed</term> if its complement <m>\C \wo U</m> is open.
            </p>
            <aside>
              <p>
               If you have seen sequential limits before, you should check that <m>F</m> is closed
               if and only if every convergent sequence of elements of <m>F</m> has a limit in <m>F</m>.
              </p>
            </aside>
          </statement>
        </definition>
        <!--https://www.geogebra.org/calculator/fhvdmyaf-->
        <figure xml:id="fig-geogebra-open-ball">
          <caption>GeoGebra: <m>\epsilon</m> balls</caption>
          <interactive xml:id="geogebra-open-ball" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="open-ball" surface="geogebra" material="fhvdmyaf" aspect="1:1">
                setCoordSystem(-6,6,-6,6);
            <!--    centerView((0,0)); -->
                <!--enableShiftDragZoom(false);-->
              </slate>
            <instructions>
              <p> 
               Drag <m>p</m> around and change <m>\epsilon</m> to see various disks of radius <m>\epsilon</m>
               centered at <m>p</m>.
               You can view a larger version of this <url href="https://www.geogebra.org/calculator/fhvdmyaf">here</url>.
              </p>
            </instructions>
          </interactive>
        </figure>
        <!--https://www.geogebra.org/calculator/fqjanwm3-->
        <figure xml:id="fig-geogebra-open-rectangle">
          <caption>GeoGebra: <m>\epsilon</m> balls</caption>
          <interactive xml:id="geogebra-open-rectangle" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="open-rectangle" surface="geogebra" material="fqjanwm3" aspect="1:1">
                setCoordSystem(-6,6,-6,6);
            <!--    centerView((0,0)); -->
                <!--enableShiftDragZoom(false);-->
              </slate>
            <instructions>
              <p> 
               The rectangular region defined by <m>-2 \lt x \lt 5</m> and <m>-3 \lt y \ln 5</m> is an open set.
               Look at the picture: as you drag <m>p</m> around, there is always a small choice of <m>\epsilon</m>
               (computed for you in the applet) so that <m>B_\epsilon(p)</m> remains totally within the rectangle.
               You can view a larger version of this <url href="https://www.geogebra.org/calculator/fqjanwm3">here</url>.
              </p>
            </instructions>
          </interactive>
        </figure>
        <example>
          <ol marker="(a)">
            <li>
              <p>
                The unbounded sector <m>\set{z\in\C}{ \arg z \in (\frac{\pi}{6},\frac{\pi}{4})}</m>
                is open.
              </p>
            </li>
            <li>
              <p>
                The vertical strip <m>\set{z\in\C}{\Re(z)\in (1,2)}</m> is open.
              </p>
            </li>
            <li>
              <p>
                The closed annulus <m>\set{z\in\C}{ 1\le \abs{z} \le 2}</m> is closed.
              </p>
            </li>
          </ol>
          <aside>
            <p>
              If you have seen some topology, you might recognize that these are all continuous
              preimages of open or closed sets.
            </p>
          </aside>
        </example>
        <definition xml:id="def-path-connected">
          <statement>
            <p>
              A set <m>U\subseteq \C</m> is <term>path-connected</term> iff any two points in <m>U</m>
              can be joined by a continuous path that does not leave <m>U</m>;
              that is, iff for all <m>z,w\in U</m> there is a continuous function <m>\gamma\colon[0,1]\to U</m>
              with <m>\gamma(0) = z</m> and <m>\gamma(1) = w</m>.
            </p>
            <p>
              A <term>domain</term> is a set that is both open and path-connected.
            </p>
          </statement>
        </definition>
        <!-- TODO: add picture of gamma and z and w-->
        <example>
          <p>
            <m>\C</m> is path-connected!
            For any <m>z,w\in\C</m> we can take <m>\gamma(t) = tw +(1-t)z</m>, the standard
            parametrization of the line segment from <m>z</m> to <m>w</m>.
          </p>
          <p>
            But <m>\C\wo\R</m> is not path-connected.
            No continuous path starting in the upper half-plane can reach the lower half-plane
            without crossing the real axis.
            <aside>
              <p>
                How do you prove this carefully? Intermediate Value Theorem...
              </p>
            </aside>
          </p>
        </example>
        <definition xml:id="def-star-shaped">
          <statement>
            <p>
              If <m>X\subseteq \C</m> and <m>z_0\in X</m>, then <m>X</m> is 
              <term>star-shaped with respect to <m>z_0</m></term> iff 
              for all <m>z\in X</m> the straight line segment connecting <m>z_0</m> to <m>z</m>
              lies completely in <m>X</m>.
              <aside>
                <p>
                  You could state this precisely by using the standard parametrization of the line segment.
                  '<m>X</m> is star-shaped wrt <m>z_0</m> iff for all <m>t\in [0,1]</m>
                  we have <m>(1-t)z_0 + tz \in X</m>.'
                </p>
              </aside>
            </p>
            <p>
              A set <m>X</m> is <term>convex</term> if <m>X</m> is star-shaped with respect to every
              one of its elements.
              We just say that <m>X</m> is <term>star-shaped</term> if there is at least one <m>p \in X</m>
              with respect to which <m>X</m> is star-shaped.
            </p>
          </statement>
        </definition>
        <!--https://www.geogebra.org/calculator/u75uczxg-->
        <figure xml:id="fig-geogebra-star-shaped">
          <caption>GeoGebra: star-shaped regions</caption>
          <interactive xml:id="geogebra-star-shaped" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="star-shaped" surface="geogebra" material="u75uczxg" aspect="1:1">
                setCoordSystem(-10,10,-10,10);
            <!--    centerView((0,0)); -->
                <!--enableShiftDragZoom(false);-->
              </slate>
            <instructions>
              <p> 
               This star-ish region is star-shaped wrt <m>z_0</m> but not wrt <m>z_1</m>.
               You can view a larger version of this <url href="https://www.geogebra.org/calculator/u75uczxg">here</url>.
              </p>
            </instructions>
          </interactive>
        </figure>
        <example>
          <!--TODO add pictures-->
          <p>
            The slit disk <m>\set{z}{\abs{z} \lt 1 \text{ and } z\notin [0,1]}</m> is star-shaped wrt
            <m>-1/2</m> but not wrt any point in the fourth quadrant (e.g. <m>0.1-0.1i</m>).
          </p>
          <p>
            An annulus (e.g. <m>1 \le \abs z \le 2</m>) is not star-shaped. 
          </p>
        </example>
        <exercise>
          <p>
            Make sure you understand that for nonempty sets <m>X</m>, the following implications hold.
          </p>
          <me>
            \text{convex} \Longrightarrow \text{star-shaped} \Longrightarrow \text{path-connected}
          </me>
          <p>
            Give examples to show that neither of these implications reverses.
          </p>
        </exercise>
      </section>
      <section xml:id="sec-limits-continuity">
        <title>Limits and continuity</title>
        <p>
          import definitions from multivariable calculus
        </p>
      </section>
    </chapter>
    <chapter xml:id="ch-analytic-functions">
      <title>Analytic Functions</title>
      <section xml:id="sec-derivative">
        <title>The Complex Derivative</title>
        
      <definition xml:id="def-deriv">
        <statement>
          <p>
            A function <m>f\colon U\to \C</m> defined on a domain <m>U</m>
            is <term>differentiable</term> at <m>z_0 \in U</m> if the following limit exists.
          </p>
          <me>
            \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z-z_0}
          </me>
          <p>
            The value of the limit is written <m>f'(z_0)</m> or <m>\frac{df}{dz} (z_0)</m>.
          </p>
          <p>
            We say that <m>f</m> is <term>analytic</term> (or holomorphic) at <m>z_0</m>
            if there is <m>\epsilon \gt 0</m> such that <m>f</m> is differentiable at every
            <m>z\in B_\epsilon(z_0)</m>.
          </p>
          <p>
            If <m>f</m> is analytic at every point in <m>\C</m>, then we say that <m>f</m> is 
            <term>entire</term>. (In particular this means <m>f</m> is defined at every point in <m>\C</m>.)
          </p>
        </statement>
      </definition>
      <p>
        <alert>NB.</alert> This looks like the definition of derivative from calculus,
        and indeed we will discover many similarities between the complex derivative and real derivatives.
        However, a function <m>f\colon \C\to \C</m> can be thought of as a function <m>\R^2\to\R^2</m>, and there
        is a notion of real-differentiability for such functions. 
        Complex-differentiability of <m>f</m> as a function <m>\C\to\C</m> is
        <alert>much stronger</alert> than real-differentiability as a function <m>\R^2\to\R^2</m>.
        This should become clearer as we discover some general properties of analytic functions,
        especially the Cauchy–Riemann Equations.
      </p>
      <investigation>
        <p>
          A function <m>f\colon\R^2\to\R^2</m> can be decomposed into two component functions
          <m>f_1</m> and <m>f_2</m> so that <m>f(x,y) = (f_1(x,y),f_2(x,y))</m>.
          Notice that <m>f_1</m> and <m>f_2</m> are functions <m>\R^2\to\R</m>: their graphs are surfaces,
          just like in multivariable calculus.
          Then <m>f</m> is real-differentiable if and only if both <m>f_1</m> and <m>f_2</m>
          are differentiable (meaning that they have well-defined tangent planes).
          (This is not usually taken as the <em>definition</em>, but it is equivalent.)
        </p>
      </investigation>
      
<!-- TODO: insert examples etc.-->
<!-- TODO: insert graphic illustrating idea of the derivative-->
<!--https://www.geogebra.org/calculator/rveqzyzb <<< this is it-->
<figure xml:id="fig-geogebra-idea-of-deriv">
  <caption>GeoGebra: The idea of the derivative</caption>
  <interactive xml:id="geogebra-idea-of-deriv" platform="geogebra" width="80%" aspect="1:1">
      <slate xml:id="idea-of-deriv" surface="geogebra" material="rveqzyzb" aspect="1:1">
        setCoordSystem(-2,8,-4,6);
    <!--    centerView((0,0)); -->
        <!--enableShiftDragZoom(false);-->
      </slate>
    <instructions>
      <p> 
       You can drag to change <m>dz</m>. Notice how <m>df</m> is a constant multiple of <m>dz</m>:
       there are fixed <m>\theta_0</m> and <m>r_0</m> such that <m>df = r_0e^{i\theta_0} dz</m>.
       You can view a larger version of this <url href="https://www.geogebra.org/calculator/rveqzyzb">here</url>.
      </p>
    </instructions>
  </interactive>
</figure>
    </section>
    <section xml:id="sec-cauchy-riemann">
      <title>The Cauchy–Riemann Equations</title>
      <p>
        The limit of the difference quotient from the definition of derivative
      </p>
      <me>
        \lim_{\Delta z \to 0} \frac{f(z + \Delta z) - f(z)}{\Delta z}
      </me>
      <p>
        is really a multivariable calculus limit:
      </p>
      <me>
        \lim_{(\Delta x, \Delta y) \to (0,0)} \frac{f((x + \Delta x) + i(y + \Delta y)) - f(x + iy)}{\Delta x + i\Delta y}
      </me>
      <p>
        If this limit exists (meaning that <m>f = u + iv</m> is differentiable at <m>z</m>),
        then it must exist along the two coordinate directions. That is, in the special
        cases <m>\Delta z = \Delta x</m> and <m>\Delta z = i\Delta y</m> we must get the same result.
        Let's explore that.
      </p>
      <md>
        <mrow> \frac{f(z + \Delta x) - f(z)}{\Delta x} \amp = \frac{u(z + \Delta x,y) + iv(x + \Delta x,y) - u(x,y) - iv(x,y)}{\Delta x} </mrow>
        <mrow xml:id="item-partial-deriv-x" number="yes"> \amp = \frac{u(x + \Delta x,y) - u(x,y)}{\Delta x} + i \frac{v(x + \Delta x,y) - v(x,y)}{\Delta x} </mrow>
      </md>
      <p>
        If <m>f'(z)</m> exists, then as <m>\Delta x</m> tends to <m>0</m>
        the expression in <xref ref="item-partial-deriv-x"/> must tend toward <m>f'(z)</m>.
        But it must also equal <m>\frac{\partial u}{\partial x}(x,y) + i \frac{\partial v}{\partial x}(x,y)</m>,
        by the definition of partial derivatives! In other words, for <m>f = u + iv</m> and <m>z = x + iy</m>,
      </p>
      <me>
        f'(z) = \frac{\partial u}{\partial x}(x,y) + i \frac{\partial v}{\partial x} (x,y).
      </me>
      <p>
        Do the same thing in the <m>y</m>-direction with <m>\Delta z = i \Delta y</m> and you'll get the following.
      </p>
      <md>
        <mrow> \frac{f(z + i\Delta y) - f(z)}{i \Delta y} \amp = \frac{v(x,y + \Delta y) - v(x,y)}{\Delta y} - i \frac{u(x,y + \Delta y) - u(x,y)}{\Delta y} </mrow>
        <mrow> \amp \underset{\Delta y \to 0}{\longrightarrow} \frac{\partial v}{\partial y} (x,y) - i \frac{\partial u}{\partial y}(x,y) </mrow>
      </md>
      <p>
        More compactly, <m>f'(z) = u_x + iv_x = v_y - iu_y</m>. Identifying real and imaginary parts, we obtain
        the Cauchy–Riemann Equations.
      </p>
      <theorem xml:id="thm-cauchy-riemann">
        <title>Cauchy–Riemann Equations</title>
        <statement>
          <p>
            Suppose that <m>f = u + iv</m> is defined on a domain <m>U\subseteq \C</m>
            and that <m>z = x + iy \in U</m>.
            Then <m>f</m> is (complex-)differentiable at <m>z</m> if and only if
            <m>u</m> and <m>v</m> (construed as functions <m>\R^2 \to \R</m>) have continuous partial derivatives that satisfy
            the following equations, called the <term>Cauchy–Riemann Equations</term>, at <m>z</m>.
          </p>
          <md>
            <mrow> u_x \amp = v_y </mrow>
            <mrow> u_y \amp = -v_x </mrow>
          </md>
          <p>
            In that case, we have
          </p>
          <me>
            f'(z) = u_x(x,y) + i v_x(x,y) = v_y(x,y) - i u_y(x,y).
          </me>
        </statement>
      </theorem>
      <p>
        We have basically shown how to prove the forward direction. We will not give the proof of the other direction;
        it is an exercise in multivariable real analysis using Taylor's Theorem.
      </p>
      <!-- TODO: add in this argument in an appendix! Appendix: the gory details-->
      <example>
        <ol marker="(a)">
          <li>
            <p>
              Let <m>f(z) = z^2</m>, so that <m>f = u + iv</m> where <m>u(x,y) = x^2 - y^2</m> and <m>v(x,y) = 2xy</m>.
              We know that this function (a polynomial) is differentiable everywhere, so we expect
              <m>u</m> and <m>v</m> to satisfy the Cauchy–Riemann Equations everywhere. Indeed, they do:
            </p>
            <md>
              <mrow> u_x \amp = 2x = v_y </mrow>
              <mrow> u_y \amp = -2y = -v_x </mrow>
            </md>
          </li>
          <li>
            <p>
              Consider the conjugation map <m>f(z) = \bar z</m>. Then <m>f = u + iv</m> with <m>u(x,y) = x</m>
              and <m>v(x,y) = -y</m>. In this case we have <m>u_x = 1</m> <m>v_y = -1</m>, so the Cauchy–Riemann
              Equations hold <em>nowhere</em>. So the conjugation map is nowhere (complex-)differentiable,
              which might seem weird since it is a nice orthogonal transformation. 
              In <xref ref="sec-conformal"/> we will get another explanation: conjugation is not analytic
              because it fails to preserve angles, in particular their orientation.
            </p>
          </li>
          <li>
            <p>
              The exponential map <m>f(z) = e^z</m> has real part <m>u(x,y) = e^x \cos y</m> and 
              imaginary part <m>v(x,y) = e^x \sin y</m>. We see that the Cauchy–Riemann equations
            </p>
            <md>
              <mrow> u_x \amp = e^x \cos y = v_y </mrow>
              <mrow> u_y \amp = -e^x \sin y = -v_x </mrow>
            </md>
            <p>
              hold everywhere, as expected since <m>f</m> is entire.
              We also observe that
            </p>
            <me>
              f'(z) = u_x + i v_x = e^x \cos y + i e^x \sin y = e^z.
            </me>
          </li>
        </ol>
      </example>
      <p>
        Using the Cauchy–Riemann Equations, we will several rigidity properties of analytic
        functions that start to give us a sense of what sort of functions can be analytic.
        We begin with an unsurprising complex analogue of a standard fact from single-variable calculus.
      </p>
      <lemma xml:id="lem-deriv-zero-constant">
        <statement>
          <p>
            If <m>f</m> is analytic on a domain <m>D</m>
            and <m>f'(z) = 0</m> for every <m>z\in D</m>, then <m>f</m> must be constant on <m>D</m>.
          </p>
        </statement>
        <proof>
          <p>
            Write <m>f = u+iv</m>, so that our assumption and the Cauchy–Riemann Equations give
          </p>
          <me>
            0 = f'(z) = u_x + iv_x = v_y - i u_y.
          </me>
          <p>
            Identifying real and imaginary parts, we see that <m>u_x = u_y = v_x = v_y = 0</m> on <m>D</m>.
            It follows that the directional derivative <m>D_{\mathbf{w}}f = \grad w \cdot \mathbf{w} = 0</m>
            for every direction vector <m>\mathbf{w}</m>, at every point of <m>D</m>.
            Using this, one can show (using the fact that a plain ole function <m>\R\to\R</m> with derivative
            <m>0</m> must be constant) that <m>f</m> is constant along any line segment that lies completely in <m>D</m>.
            But, since <m>D</m> is path-connected, any two points <m>z,w\in D</m> can be joined by a finite sequence 
            of line segments.
            <aside>
              <p>
              This actually requires a togological argument that we've swept under the rug.
              The gist of it is this: every point on a path from <m>z</m> to <m>w</m> has an open neighborhood that is included in <m>D</m>,
              since <m>D</m> is open. Only finitely many of these open neighborhoods are needed to cover the path by compactness.
              Now replace the portion of the path in the first ball with the straight-line path to where it exits
              the ball. Repeat with the remaining balls.
              </p>
            </aside>
            Since <m>f</m> is constant along each of these line segments, <m>f(z) = f(w)</m>.
            So <m>f</m> is constant on <m>D</m>.
          </p>
        </proof>
      </lemma>
      <exercise xml:id="exercise-real-valued-const">
        <p>
          If <m>f</m> is analytic and real-valued on a domain <m>D</m>, then <m>f</m> must be constant on <m>D</m>.
        </p>
      </exercise>
      <proposition xml:id="prop-conj-const">
        <statement>
          <p>
            If <m>f</m> and <m>\bar f</m> are both analytic on a domain <m>D</m>, then <m>f</m> is constant on <m>D</m>.
          </p>
        </statement>
        <proof>
          <p>
            There is a short proof from <xref ref="exercise-real-valued-const"/>, but we will give a direct proof
            that does not appeal to a homework problem.
          </p>
          <p>
            Write <m>f = u+iv</m> so that <m>\bar f = u - iv</m>.
            The Cauchy–Riemann Equations for <m>f</m> say:
            <me>
              u_x = v_y \quad \text{and} \quad u_y = -v_x,
            </me>
            while the Cauchy–Riemann Equations for <m>\bar f</m> say:
            <me>
              u_x = -v_y \quad \text{and} \quad u_y = v_x.
            </me>
            Adding these equations together gives <m>u_x = u_y = v_x = v_y = 0</m>.
            So <m>f'(z) = u_x + i u_y = 0</m> on <m>D</m>. By <xref ref="lem-deriv-zero-constant"/>,
            it follows that <m>f</m> is constant on <m>D</m>.
          </p>
        </proof>
      </proposition>
      <corollary xml:id="cor-modulus-const">
        <statement>
          <p>
            If <m>f</m> is analytic on a domain <m>D</m> and <m>\abs{f(z)}</m> is constant on <m>D</m>,
            then <m>f</m> is constant on <m>D</m>.
          </p>
        </statement>
        <proof>
          <p>
            If <m>\abs{f}</m> takes the constant value <m>0</m>
            on <m>D</m>, then <m>f</m> takes the constant value <m>0</m> on <m>D</m>. So assume
            from now on that the constant value of <m>\abs{f}</m> on <m>D</m> is not zero.
            Recall that <m>\abs{f(z)} = f(z)\bar{f(z)}</m>. 
            Rearrange to see that <m>\bar{f(z)} = \frac{1}{\abs{f(z)}^2} f(z)</m>,
            which means that <m>\bar f</m> is a constant multiple of the analytic function <m>f</m>;
            therefore <m>\bar f</m> is analytic. 
            Now we can apply <xref ref="prop-conj-const"/> to conclude that <m>f</m> is constant on <m>D</m>.
          </p>
        </proof>
      </corollary>
    </section>
    <section xml:id="sec-inverse">
      <title>Analyticity of inverse functions</title>
      <p>
        If you paid close attention in calculus, you right remember doing something like this to find the 
        derivative of the logarithm.
      </p>
      <md>
        <mrow> e^{\log x} = x  \amp \Longrightarrow \frac{d}{dx} e^{\log x} = \frac{d}{dx} x </mrow>
        <mrow> \amp \Longrightarrow e^{\log x} \frac{d}{dx} \log(x) = 1 </mrow>
        <mrow> \amp \Longrightarrow \frac{d}{dx} = \frac{1}{e^{\log(x)}} = \frac{1}{x} </mrow>
      </md>
      <p>
        You will be pleased to hear that we can do more-or-less the same thing in complex analysis!
        The key theorem should say, essentially, that the derivative of <m>f^{-1}</m> at 
        <m>(b,f^{-1}(b))</m> should be the reciprocal of the derivative of <m>f</m> at
        <m>(a,f(a))</m>. The single-variable calculus version of this fact is illustrated by
        <xref ref="fig-geogebra-deriv-inverse"/>.
      </p>
      <!--https://www.geogebra.org/calculator/qpmqwusa-->
      <figure xml:id="fig-geogebra-deriv-inverse">
      <caption>GeoGebra: Derivatives of Inverses</caption>
      <interactive xml:id="geogebra-deriv-inverse" platform="geogebra" width="80%" aspect="1:1">
          <slate xml:id="deriv-inverse" surface="geogebra" material="qpmqwusa" aspect="1:1">
            setCoordSystem(-2,5,-2,5);
            <!-- centerView((0,0)); -->
            <!--enableShiftDragZoom(false);-->
          </slate>
        <instructions>
          <p> 
          Pictured are graphs of a function and its inverse. You can drag <m>(a,f(a))</m> along the curve.
          Watch how the slope of the tangent line to <m>f</m> at <m>(a,f(a))</m> is always reciprocal to 
          (rise/run becomes run/rise) the slope of the 
          tangent line at the corresponding point <m>(f(a),a)</m> on the graph of <m>f^{-1}</m>.
          </p>
          <p>
          You can view a larger version of this <url href="https://www.geogebra.org/calculator/qpmqwusa">here</url>.
          </p>
        </instructions>
      </interactive>
      </figure>
      <theorem xml:id="thm-deriv-inverse">
        <statement>
          <p>
            Suppose that <m>f</m> is analytic on a domain <m>D</m>, <m>z_0 \in D</m>, and <m>f'(z_0) \ne 0</m>.
            There is a disk <m>B_\epsilon(z_0) \subseteq D</m> on which <m>f</m> is one-to-one;
            moreover the image <m>V = f[B_\epsilon(z_0)]</m> is open, and the inverse function
            <m>f^{-1} \colon V \to U</m> is analytic and satisfies
          </p>
          <me tag="star" xml:id="deriv-inverse-formula">
            (f^{-1})'(f(z)) = \frac{1}{f'(z)}.
          </me>
        </statement>
      </theorem>
      <p>
        We will not bother with a careful proof of <xref ref="thm-deriv-inverse"/> here. 
        Most of the hard work is handled by the Inverse Function Theorem;
        the formula <xref ref="deriv-inverse-formula"/> is obtained just as in Calculus
        by applying the Chain Rule to the equation <m>f(f^{-1}(z)) = z</m>
        and solving for <m>(f^{-1})'(z)</m>.
      </p>
      <investigation>
        <p>
        Where does the Inverse Function Theorem come in? you might wonder.
        Consider a function <m>f = u + iv</m> that is analytic on a domain <m>D</m>.
        If we think of <m>f</m> as the function <m>(u,v) \colon \R^2 \to \R^2</m>, then it has a Jacobian matrix
        <me>
          J_f = \begin {bmatrix}
            \frac{\partial u}{\partial x} \amp  \frac{\partial u}{\partial y} \\
            \frac{\partial v}{\partial x} \amp \frac{\partial v}{\partial y}
          \end {bmatrix}
        </me>
        whose determinant can be computed using the Cauchy–Riemann Equations:
      <me>
        \det J_f = u_x v_y - u_y v_x = u_x^2 + v_x^2 = \abs{u_x + i v_x}^2 = \abs{f'}^2.
      </me>
        So the Jacobian is zero exactly where the complex derivative is zero.
        This allows us to state <xref ref="thm-deriv-inverse"/> in terms of the complex derivative
        instead of referring to the Jacobian.
    </p>
    </investigation>
    <example>
      <p>
        The exponential function <m>f(z) = e^z</m> is entire and has nonzero derivative everywhere.
        The function Log (the principal branch) is an inverse of <m>f</m> 
        defined on <m>\C \wo (-\infty,0]</m>, and it is analytic on its domain by <xref ref="thm-deriv-inverse"/>.
        And its derivative is given by
        <me>
          \Log'(z) = \frac{1}{e^{\Log(z)}} = \frac{1}{z}.
        </me>
        What's more, other branches of log differ from the principal branch by a constant, 
        so they all have the same derivative!
      </p>
      <p>
        <alert>Warning.</alert> Not every multifunction has the property that all its branches have the same derivative, 
        because not every multifunction has the property that its branches all differ by a constant. 
        Consider arccosine, for example. Or even the square-root, of the next exercise.
      </p>
    </example>
    <exercise>
      <p>
       Make sure that you see why <xref ref="thm-deriv-inverse"/> implies that 
       every branch of the square-root is analytic, and 
       <m>\frac{d}{dz} \sqrt z = \frac{1}{2\sqrt z}</m>, where the same square-root function is used on each side
       of the equation.
      </p>
    </exercise>
      
    </section>
    <section xml:id="sec-harmonic">
      <title>Harmonic functions</title>
      <p>
        Motivated by Laplace's Equation
        <me>
          \Delta u = \frac{\partial^2 u}{\partial x_1^2} + \cdots + \frac{\partial^2 u}{\partial x_n^2} = 0,
        </me>
        which is very important in mathematical physics, we make the following definition.
      </p>
      <definition xml:id="def-harmonic">
        <statement>
          <p>
            A function <m>u = u(x,y)\colon \R^2 \to \R</m> is <term>harmonic</term>
            if the partial derivatives <m>u_x, u_y,u_{xx}, u_{xy}, u_{yx}, u_{yy}</m>
            all exist and are continuous, and <m>\Delta u = 0</m>, i.e.,
            <m>u_{xx} + u_{yy} = 0</m>.
          </p>
        </statement>
      </definition>
      <theorem xml:id="thm-analytic-harmonic">
        <statement>
          <p>
            If <m>u+iv</m> is analytic, then <m>u</m> and <m>v</m> are harmonic functions.
          </p>
        </statement>
      </theorem>
      <proof>
        <p>
          Later we will show that the real and imaginary parts of analytic functions have 
          continuous partial derivatives of all orders. So let's not worry about that part for now.
        </p>
        <p>
          This is just an application of the Cauchy–Riemann Equations and equality of mixed partials
          (sometimes called Clairaut's Theorem by calculus textbooks):
        </p>
        <md>
          <mrow> u_{xx} \amp = \frac{\partial}{\partial x} u_x  \amp\amp </mrow>
          <mrow> \amp = \frac{\partial}{\partial x} v_y         \amp\amp \text{(CR)} </mrow>
          <mrow> \amp = \frac{\partial}{\partial y} v_x         \amp\amp \text{(Clairaut)} </mrow> 
          <mrow> \amp = \frac{\partial}{\partial y} (-u_y)       \amp\amp \text{(CR)} </mrow>
          <mrow> \amp = -u_{yy}</mrow>
        </md>
        <p>
          Rearranging gives <m>u_{xx} + u_{yy} = 0</m>. A very similar proof works for <m>v</m>.
        </p>
      </proof>
      <example>
        <p>
          The function <m>u(x,y) = e^x \cos(y)</m> is harmonic, since it is the real part of the 
          analytic function <m>f(z) = e^z</m>.
        </p>
      </example>
      <definition xml:id="def-harmonic-conjugate">
        <statement>
          <p>
            If <m>u</m> is harmonic on a domain <m>D</m> and <m>v</m> is a function for which
            <m>u + iv</m> is analytic on <m>D</m>, then we say that <m>v</m> is a <term>harmonic conjugate</term>
            of <m>u</m>.
          </p>
        </statement>
      </definition>
      <exercise>
        <p>
          State and prove something to the effect that harmonic conjugates are unique up to an additive constant. 
        </p>
        <solution>
          <p>
            Suppose that <m>u+iv</m> and <m>u + iw</m> are both analytic. Then 
            <m>\frac{i(v - w)}{2}</m> is analytic too, but it is also real-valued.
            So <m>v - w</m> is constant.
          </p>
        </solution>
      </exercise>
      <example xml:id="example-harmonic-conjugate">
        <p>
          Find a harmonic conjugate for <m>u(x,y) = xy</m>.
        </p>
        <solution>
          <p>
            First notice that <m>\frac{\partial^2}{\partial x^2} xy = 0 = -\frac{\partial^2}{\partial y^2} xy</m>,
            so <m>u</m> is harmonic.
          </p>
          <p>
            Solve the CR equations. Starting with
            <me>
              y = u_x = v_y
            </me>
            we conclude that <m>v(x,y) = \frac{y^2}{2} + h(x)</m> for some function <m>h</m>.
            Differentiating wrt <m>x</m> and using the CR equations again gives
            <me>
              x = u_y = -v_x = h'(x),
            </me>
            which means (calculus) that <m>h(x) = -\frac{x^2}{2} + C</m>.
            We conclude that <m>v(x,y) = \frac{y^2}{2} - \frac{x^2}{2} + C</m>.
          </p>
          <p>
            What analytic function is <m>u+iv</m>? Look:
          </p>
          <me>
            f(z) = f(x+iy) = xy + \left( \frac{y^2}{2} - \frac{x^2}{2} + C \right)i = -i\frac{z^2}{2} + C.
          </me>
        </solution>
      </example>
      <p>
        An abstract version of the method used in <xref ref="example-harmonic-conjugate"/> can be used to prove the following general theorem.
      </p>
      <theorem xml:id="thm-harmonic-conjugates">
        <statement>
          <p>
            Let <m>D</m> be an open disk or an open (filled-in) rectangle.
            Let <m>u = u(x,y)</m> be a harmonic function on <m>D</m>.
            Then <m>u</m> has a harmonic conjugate <m>v</m> on <m>D</m>, unique up to adding a constant.
          </p>
        </statement>
      </theorem>
      <p>
        The <q>right</q> class of domains <m>D</m> to which <xref ref="thm-harmonic-conjugates"/> applies is the class of
        <term>simply connected</term> domains. A domain is simply connected if and only if every 
        loop in <m>D</m> can be shrunk continuously to a point without leaving <m>D</m>.
        E.g. a disk is simply connected but an annulus is not.
      </p>
      <p>
        <alert>NB.</alert> <xref ref="thm-harmonic-conjugates"/> does not hold in general for domains
        that are not simply connected, e.g. <m>D</m> an annulus or <m>D = \C \wo\{0\}</m>.
        For example, consider <m>u(x,y) = \log\sqrt{x^2 + y^2}</m>. You will probably be asked on the homework
        to explore this example.
      </p>
    </section>
    <section xml:id="sec-conformal">
      <title>Conformal mappings</title>
      <p>
        The idea is that a conformal map should be one that <q>preserves angles</q>.
        <!-- TODO: insert picture-->
        To state this precisely, we will need tangent vectors.
      </p>
      <definition xml:id="def-conformal">
        <statement>
          <p>
            Let <m>\gamma_1,\gamma_2\colon[-1,1]\to\C</m> be two continuous differentiable paths that 
            intersect at <m>0</m>: <m>\gamma_1(0) = \gamma_2(0)</m>. 
            Suppose also that <m>\gamma_1'(0) \ne 0</m> and <m>\gamma_2'(0) \ne 0</m>.
            Define the angle between <m>\gamma_1</m> and <m>\gamma_2</m> as follows.
          </p>
          <me>
            \angleop(\gamma_1,\gamma_2) = \arg(\gamma_1'(0)) - \arg(\gamma_2'(0)).
          </me>
          <p>
            A function <m>f\colon \C\to\C</m> is said to be <term>conformal</term> at <m>z_0</m>
            if whenever <m>\gamma_1,\gamma_2\colon[-1,1]\to\C</m> are two continuously differentiable
            curves with <m>\gamma_1(0) = \gamma_2(0) = z_0</m> and <m>\gamma_1'(0) \ne 0</m> and <m>\gamma_2'(0) \ne 0</m>,
            then 
            <me>
              \angleop(\gamma_1,\gamma_2) = \angleop(f\circ \gamma_1, f\circ \gamma_2)
            </me>
            (and <m>(f\circ \gamma_1)'(0)\ne 0</m> and <m>(f\circ \gamma_2)'(0) \ne 0</m>,
            so that <m>\angleop(f\circ \gamma_1, f\circ \gamma_2</m> is defined).
          </p>
        </statement>
      </definition>
      <p>
        The point of all this is the following theorem.
      </p>
      <theorem xml:id="thm-analytic-conformal">
        <statement>
          <p>
            If <m>f\colon D\to \C</m> is analytic at <m>z_0 \in D</m> and <m>f'(z_0) \ne 0</m>,
            then <m>f</m> is conformal at <m>z_0</m>.
          </p>
        </statement>
        <proof>
          <p>
            This is basically just the Chain Rule and the fact that <m>\arg(z/w) = \arg(z) - \arg(w)</m>.
          </p>
          <md>
            <mrow> \angleop( f\circ \gamma_1, f\circ \gamma_2) \amp \arg((f\circ\gamma_1)'(0)) - \arg((f\circ\gamma_2)'(0))</mrow>
            <mrow> \amp \arg(f'(z_0) \gamma_1'(0)) - \arg(f'(z_0)\gamma_2'(0))</mrow>
            <mrow> \amp \arg\left( \frac{f'(z_0) \gamma_1'(0)}{f'(z_0)\gamma_2'(0)}\right)</mrow>
            <mrow> \amp \arg(\gamma_1'(0)) - \arg(\gamma_2'(0))</mrow>
            <mrow> \amp \angleop(\gamma_1,\gamma_2) </mrow>
          </md>
          <p>
            That's it!
          </p>
        </proof>
      </theorem>
      <p>
        There is a converse to this theorem that we state for completeness but we won't prove.
      </p>
      <fact xml:id="fact-conformal-analytic">
        <statement>
          <p>
            Suppose that <m>f</m> is continuously differentiable and conformal on a domain <m>D</m>
            with nonzero gradient at every point in <m>D</m>.
            Then <m>f</m> is analytic on <m>D</m>, and <m>f'(z) \ne 0</m> for every <m>z\in D</m>.
          </p>
        </statement>
      </fact>
      <example>
        <p>
          The squaring function <m>f(z) = z^2</m> is (as a polynomial) analytic everywhere.
         It maps the sector <m>\arg z \in (-\theta_0,\theta_0)</m> to the sector 
         <m>\arg z \in (-2\theta_0,2\theta_0)</m> of twice the aperture.
         Notice that this function is not conformal at <m>0</m> since its derivative is zero there!
        </p>
      </example>
      <!--https://www.geogebra.org/calculator/c3xacyh7-->
      <figure xml:id="fig-geogebra-square-conformal-1">
        <caption>GeoGebra: <m>z\mapsto z^2</m> transforms some curves conformally</caption>
        <interactive xml:id="geogebra-square-conformal-1" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="square-conformal-1" surface="geogebra" material="c3xacyh7" aspect="1:1">
              setCoordSystem(-70,70,-70,70);
          <!--    centerView((0,0)); -->
              <!--enableShiftDragZoom(false);-->
            </slate>
          <instructions>
            <p> 
             You can view a larger version of this <url href="https://www.geogebra.org/calculator/c3xacyh7">here</url>.
            </p>
          </instructions>
        </interactive>
      </figure>
      <!--https://www.geogebra.org/calculator/cankttgf-->
      <figure xml:id="fig-geogebra-square-conformal-2">
        <caption>GeoGebra: <m>z\mapsto z^2</m> transforms some curves conformally</caption>
        <interactive xml:id="geogebra-square-conformal-2" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="square-conformal-2" surface="geogebra" material="cankttgf" aspect="1:1">
              setCoordSystem(-10,10,-10,10);
          <!--    centerView((0,0)); -->
              <!--enableShiftDragZoom(false);-->
            </slate>
          <instructions>
            <p> 
             You can view a larger version of this <url href="https://www.geogebra.org/calculator/cankttgf">here</url>.
            </p>
          </instructions>
        </interactive>
      </figure>
      <example>
        <p>
         The exponential function <m>z\mapsto e^z</m> is conformal at every <m>z\in\C</m>.
         It restricts to a <term>conformal equivalence</term> between the horizontal strip
         <m>\Im z \in (-\pi,pi)</m> to the slit plane <m>\C\wo(-\infty,0]</m>.
        </p>
      </example>
      <!--https://www.geogebra.org/calculator/rapkxztc-->
      <figure xml:id="fig-geogebra-exp-conformal">
        <caption>GeoGebra: <m>z\mapsto e^z</m></caption>
        <interactive xml:id="geogebra-exp-conformal" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="exp-conformal" surface="geogebra" material="rapkxztc" aspect="1:1">
              setCoordSystem(-10,10,-10,10);
          <!--    centerView((0,0)); -->
              <!--enableShiftDragZoom(false);-->
            </slate>
          <instructions>
            <p> 
             You can view a larger version of this <url href="https://www.geogebra.org/calculator/rapkxztc">here</url>.
            </p>
          </instructions>
        </interactive>
      </figure>
      <definition xml:id="def-conformal-equivalence">
        <statement>
          <p>
            If <m>U</m> and <m>V</m> are open subsets of <m>\C</m> and <m>f\colon U\to V</m>
            is a conformal bijection, then <m>f</m> is called a <term>conformal equivalence</term>.
          </p>
        </statement>
      </definition>
      <investigation>
        <p>
          Don't forget that conformality is equivalent to analytic with derivative <m>0</m>.
          So the Inverse Function Theorem implies that a conformal bijection has local conformal inverses,
          which can be patched together to give a global conformal inverse. All this to say that 
          conformal equivalence is a symmetric relation: if <m>U</m> is conformally equivalent to <m>V</m>,
          then <m>V</m> is conformally equivalent to <m>U</m>.
        </p>
      </investigation>
      <p>
        <alert>Motivation:</alert> Suppose that we want to solve 2D Laplace's Equation
        on a domain <m>U</m> subject to some boundary conditions. 
        Maybe <m>U</m> isn't so nice. We might try to find a conformally equivalent domain <m>V</m>,
        solve Laplace's Equation on <m>V</m>, and then transfer the solution back to <m>U</m>.
      </p>
      <p>
        So it is useful to have a library of conformal equivalences.
      </p>
      <example>
        <p>
        The map <m>z\mapsto z^n</m>, <m>n\ge 2</m>, defines a conformal equivalence
        </p>
        <me>
          \set{ z\in \C}{0 \lt \arg(z) \lt \frac{\pi}{n}} \to \bH,
        </me>
        <p>
          where <m>\bH</m> is the upper halfplane <m>\Im z > 0</m>.
        </p>
        <!--https://www.geogebra.org/calculator/hkhebdqt-->
        <figure xml:id="fig-geogebra-cube-conformal">
          <caption>GeoGebra: <m>z\mapsto z^3</m></caption>
          <interactive xml:id="geogebra-cube-conformal" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="cube-conformal" surface="geogebra" material="hkhebdqt" aspect="1:1">
                setCoordSystem(-8,8,-3,13);
            <!--    centerView((0,0)); -->
                <!--enableShiftDragZoom(false);-->
              </slate>
            <instructions>
              <p> 
               Here is pictured the case <m>n = 3</m>. Notice how the rays and circles meet at right angles
               before applying the map and after!
               You can view a larger version of this <url href="https://www.geogebra.org/calculator/hkhebdqt">here</url>.
              </p>
            </instructions>
          </interactive>
        </figure>
      </example>
      <example xml:id="example-baby-FLT">
        <p>
          The map <m>z\mapsto \frac{z-i}{z+i}</m> defines a conformal equivalence
          between <m>\bH</m> and the unit disk <m>\set{z}{\abs{z} \lt 1}</m>.
        </p>
        <p>
          (Why does this function even send the upper halfplane to the disk? 
          Well, <m>z\in \bH</m> iff <m>z</m> is closer to <m>i</m> than to <m>-i</m>,
          iff <m>\abs{z-i} \lt \abs{z+i}</m>, iff <m>\abs{\frac{z-i}{z+i}} \lt 1</m>.)
        </p>
        <p>
          Why is it conformal? Why is it a bijection? For the answers to those and other questions,
          look to the next Section!!!
        </p>
      </example>
    </section>
    <section xml:id="sec-flt">
      <title>Fractional Linear Transformations</title>
      <p>
        In <xref ref="example-baby-FLT"/> we saw an example of a conformal equivalence.
        This was in fact our second example of a <term>Möbius Transformation</term>,
        aka <term>Fractional-linear Transformation (FLT)</term>.
      </p>
      <definition xml:id="def-FLT">
        <statement>
          <p>
            A <term>Fractional-linear Transformation</term> 
            (aka <term>FLT</term> aka <term>Möbius Transformation</term>)
            is a function <m>f\colon \C\to\C</m> of the form
            <me>
              f(z) = \frac{az + b}{cz + d}
            </me>
            where <m>a,b,c,d</m> are complex numbers satisfying <m>ad-bc \ne 0</m>.
          </p>
        </statement>
      </definition>
      <p>
        (Notice that if we allowed <m>ad-bc = 0</m> then we'd simply get a constant map.
        Some authors allow this and call constant maps <term>singular</term> FLTs,
        so that ours would be <term>non-singular</term> FLTs.)
      </p>
      <example>
        <ol marker="(a)">
          <li>
            <p>
              The function from <xref ref="example-baby-FLT"/> is the FLT
              with <m>a = 1</m>, <m>b = -i</m>, <m>c = 1</m>, and <m>d = i</m>.
            </p>
          </li>
          <li>
            <p>
              Complex inversion <m>z \mapsto \frac{1}{z}</m>
              is the FLT with <m>a = 0</m>, <m>b = 1</m>, <m>c = 1</m>, and <m>d = 0</m>.
            </p>
          </li>
          <li>
            <p>
              The affine transformation <m>z \mapsto az + b </m>
              is the FLT with <m>c = 0</m>, <m>d = 1</m>, and <m>a \ne 0</m>.
            </p>
          </li>
        </ol>
      </example>
      <p>
        It is convenient to regard an FLT <m>f(z) = \frac{az+b}{cz + d}</m> as a 
        transformation <m>\C\cup\{\infty\} \to \C \cup \{\infty\}</m> of the extended complex plane
        by introducing the following conventions.
      </p>
      <p>
        If <m>c = 0</m> then define <m>f(\infty) = \infty</m>.
      </p>
      <p>
        If <m>c \ne 0</m> then set <m>f(-d/c) = \infty</m>
        and set <m>f(\infty) = \frac{a}{c}</m>.
      </p>
      <aside>
        <p>
          Where does <m>\frac{a}{c}</m> come from? Divide the numerator and denominator of 
          <m>\frac{az + b}{cz + d}</m> by <m>z</m> and imagine what happens when <m>z</m>
          tends toward <m>\infty</m>.
        </p>
      </aside>
      <p>
        If you have seen some linear algebra, then it is impossible to look at the condition
        <q><m>ad-bc \ne 0</m></q> in the definition of FLT and not wonder whether this has something
        to do with determinants. We are about to see that it does!
      </p>
      <proposition xml:id="prop-FLT-homom">
        <statement>
          <ol marker="(a)">
            <li>
              <p>
                Every FLT is invertible, and its inverse is another FLT.
              </p>
            </li>
            <li>
              <p>
                The composite of two FLTs is another FLT.
              </p>
            </li>
          </ol>
        </statement>
        <proof>
          <p>
            Consider an FLT <m>f(z) = \frac{az+b}{cz+d}</m>.
            We will show more than what is stated in the Proposition.
            For the first part, define
          </p>
          <me>
             g(z) = \frac{1}{ad-bc} \frac{-dz + b}{cz - a}.
          </me>
          <p>
            (Notice that these parameters are exactly the same as the entries of the matrix
            inverse of the matrix <m>\displaystyle \begin {bmatrix} a \amp b \\ c \amp d \end {bmatrix}</m>!)
          </p>
          <p>
            You can check that <m>g(f(z)) = z</m>. (In fact, this follows from the next part of the proof.)
          </p>
          <p>
            For part (b), consider FLTs <m>f</m> and <m>g</m> given by
            <me>
              f(z) = \frac{az+b}{cz+d}  \quad \text{and}  \quad g(z) = \frac{pz + q}{rz + s}.
            </me>
            You might guess that <m>f(g(z))</m> corresponds to the product of the matrices
            <m>\displaystyle \begin {bmatrix} a \amp b \\ c \amp d \end {bmatrix}</m>
            and <m>\displaystyle \begin {bmatrix} p \amp q \\ r \amp s \end {bmatrix}</m>,
            and you'd be correct!
          </p>
          <p>
            Check that 
            <me>
             f(g(z)) = \frac{(ap + br)z + (aq + bs)}{(cp + dr)z + (cq + ds)}
            </me>
            and use linear algebra to explain why the new parameters <m>A,B,C,D</m> satisfy the non-singular condition
            <m>AD - BC \ne 0</m>.
          </p>
        </proof>
      </proposition>
      <investigation>
        <p>
          What's really going on? 
          The map
          <me>
            \begin{bmatrix} a \amp b \\ c \amp d \end {bmatrix} \mapsto \left(z \mapsto \frac{az + b}{cz + d}\right)
          </me>
          defines a <term>group homomorphism</term>
          <m>\operatorname{GL}_2(\C) \to \operatorname{Aut}(\C\cup\{\infty\})</m>.
          (You don't need to know for this class what these things mean, but you might have seen them in 
          other classes.)
        </p>
      </investigation>
      <theorem xml:id="thm-FLT-decomp">
        <statement>
          <p>
            Every FLT can be expressed as 
            a composite of dilations (<m>z \mapsto az</m>), translations (<m>z\mapsto z + b</m>)
            and inversions (<m>z\mapsto \frac{1}{z}</m>).
          </p>
        </statement>
        <aside>
          <p><q>Dilation</q> is a misnomer, since in the expression <m>z \mapsto az</m> we allow 
          <m>a</m> to be any complex number. Remember that multiplication by a fixed complex
        number <m>a</m> is really amplification by <m>\abs{a}</m> followed by rotation by 
      <m>\arg(a)</m>.</p>
        </aside>
        <proof>
          <p>
            Consider <m>f(z) = \frac{az + b}{cz + d}</m>.
            Again, we consider separately the cases where <m>c = 0</m> and <m>c \ne 0</m>.
          </p>
          <p>
            If <m>c = 0</m> then <m>f(z) = \frac{a}{d} z + \frac{b}{d} = a(z + \frac{b}{a})</m>.
            This is the translation <m>z \mapsto z+ \frac{b}{a}</m> postcomposed by the dilation <m>z \mapsto az</m>.
          </p>
          <p>
            Now suppose that <m>c \ne 0</m>.
            Divide the numerator and denominator by <m>c</m> in order to assume <m>c = 1</m>:
          </p>
          <me>
            f(z) = \frac{az+b}{cz + d} = \frac{\frac{a}{c}z + \frac{b}{c}}{z + \frac{d}{c}}
            = \frac{A z + B}{z + D}.
          </me>
          <p>
            Now do some fraction arithmetic to get
          </p>
          <me>
            f(z) = A + \frac{B - AD}{Z + D}.
          </me>
          <p>Now <m>f</m> can be written as a composite of translations, inversions, and translations. Look:</p>
          <md>
            <mrow>z \amp \mapsto z + D  \amp\amp \text{(translation)}</mrow>
            <mrow> \amp \mapsto \frac{1}{z + D} \amp\amp \text{(inversion)} </mrow>
            <mrow> \amp \mapsto \frac{B - AD}{z + D} \amp\amp \text{(dilation)}</mrow>
            <mrow> \amp \mapsto A + \frac{B-AD}{z+D}  \amp\amp \text{(translation)}</mrow>
          </md>
          <p> The proof is complete. </p>
        </proof>
      </theorem>
      <p>
        <xref ref="thm-FLT-decomp"/> has the following important geometric corollary.
      </p>
      <corollary xml:id="cor-FLT-preserve-circles">
        <statement>
          <p>
            Every FLT is circle-preserving.
          </p>
        </statement>
        <proof>
          <p>
            It is intuitively clear (and straightforward to check carefully)
            that dilations and translations are circle-preserving.
            And we already proved that the complex inversion map <m>z\mapsto 1/z</m>
            preserves circles by considering it as a transformation of the Riemann Sphere!
            <!--TODO: insert ref to this theorem in SP section-->
          </p>
        </proof>
      </corollary>
      <p>Before we move on to other geometric properties of FLTs,
        we should not forget that we know some calculus! What happens when we differentiate
        an FLT?
      </p>
      <me>
        \frac{d}{dz}\left() \frac{az + b}{cz + d} \right)
         = \frac{(cz+d)(a) - (az+b)(c)}{(cz+d)^2}
         = \frac{ad - bc}{(cz + d)^2}
      </me>
      <p>Notice that this is always nonzero, by our non-singularity condition!
        Together with the observation that an FLT is analytic everywhere it is defined
        (it is a rational function!), this amounts to a proof of the following Lemma.
      </p>
      <lemma>
        <statement>
          <p>
            An FLT is analytic wherever it is defined, and it is conformal.
          </p>
        </statement>
      </lemma>
      <proposition xml:id="prop-FLT-fixed-pts">
        <title>Fixed-Point Property of FLTs</title>
        <statement>
          <p>
            Every FLT other than the identity map has either one or two fixed points 
            (counting the point at <m>\infty</m>).
            That is, there are either one or two solutions to <m>f(z) = z</m>.
          </p>
        </statement>
        <proof>
          <p>
            As usual, we consider separately the cases where <m>c=0</m> and <m>c \ne 0</m>.
            Suppose first that <m>c = 0</m>, so that our FLT can be written as <m>f(z) = az + b</m>.
            One fixed point is <m>\infty</m>. If <m>a\ne 1</m> then 
            <m>z = \frac{b}{1-a}</m> is another:
          </p>
          <me>
            f\left( \frac{b}{1-a} \right) = a\frac{b}{1-a} + b = \frac{b}{1-a}.
          </me>
          <p>
            If <m>a=1</m> then <m>b\ne 0</m>, and so <m>z+b = z</m> has no solutions other than <m>z = \infty</m>.
          </p>
          <p>
            Now suppose that <m>c \ne 0</m>. Then <m>f(\infty) = \frac{a}{c} \ne \infty</m>, so <m>\infty</m>
            is not a fixed point.
            The equation
           <me>
             z = \frac{az + b}{cz + d}
           </me>
            can be rearranged into the quadratic equation <m>cz^2 - (a-d)z - b = 0</m>,
            which has two solutions
            <me>
              z = \frac{a-d \pm \sqrt{(a-d)^2 + 4bc}}{2c}
            </me>
            if <m>(a-d)^2 + 4bc \ne 0</m>. Otherwise the two solutions coalesce into just one fixed point:
            <m>\frac{a-d}{2c}</m>.
          </p>
        </proof>
      </proposition>
      <example>
        <ol>
          <li>
            <p>
              The FLT <m>f(z) = \frac{1}{z}</m> has two fixed points <m>z = \pm 1</m>.
            </p>
          </li>
          <li>
            <p>
              The FLT <m>f(z) = \frac{-1}{z}</m> has two fixed points <m>z = \pm i</m>.
            </p>
          </li>
        </ol>
      </example>
      <corollary xml:id="cor-FLT-three">
        <title>Three Points Property</title>
        <statement>
          <p>
            If <m>f</m> and <m>g</m> are FLTs with three common values, i.e.,
            <me>
              f(z_1) = g(z_1) \text{ and } f(z_2) = g(z_2) \text{ and } f(z_3) = g(z_3),
            </me>
            then <m>f = g</m>.
          </p>
        </statement>
        <proof>
          <p>
            The function <m>g^{-1} \circ f</m> (is an FLT by <xref ref="prop-FLT-homom"/> and)
          has three fixed points so by <xref ref="prop-FLT-fixed-pts"/> must be the identity map.
          </p>
        </proof>
      </corollary>
      <theorem xml:id="thm-FLT-three-pts">
        <statement>
          <p>
            For all distinct <m>q,r,s</m> and all distinct <m>q', r', s'</m>
            there is a <em>unique</em> FLT <m>f</m> satisfying
            <m>f(q) = q'</m>, <m>f(r) = r'</m>, and <m>f(s) = s'</m>.
          </p>
          <proof>
            <p>
              Let's start with <m>q' = 0</m>, <m>r' = 1</m>, and <m>s' = \infty</m>.
              (It is not obvious that this is what we should do, but hang in there and you'll see.)
            </p>
            <claim xml:id="claim-FLT-three-pts-special">
              <statement>
                <p>
                  For all distinct complex numbers <m>q,r,s</m> there is a unique FLT <m>f</m>
                  satisfying <m>f(q) = 0</m>, <m>f(r) = 1</m>, and <m>f(s) = \infty</m>.
                </p>
              </statement>
              <proof>
                <p>
                  In order for <m>f</m> to send <m>q</m> to <m>0</m> and <m>s</m> to <m>\infty</m>,
                  <m>f(z)</m> must be proportional to <m>\frac{z - q}{z - s}</m>.
                  That is, <m>f(z) = k\left( \frac{z-q}{z-s} \right)</m> for some <m>k</m>.
                  We plug in <m>r</m> and to solve for <m>k</m>.
                  <me>
                    1 = r' = f(r) = k\left( \frac{r - q}{r-s} \right),
                  </me>
                  so <m>k = \frac{r-s}{r-q}</m>.
                  We conclude that the following FLT <m>f</m> will do the trick:
                </p>
                <me>
                  f(z) = \left( \frac{r-s}{r-q} \right)\left( \frac{z-q}{z-s} \right).
                </me>
                <p>
                (Remember that <m>z</m> is the only variable in this expression.
                So the parameters of <m>f</m> are e.g. <m>b = \frac{r-s}{r-q}(-q)</m>.
                These have to be interpreted appropriately when you plug in <m>\infty</m>
                or get <m>0</m> in the denominator.)
                </p>
              </proof>
            </claim>
            <p>
              By the Claim we can find a FLT <m>f</m> that sends <m>q,r,s</m> to <m>0,1,\infty</m>
            (respectively) and another FLT <m>g</m> that sends <m>q',r',s'</m> to <m>0,1,\infty</m> (respectively).
            Now <m>g^{-1} \circ f</m> sends <m>q,r,s</m> to <m>q',r',s'</m>.
            </p>
          </proof>
        </statement>
      </theorem>
          <definition xml:id="def-cross-ratio">
            <statement>
              <p>
                We define the <term>cross ratio</term> 
                of four complex numbers <m>z,q,r,s</m> to be
                <me>
                  [z : q : r : s] = \left( \frac{r-s}{r-q} \right)\left( \frac{z-q}{z-s} \right),
                </me>
                which is the image of <m>z</m> under the unique FLT sending 
                <m>q,r,s</m> to <m>0,1,\infty</m>.
              </p>
              <aside>
                <p>
                  Warning: different textbooks use different conventions for the cross ratio.
                </p>
              </aside>
            </statement>
          </definition>
          <!--https://www.geogebra.org/calculator/ftf2ykuf-->
          <figure xml:id="fig-geogebra-cross-ratio">
            <caption>GeoGebra: a basic path <m>\gamma</m></caption>
            <interactive xml:id="geogebra-cross-ratio" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="cross-ratio" surface="geogebra" material="ftf2ykuf" aspect="1:1">
                  setCoordSystem(-3,3,-3,3);
              <!--    centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> 
                 Move <m>z,q,r,s</m> around and watch the cross ratio <m>[z : q : r : s]</m> change.
                 The circle through <m>q,r</m> and <m>s</m> is shown for your convenience.
                 You can view a larger version of this <url href="https://www.geogebra.org/calculator/ftf2ykuf">here</url>.
                </p>
              </instructions>
            </interactive>
          </figure>
          <p>
            It is often useful to have an explicit form for the unique FLT
            sending <m>q,r,s</m> to <m>q',r',s'</m>. It is given by solving the following equation
            for <m>w</m> as a function of <m>z</m>, after making appropriate changes to deal with <m>\infty</m>:
          </p>
          <me>
            \frac{(r'-s')(w-q')}{(r'-q')(w-s')} = [w : q' : r' : s'] = [z : q : r : s] = \frac{(r-s)(z-q)}{(r-q)(z-s)}.
          </me>
          <example>
            <p>
              Let's find the unique FLT <m>f</m> sending <m>(i,\infty,-i)</m> to <m>(0,1,\infty)</m>.
              We solve
              <me>
                \frac{w-0}{1-0} = \frac{z-i}{z+i}
              </me>
              for <m>w</m>. Easy! Get <m>w = f(z) = \frac{z-i}{z+i}</m>. 
              Hey, this is the example from <xref ref="example-baby-FLT"/>!
            </p>
          </example>
          <example>
            <p>
              Let's find the unique FLT <m>f</m> sending <m>(\infty,i,0)</m> to <m>(-1,\infty,1)</m>.
              We solve the following equation for <m>w</m>.
              <me>
                \frac{w+1}{w-1} = \frac{i-0}{1}\left( \frac{1}{z-0} \right) = \frac{i}{z}.
              </me>
              We get
            </p>
              <me>
                f(z) = w = \frac{-1-\frac{i}{z}}{1 - \frac{i}{z}} = \frac{-z - i}{z - i}.
              </me>
          </example>
      <lemma xml:id="lem-FLT-only">
        <statement>
          <ol>
            <li>
              <p>
                If <m>f</m> is a FLT whose only fixed point is <m>\infty</m>,
                then there is a nonzero <m>\beta \in \C</m> for which <m>f(z) = z + \beta</m>.
              </p>
            </li>
            <li>
              <p>
                If <m>g</m> is a FLT whose fixed points are <m>0</m> and <m>\infty</m>,
                then there is <m>\gamma\ne 1</m> for which <m>g(z) = \gamma z</m>.
              </p>
            </li>
          </ol>
        </statement>
        <proof>
          <p>
            Write <m>f(z) = \frac{az + b}{cz + d}</m>.
            Notice that <m>c = 0</m> since <m>\infty</m> is a fixed point of 
            <m>f</m>. (This follows from how we defined the extension of an FLT
            to the point at infinity.) So by changing names of constants we can write
            <m>f(z) = az + b</m>. If <m>b=0</m>, then <m>0</m> would be a fixed point of <m>f</m>, 
            contradicting our assumption. So <m>b\ne 0</m>. If <m>a \ne 1</m>
            then <m>\frac{b}{1-a}</m> would be another fixed point of <m>f</m>.
            So <m>a=1</m>; that is, <m>f(z) = z + b</m>, as desired.
          </p>
          <p>
            For the second part, notice that <m>g</m> must be the unique FLT
            that sends <m>0</m> to <m>0</m>, <m>\infty</m> to <m>\infty</m>,
            and <m>1</m> to <m>g(1)</m>. But <m>z \mapsto g(1) z</m> also has these properties,
            so <m>g(z) = g(1) z</m>. And <m>g(1) \ne 1</m>, since <m>g</m> has exactly
            two fixed points (and is therefore not the identity map).
          </p>
        </proof>
      </lemma>
      <lemma xml:id="lem-FLTs-preserve-cross-ratios">
        <statement>
          <p>
            FLTs preserve cross ratios.
            That is, if <m>f</m> is an FLT then
          </p>
          <me>
            [f(z) : f(q) : f(r) : f(s)] = [z : q : r : s].
          </me>
        </statement>
        <proof>
          <p>
            The lefthand side of the equation
            is <m>g(f(z))</m> where <m>g</m> is the unique
            FLT sending <m>(f(q),f(r),f(s))</m> to <m>(0,1,\infty)</m>.
            The righthand side of the equation is <m>h(z)</m>, where <m>h</m> is the unique
            FLT sending <m>(q,r,s)</m> to <m>(0,1,\infty)</m>.
            But <m>g \circ f</m> is also an FLT sending <m>(q,r,s)</m> to <m>(0,1,\infty)</m>,
            so it must be that <m>h = g\circ f</m>. In particular, <m>h(z) = g(f(z))</m>.
          </p>
        </proof>
      </lemma>
    </section>
    </chapter>
    <chapter xml:id="ch-complex-integration">
      <title>Complex Integration
      </title>
      <section xml:id="sec-def-contour-integrals">
        <title>Defining the contour integral</title>
        <p>
          The integral <m>\int_a^b f(x)\,dx</m> from single-variable calculus 
          is defined over an interval <m>[a,b]</m> of real numbers.
          An integral of a complex-valued function <m>f\colon \C\to\C</m>
          from a complex number <m>p</m> to another complex number <m>q</m>
          will more closely resemble integrals from multivariable calculus,
          since <m>\C</m> is inherently two-dimensional!
          In particular, the definition will depend on what path we choose to take from <m>p</m>
          to <m>q</m>.
        </p>
        <definition xml:id="def-paths">
          <statement>
            <p>
              A <term>path</term> is a continuous function <m>\gamma\colon [a,b]\to\C</m>
              for some <m>a,b\in\R</m>.
              A path <m>\gamma</m> is <term>simple</term> if it doesn't cross itself, except possibly
              at its endpoints. That is, <m>\gamma\colon[a,b]\to\C</m> is 
              simple if whenever <m>\gamma(t_1) = \gamma(t_2)</m>
              then either <m>t_1 = t_2</m> or <m>\{t_1,t_2\} = \{a,b\}</m>.
              A path <m>\gamma</m> is <term>closed</term> if <m>\gamma(a) = \gamma(b)</m>.
              A <term>contour</term> is a path that is <term>piecewise <m>C^1</m></term>,
              i.e., a path that can be divided into finitely many paths
              each of which is continuously differentiable.
            </p>
            <!-- TODO: insert picture of a piecewise C^1 path-->
          </statement>
        </definition>
        <!--https://www.geogebra.org/calculator/tesbbp6a-->
        <figure xml:id="fig-geogebra-basic-path">
          <caption>GeoGebra: a basic path <m>\gamma</m></caption>
          <interactive xml:id="geogebra-basic-path" platform="geogebra" width="80%" aspect="1:1">
              <slate xml:id="basic-path" surface="geogebra" material="tesbbp6a" aspect="1:1">
                setCoordSystem(-3,3,-3,3);
            <!--    centerView((0,0)); -->
                <!--enableShiftDragZoom(false);-->
              </slate>
            <instructions>
              <p> 
               You can view a larger version of this <url href="https://www.geogebra.org/calculator/tesbbp6a">here</url>.
              </p>
            </instructions>
          </interactive>
        </figure>
        <definition xml:id="def-contour-integral">
          <statement>
            <p>
              We first define the complex integral for paths in the complex plane.
              If <m>g\colon [a,b]\to \C</m> is continuous, then we integrate <m>g</m> by 
              integrating its real and imaginary parts separately:
              <me>
                \int_a^b g(t)\,dt = \int_a^b \Re(g(t))\,dt + i \int_a^b \Im(g(t))\,dt.
              </me>
              Notice that the result is a complex number.
              But this is really just a prelude to the main event:
            </p>
            <p>
              For a <m>C^1</m> path <m>\gamma\colon[a,b]\to U\subseteq \C</m>
              and a continuous function <m>f\colon U\to \C</m>, we define the <term>integral</term>
              of <m>f</m> over <m>\gamma</m> as follows.
              <me>
                \int_\gamma f(z)\, dz = \int_a^b f(\gamma(t))\gamma'(t)\,dt.
              </me>
              Notice that the integral on the righthand side is defined by the first part 
              of this definition (with <m>g(t) = f(\gamma(t))\gamma'(t)</m>)
              to be
              <me>
                \int_a^b \Re(f(\gamma(t))\gamma'(t))\,dt + i\int_a^b \Im(f(\gamma(t))\gamma'(t))\,dt.
              </me>
              The definition naturally extends to contours <m>\gamma</m> by adding integrals
              over <m>C^1</m> pieces.
            </p>
          </statement>
        </definition>
        <p>
          First, we emphasize two points: the product <m>f(\gamma(t))\gamma'(t)</m>
          is <alert>complex multiplication</alert>, as we will see in the next paragraph. 
          Even though this looks a lot like a definition you saw in multivariable calculus,
          it is not literally the same definition. (In the next section and on the homework
          you will untangle the connection, though.)
        </p>
        <p>
          Second, notice that the result of integrating a complex-valued function over a
          curve will be a complex number, which is fundamentally two-dimensional! So it is not 
          totally clear how to interpret an integral as a physical quantity. Like, what should its
          units be? We will start exploring this in the next section, and you will take the 
          exploration further on the homework.
        </p>
        <p>
          It is natural to wonder whether we've made a reasonable definition here, so let's
          give some motivation. Writing <m>f(z) = u(z) + iv(z)</m>, <m>\gamma(t) = x(t) + iy(t)</m>,
          and <m>dz = dx + idy</m>, we discover the following.
        </p>
        <md>
          <mrow>\int_\gamma f(z)\,dz \amp \int_a^b (u(x,y) + iv(x,y))(dx + idy) </mrow>
          <mrow> \amp \int_a^b u\,dx - v\, dy + i\int_a^b v\,dx + u\,dy </mrow>
        </md>
        <p>
          On the other hand...
        </p>
        <md>
          <mrow> \int_a^b f(\gamma(t))\gamma'(t)\,dt \amp = \int_a^b \Re(f(\gamma(t))\gamma'(t))\,dt + i \int_a^b \Im(f(\gamma(t))\gamma'(t))\,dt </mrow>
          <mrow> \amp = \int_a^b u\,dx - v\, dy + i\int_a^b v\,dx + u\,dy </mrow>
        </md>
        <p>
          (We have omitted some calculations, which you should do carefully!)
        </p>
        <example>
          <p>
            Compute <m>\int_{C_1} \frac{dz}{z}</m>, where <m>C_1</m> is the top half of the unit
            circle traversed from <m>1</m> to <m>-1</m>.
            (We will see below that value of the integral does not depend on the parametrization
            of the curve, so feel free to use any parametrization of <m>C_1</m> here.)
          </p>
          <p>
            The given curve <m>C_1</m> is parametrized by <m>\gamma(t) = e^{it}</m>
            for <m>t\in [0,\pi]</m>.
            We see that <m>\gamma(t) = ie^{it}</m> and <m>f(\gamma(t)) = \frac{1}{e^{it}}</m>.
            That is all we need to compute the integral:
            <me>
              \int_{C_1} \frac{dz}{z} = \int_{t=0}^{\pi} \frac{1}{e^{it}} ie^{it} \,dt = i\int_0^{\pi} dt = \pi i.
            </me>
          </p>
        </example>
        <example>
          <p>
            It is important to note that the integrand in a contour integral need not be analytic.
            We can integrate any continuous function of <m>z</m>.
            (In the next few sections, we will see that amazing things happen when the integrand
            <em>is</em> analytic, though!)
          </p>
          <p>
            Integrate <m>f(z) = \bar z</m> over the top half of the circle <m>\abs{z-1} = 1</m>, oriented counterclockwise.
          </p>
          <p>
            The contour is parametrized by <m>\gamma(t) = 1 + \cos(t) + i\sin(t)</m> for <m>t\in [0,\pi]</m>.
            Plug this in and calculate:
          </p>
          <md>
            <mrow> \int_\gamma \bar z\, dz \amp = \int_{t=0}^\pi (\overline{1 + \cos(t) + i\sin(t)})(-\sin(t) + i \cos(t))\, dt </mrow>
            <mrow> \amp = \int_{t=0}^\pi -\sin(t) + i(\cos(t) + 1)\,dt </mrow>
            <mrow> \amp = \int_{t=0}^\pi -\sin(t)\,dt + i \int_0^\pi (\cos(t) + 1) \, dt </mrow>
            <mrow> \amp = -2 + \pi i </mrow>
          </md>
        </example>
        <example>
          <p>
            Compute <m>\int_{OABO} f(z)\,dz</m> over the triangular curve through the points
            <m>O = 0</m>, <m>A = i</m>, and<m>B = 1+i</m>,
            where <m>f(x+iy) = (y-x) -3ix^2</m>.
          </p>
          <!--TODO: insert picture of OABO-->
          <p>
            We parametrize the three sides of the triangle and integrate along each 
            piece separately; then we add the results together.
          </p>
          <p>
            Along <m>OA</m> you should get <m>\frac{i}{2}</m>.
            Along <m>AB</m> you should get <m>\frac12 - i</m>.
            Along <m>BO</m> you should get <m>1-i</m>.
            The total is <m>\frac{i - 1}{2}</m>.
          </p>
        </example>
      </section>
      <section xml:id="sec-basic-integral-props">
        <title>Basic properties and the Fundamental Theorem</title>
        <lemma xml:id="lem-integral-reparametrize">
          <statement>
            <p>
              The integral <m>\int_\gamma f(z)\, dz</m> is independent of parametrization.
              That is, if <m>\gamma\colon [a,b]\to\C</m>, <m>\delta\colon [a',b']\to\C</m>,
              and <m>\phi\colon [a',b']\to[a,b]</m> satisfy <m>\delta = \gamma \circ \phi</m>,
              then
            </p>
            <me>
              \int_\gamma f(z)\,dz = \int_\delta f(z)\,dz.
            </me>
          </statement>
          <proof>
            <p>
              This follows from the definition of the contour integral and the substitution
              rule (aka <q>u-sub</q>) for the usual Calc I integral:
            </p>
            <md>
              <mrow> \int_\delta f(z)\,dz \amp = \int_{a'}^{b'} f(\gamma(\phi(t)))(\gamma\circ\phi)'(t)\,dt</mrow>
              <mrow> \amp = \int_{a'}^{b'} f(\gamma(\phi(t))) \gamma'(\phi(t)) \phi'(t)\,dt </mrow>
              <mrow> \amp = \int_a^b f(\gamma(u)) \gamma'(u) \,du </mrow>
              <mrow> \amp = \int_\gamma f(z)\,dz</mrow>
            </md>
            <p>
            (For the third equality, we did a u-substitution with <m>u = \gamma(\phi(t))</m>.)
            </p>
          </proof>
        </lemma>
        <lemma xml:id="lem-integral-basic-props">
          <statement>
            <ol marker="(a)">
              <li>
                <p>
                  <m>\int_\gamma f(z) + g(z)\,dz = \int_\gamma f(z)\,dz + \int_\gamma g(z)\,dz</m>
                  and <m>\int_\gamma cf(z)\,dz = c \int_\gamma f(z)\,dz</m>.
                </p>
              </li>
              <li>
                <p>
                  Suppose that <m>\gamma\colon[a,b]\to\C</m> is a contour and that <m>c\in [a,b]</m>.
                  Let <m>\gamma_{\text{start}}</m> be the restriction of <m>\gamma</m> to <m>[a,c]</m>
                  and let <m>\gamma_{\text{end}}</m> be the restriction of <m>\gamma</m> to <m>[c,b]</m>.
                  Then
                </p>
                <me>
                  \int_\gamma f(z)\,dz = \int_{\gamma_{\text{start}}} f(z)\,dz + \int_{\gamma_{\text{end}}} f(z)\,dz
                </me>
              </li>
              <li>
                <me>
                  \int_{-\gamma} f(z)\,dz = -\int_\gamma f(z)\,dz
                </me>
                <p>
                  where <m>-\gamma\colon [a,b] \to \C</m> is the reverse of <m>\gamma</m> defined by 
                  <m>(-\gamma)(t) = a+b - t </m>.
                </p>
              </li>
              <li xml:id="integral-basic-props-max">
                <me>
                  \abs{\int_\gamma f(z)\,dz} \le \operatorname{length}(\gamma) \cdot \sup \abs{f(\gamma(t))},
                </me>
                <p>
                  where <m>\operatorname{length}(\gamma) = \int_a^b \abs{\gamma'(t)}\,dt</m>. 
                  (This is the same definition of arclength from multivariable calculus.)
                </p>
              </li>
            </ol>
          </statement>
          <proof>
            <p>
              We'll prove <xref ref="integral-basic-props-max"/>, but the proofs of the remaining properties
              are left as exercises.
            </p>
            <p>
              Property <xref ref="integral-basic-props-max"/> follows from the definition and the 
              similar <q>bounding box property</q> of standard Calc I integrals:
            </p>
            <md>
              <mrow> \abs{\int_\gamma f(z)\,dz} \amp = \abs{\int_a^b f(\gamma(t))\gamma'(t)\,dt} </mrow>
              <mrow> \amp \le \int_a^b \abs{f(\gamma(t))} \abs{\gamma'(t)}\,dt </mrow>
              <mrow> \amp \le \left( \sup_{t\in [a,b]} \abs{f(\gamma(t))} \right) \int_a^b \abs{\gamma'(t)}\,dt</mrow>
            </md>
            <p>
              That's what we wanted to prove.
            </p>
          </proof>
        </lemma>
        <example xml:id="example-power-function">
          <p>
            Take the standard parametrization of the unit circle:
            <m>\gamma\colon [0,2\pi]\to\C</m>, <m>\gamma(\theta) = e^{i\theta}</m>.
            Let <m>f(z) = z^n</m> for an unspecified <m>n\in\mathbb{Z}</m>.
            Let's compute <m>\int_\gamma f(z)\,dz</m>:
          </p>
          <me>
            \int_\gamma f(z)\,dz = \int_0^{2pi} (e^{i\theta})^n \cdot i e^{i\theta} \, d\theta
            = i\int_0^{2\pi} e^{i(n+1)\theta}\,d\theta,
          </me>
          <p>
            which equals <m>2\pi i</m> if <m>n = -1</m> and <m>0</m> otherwise.
          </p>          
        </example>
        <p>
          We aim to prove a version of the Fundamental Theorem of Calculus for contour integrals.
          First we need a simple version for functions <m>g\colon [a,b] \to \C</m>:
        </p>
        <lemma xml:id="lem-FTC-easy">
          <statement>
            <p>
              Suppose that <m>g(t) = u(t) + iv(t)</m> and <m>G(t) = U(t) + iV(t)</m>
              are two paths <m>[a,b]\to\C</m> for which <m>G'(t) = g(t)</m>.
              Then <m>\int_a^b g(t)\,dt = G(b) - G(a)</m>.
            </p>
          </statement>
          <proof>
            <p>
              This follows immediately from the defintion of integrals for paths like this
              and the Fundamental Theorem of Calculus.
            </p>
            <me>
              \int_a^b g(t)\,dt = \int_a^b u(t)\,dt + i\int_a^b v(t)\,dt = U(b) - U(a) + i(V(b) - V(a))
              = G(b) - G(a).
            </me>
          </proof>
        </lemma>
        <theorem xml:id="thm-FTC">
          <statement>
            <p>
              If <m>F'(z) = f(z)</m> on a domain <m>U</m> and <m>\gamma \colon [a,b]\to U</m> is a contour,
              then <m>\int_\gamma f(z)\,dz = F(\gamma(b)) - F(\gamma(a))</m>.
            </p>
          </statement>
        </theorem>
        <proof>
          <p>
            Apply <xref ref="lem-FTC-easy"/> to <m>G = F\circ \gamma</m> and <m>g = f</m>.
          </p>
        </proof>
        <example>
          <p>
          Let's revisit <xref ref="example-power-function"/>. 
          We're considering <m>f(z) = z^n</m> and <m>\gamma(t) = e^{it}</m> for <m>t \in [0,2\pi]</m>.
          If <m>n\ne -1</m>, then <m>F(z) = \frac{z^{n+1}}{n+1}</m> is an antiderivative of <m>f</m> on <m>\C</m>.
          So <m>\int_\gamma z^n \, dz = F(0) - F(0) = 0</m>.
          </p>
          <p>
          On the other hand, if <m>n = -1</m>, then <m>f(z) = \frac{d}{dz} \log(z)</m>, but the complex
          logarithm can be defined continuously only on a slit plane.
          In fact, because <m>\int \frac{1}{z} \, dz</m> does not vanish on the unit circle,
          there <alert>cannot</alert> be a continuous branch of the log defined on any domain <m>U</m> that
          includes the unit circle. Now we have a <em>proof</em> of that fact!
          </p>
        </example>
        <p>
          An especially important consequence of the FTC for contour integrals
          is that if <m>f</m> has an antiderivative, then <m>f</m> integrates to <m>0</m>
          over any closed curve. As we will see in the next section, this implication reverses!
        </p>
      </section>
      <section xml:id="sec-cauchys-thm">
        <title>Cauchy's Theorem</title>
        <theorem xml:id="thm-antiderivative-conditions">
          <statement>
            <p>
              Suppose that <m>f</m> is a continuous function defined on a domain <m>D</m>. The following are equivalent:
            </p>
            <ol marker="(a)">
              <li xml:id="thm-item-antiderivative">
                <p>
                  <m>f</m> has an antiderivative <m>F</m> on <m>D</m>;
                </p>
              </li>
              <li xml:id="thm-item-path-ind"><p>for all <m>z_1,z_2\in D</m> the integral <m>\int_{z_1}^{z_2} f(z)\,dz</m> 
              is <term>independent of path</term>, meaning that for all contours <m>\gamma,\delta\colon [a,b]\to D</m>
            with <m>\gamma(a) = \delta(a) = z_1</m> and <m>\gamma(b) = \delta(b) = z_2</m> we have
          <m>\int_\gamma f(z)\,dz = \int_\delta f(z)\,dz</m>; </p> </li>
          <li xml:id="thm-item-closed">
            <p>
              for all closed paths <m>\gamma \colon [a,b]\to D</m> we have <m>\int_\gamma f(z)\,dz = 0</m>.
            </p>
          </li>
            </ol>
          </statement>
          <proof>
            <p>
              We'll give the proofs of all the easy directions here and leave the difficult direction for
              a separate proposition.
            </p>
            <p>
              First, notice that we already observed that <xref ref="thm-item-antiderivative"/> implies <xref ref="thm-item-path-ind"/>
              after our discussion of the FTC for contour integrals.
              It is not too difficult to see that conditions <xref ref="thm-item-path-ind"/> and <xref ref="thm-item-closed"/> are 
              equivalent. Assume <xref ref="thm-item-path-ind"/> and suppose that <m>\gamma</m> is closed.
              Divide <m>\gamma</m> into two paths, <m>\gamma_1</m> from <m>z_1</m> to <m>z_2</m> and <m>\gamma_2</m> from
              <m>z_2</m> back to <m>z_1</m>. (It does not matter where this division happens.) 
              Using path-independence and the basic properties of contour integrals, we have
             </p>
             <me>
              \int_{\gamma_1} f(z)\,dz = \int_{\gamma_2} f(z)\,dz = -\int_{\gamma_2} f(z)\,dz,
             </me>
             <p>
              from which we conclude that
              <me>
                \int_\gamma f(z)\,dz = \int_{\gamma_1 + -\gamma_2} f(z)\,dz = 0.
              </me>
              So <xref ref="thm-item-path-ind"/> implies <xref ref="thm-item-closed"/>.
              The proof of the converse uses similar ideas and is left as an exercise.
             </p>
             <p>
              So it remains to show that <xref ref="thm-item-path-ind"/> implies <xref ref="thm-item-antiderivative"/>,
              which we leave to <xref ref="exerc-antiderivatives-loose-end"/> because it will be useful to have a refinement of this result.
             </p>
          </proof>
        </theorem>
        <p>
          Notice that when we say that <m>f</m> has an <term>antiderivative</term> here, we mean that it has a complex
          antiderivative, i.e., a function <m>F</m> for which <m>\frac{d}{dz} F(z) = f(z)</m>.
        </p>        
        <p>
          <xref ref="thm-antiderivative-conditions"/> should remind you of a theorem from multivariable calculus.
          In fact you can use one to prove the other; see <xref ref="exercise-antiderivative-conditions-multi"/>.
        </p>
        <proposition xml:id="prop-triangles-antiderivative">
          <statement>
            <p>
              Suppose that <m>U</m> is a star-shaped domain, <m>f\colon U\to \C</m> is continuous,
              and <m>\int_{\partial T} f(z)\,dz = 0</m> for all triangles <m>T \subseteq U</m>.
              Then <m>f</m> has an antiderivative on <m>U</m>.
            </p>
          </statement>
          <proof>
            <p>
              Let <m>a_0 \in U</m> be a point of <m>U</m> with respect to which <m>U</m> is star-shaped.
              For <m>w\in U</m> define <m>F(w) = \int_{[a_0,w]} f(z)\,dz</m>,
              where <m>[a_0,w]</m> is the straight-line path from <m>a_0</m> to <m>w</m>.
              (Notice that <m>[a_0,w]</m> lies completely in <m>U</m>, since <m>U</m> is star-shaped wrt <m>a_0</m>.)
            </p>
            <!--https://www.geogebra.org/calculator/gjscszrk-->
            <figure xml:id="fig-geogebra-star-shaped-antiderivative">
              <caption>GeoGebra: a basic path <m>\gamma</m></caption>
              <interactive xml:id="geogebra-star-shaped-antiderivative" platform="geogebra" width="80%" aspect="1:1">
                  <slate xml:id="star-shaped-antiderivative" surface="geogebra" material="gjscszrk" aspect="1:1">
                    <!--setCoordSystem(-3,3,-3,3);-->
                <!--    centerView((0,0)); -->
                    <!--enableShiftDragZoom(false);-->
                  </slate>
                <instructions>
                  <p> 
                   You can move <m>w</m> around freely.
                    You can view a larger version of this <url href="https://www.geogebra.org/calculator/gjscszrk">here</url>.
                  </p>
                </instructions>
              </interactive>
            </figure>
            <p>
              We aim to show that <m>F'(w) = f(w)</m>. Since <m>U</m> is open, there is <m>\epsilon \gt 0</m>
              for which <m>B_\epsilon(w) \subseteq U</m>. Let <m>\Delta w \lt \epsilon</m>.
              Let <m>T</m> be the triangle formed by <m>a_0, w</m>, and <m>w+\Delta w</m>, with boundary oriented counterclockwise.
              Notice that <m>T</m> is completely included in <m>U</m>, since every point on the line segment 
              <m>[w,w+\Delta w]</m> is (by choice of <m>\Delta w</m>), and since <m>U</m> is star-shaped wrt <m>a_0</m>.
              We can therefore apply our assumption to conclude that <m>\int_{[a_0,w] + [w,w+\Delta w] + [w+\Delta w,a_0]} f(z)\,dz = 0</m>.
              On the other hand, this integral also equals <m>F(w+\Delta w) - \int_{[w,w + \Delta w]} f(z)\,dz - F(w)</m>,
              so we rearrange to obtain
            </p>
            <me>
              F(w + \Delta w) - F(w) = \int_{[w + \Delta w,w]} f(z)\,dz.
            </me>
            <p>
              What we'd really like to estimate is the difference quotient <m>\frac{F(w + \Delta w) - F(w)}{\Delta w}</m>, so we 
              rearrange further (noting that <m>f(w)</m> is a constant function, relative to <m>z</m>).
            </p>
            <me>
              F(w + \Delta w) - F(w) - \Delta w f(w) = \int_{[w+\Delta w,w]} (f(z) - f(w))\, dz
            </me>
            <p>
            Now we are in a position to make the final estimate.
            </p>
            <md>
              <mrow> \abs{\frac{F(w + \Delta w) - F(w)}{\Delta w} - f(w)} \amp \le \frac{1}{\abs{\Delta w}} \abs{\int_{[w + \Delta w, w]} (f(z) - f(w)) \, dz} </mrow>
              <mrow> \amp \le \frac{1}{\abs{\Delta w}} \abs{\Delta w} \sup_{[w + \Delta w,w]} \abs{f(z) - f(w)},</mrow>
            </md>
            <p>
              which tends to <m>0</m> as <m>\Delta w</m> tends to <m>0</m>, since <m>f</m> is continuous.
            </p>
          </proof>
        </proposition>
        <exercise xml:id="exerc-antiderivatives-loose-end">
          <p>
            Redo the proof of <xref ref="prop-triangles-antiderivative"/> without the assumption that <m>U</m> is star-shaped,
            but assuming that <m>\oint_\gamma f(z)\,dz = 0</m> for all closed contours <m>\gamma</m> (not only triangles)
            in <m>U</m>. (Choose <m>a_0</m> to be <em>any</em> element of <m>U</m>, and take <m>[a_0,w]</m> to be any path
            from <m>a_0</m> to <m>w</m> that lies completely inside <m>U</m>.)
          </p>
          <p>
            Make sure you have a complete proof of <xref ref="thm-antiderivative-conditions"/>.
          </p>
        </exercise>
        <p>
          The goal now is to prove Cauchy's Theorem for star-shaped domains, which says that if <m>U</m> is a 
          star-shaped domain and <m>f</m> is analytic on <m>U</m>, then <m>\oint_\gamma f(z)\,dz = 0</m> for all
          closed contours <m>\gamma</m> in <m>U</m>.
          In light of <xref ref="prop-triangles-antiderivative"/> and <xref ref="thm-antiderivative-conditions"/>,
          it suffices to prove the special case where <m>\gamma</m> is triangular.
        </p>
        <theorem xml:id="thm-cauchy-triangles">
          <title>Cauchy's Theorem for Triangles</title>
          <statement>
            <p>
              Suppose that <m>U</m> is a domain and that <m>f\colon U \to \C</m> is analytic on <m>U</m>.
              If <m>T\subseteq U</m> is a triangle, then <m>\oint_{\partial T} f(z)\,dz = 0</m>.
            </p>
          </statement>
          <proof>
            <p>
              This is a serious proof! Fix a triangle <m>T</m> and put <m>I = \abs{\int_{\partial T} f(z)\,dz}</m>.
              Also write <m>\ell</m> for the perimeter of <m>T</m>.
              Our plan is to bound <m>I</m>, showing that <m>I \lt \epsilon</m> for all <m>\epsilon \gt 0</m>.
              Divide <m>T = T^0</m> into four subtriangles <m>T^0_a, T^0_b, T^0_c, T^0_d</m> by taking the midpoints
              of each of the three sides.
              As indicated by the picture, these four subtriangles can be oriented in such a way that
            </p>
            <!--TODO: insert picture of triangle subdivision-->
            <me>
              \int_{\partial T^0} f = \int_{\partial T^0_a} f + \int_{\partial T^0_b} f + \int_{\partial T^0_c} f + \int_{\partial T^0_d} f
            </me>
            <p>
              It follows that one of the four satisfies <m>\abs{\int_{\partial T^0_\bullet f(z)\,dz} \ge \frac{I}{4}</m>.
              Call that one <m>T^1</m>. Notice that the four subtriangles are each similar (in the sense of geometry)
              to <m>T^0</m> with edge-lengths halved, so <m>\operatorname{perimeter}(T^1) = \frac{\ell}{2}</m>.
            </p>
            <p>
              Iterate this process. At stage <m>n</m> we have <m>2^n</m> triangles each of perimeter <m>\frac{\ell}{2}</m>
              and a particular one <m>T^n</m> with <m>\abs{\int_{\partial T^n} f(z)\,dz} \ge \frac{I}{4^n}</m>.
              These triangles form a nested sequence <m>T^0 \supseteq T^1 \supseteq \cdots</m> of closed sets of diameter
              tending to <m>0</m>, so by Compactness there is a unique point <m>z_0 \in \bigcap_{m\in\N} T^n</m>.
              We assumed that <m>f</m> was analytic at <m>z_0</m>, so, fixing arbitrary <m>\epsilon > 0</m>, we must have
              a <m>\delta > 0</m> for which the following inequality holds for every <m>w\in  B_\delta(z_0)</m>.
            </p>
            <me>
              \abs{\frac{f(w) - f(z_0)}{w - z_0} - f'(z_0)} \lt \epsilon.
            </me>
            <p>
              Rearrange:
            </p>
            <me>
              \abs{f(w) - f(z_0) - f'(z_0)(w - z_0)} \lt \epsilon \abs{w - z_0}.
            </me>
            <p>
              Let <m>n</m> be large enough that <m>T^n \subseteq B_\delta(z_0)</m>.
              We rewrite <m>\int_{\partial T^n} f(z)\,dz</m> in the following non-obvious way, using the fact
              that constant functions integrate to <m>0</m> over closed contours by the FTC.
            </p>
            <md>
              <mrow> \int_{\partial T^n} f(z)\,dz \amp = \int_{\partial T^n} f(z)\,dz + \int_{\partial T^n} -f(z_0)\,dz
                + \int_{\partial T^n} -(z-z_0)f'(z_0)\,dz </mrow>
              <mrow> \amp = \int_{\partial T^n} (f(z) - f(z_0) - (z-z_0)f'(z_0))\,dz </mrow>
            </md>
            <p>
              Now we just need to do an ML estimate:
            </p>
            <md>
              <mrow> \abs{\int_{\partial T^n} f(z)\,dz} \amp \le \int_{\partial T^n} \abs{f(z) - f(z_0) - (z-z_0)f'(z_0)}\,dz </mrow>
              <mrow> \amp \le \int_{\partial T^n} \epsilon \abs{z - z_0} \,dz </mrow>
              <mrow> \amp \le \operatorname{length}(\partial T^n) \cdot \epsilon \sup_{z\in \partial T^n} \abs{z - z_0} </mrow>
              <mrow> \amp \le \epsilon \operatorname{length}(\partial T^n)^2 </mrow>
            </md>
            <p>
              (In the second line we used the fact that <m>T^n \subseteq B_\delta(z_0)</m>; in the third we used an ML inequality;
              and in the fourth we used the fact that the distance between any two points of a triangle is at most its perimeter.)
            </p>
            <p>
              Putting everything together, we obtain the following.
            </p>
            <me>
              I \le 4^n \abs{ \int_{\partial T^n} f(z)\,dz} \le 4^n \epsilon \left( \frac{\ell}{2^n}\right)^2 = \epsilon \ell^2.
            </me>
            <p>
              But <m>\epsilon \gt 0</m> was arbitrary and <m>\ell</m> is fixed, so <m>I = 0</m>.
            </p>
            <figure width="90%" xml:id="fig-cauchy-triangles">
              <caption>Subdivided triangles.</caption>
              <image xml:id="latex-im-cauchy-triangles">
                <description>Subdivided triangles</description>
                <latex-image>
                  \begin {tikzpicture}
                  \coordinate (N) at (0,3) ;
                  \coordinate (W) at (-2,0) ;
                  \coordinate (E) at (3,1) ;
                  \draw (N) -- (W) -- (E) -- (N) ;
                  \coordinate (NW1) at ($(N)!0.5!(W)$) ;
                  \coordinate (WE1) at ($(W)!0.5!(E)$) ;
                  \coordinate (NE1) at ($(E)!0.5!(N)$) ;
                  \draw (NW1) -- (WE1) -- (NE1) -- (NW1) ;
                 \begin {scope}[decoration={
                 markings,
                 mark=at position 0.55 with {\arrow{latex}}}
                 ]
                  \draw [postaction={decorate}] (NE1) to (N) ;
                  \draw [postaction={decorate}] (N)  to (NW1) ;
                  \draw [postaction={decorate}] (NW1)  to (W) ;
                  \draw [postaction={decorate}]  (W)  to (WE1) ;
                  \draw [postaction={decorate}] (WE1)  to (E) ;
                  \draw [postaction={decorate}] (E) to (NE1);
                  \draw [postaction={decorate}] (NW1) to (NE1) ;
                  \draw [postaction={decorate}] (NE1) to (WE1) ;
                  \draw [postaction={decorate}] (WE1) to (NW1) ;
                \end {scope}
                 \end {tikzpicture}
                 \begin {tikzpicture}
                 \coordinate (N) at (0,3) ;
                 \coordinate (W) at (-2,0) ;
                 \coordinate (E) at (3,1) ;
                 \draw (N) -- (W) -- (E) -- (N) ;
                 \coordinate (NW) at ($(N)!0.5!(W)$) ;
                 \coordinate (WE) at ($(W)!0.5!(E)$) ;
                 \coordinate (NE) at ($(E)!0.5!(N)$) ;
                 \coordinate (NNE) at ($(N)!0.5!(NE1)$) ;
                 \coordinate (NEE) at ($(NE)!0.5!(E)$) ;
                 \coordinate (EWE) at ($(E)!0.5!(WE)$) ;
                 \coordinate (WEW) at ($(WE)!0.5!(W)$) ;
                 \coordinate (WNW) at ($(W)!0.5!(NW)$) ;
                 \coordinate (NWWE) at ($(NW)!0.5!(WE)$) ;
                 \coordinate (WENE) at ($(WE)!0.5!(NE)$) ;
                 \coordinate (NWN) at ($(N)!0.5!(NW)$) ;
                 \coordinate (NWNE) at ($(NW)!0.5!(NE)$) ;
                 \draw (NWN) -- (NNE) -- (NWNE) -- (NWN) ;
                 \draw (WNW) -- (NWWE) -- (WEW) -- (WNW) ;
                 \draw (NWWE) -- (NWNE) -- (WENE) -- (NWWE) ;
                 \draw (WENE) -- (NEE) -- (EWE) -- (WENE) ;
                 \draw (NW) -- (WE) -- (NE) -- (NW) ;  
                \begin {scope}[decoration={
                markings,
                mark=at position 0.55 with {\arrow{latex}}}
                ]
                % exterior
                 \draw [postaction={decorate}] (N) to (NWN) ;
                 \draw [postaction={decorate}] (NWN) to (NW) ;
                  \draw [postaction={decorate}] (NW) to (WNW) ;
                 \draw [postaction={decorate}] (WNW) to (W) ;
                 \draw [postaction={decorate}] (W) to (WEW) ;
                  \draw [postaction={decorate}] (WEW) to (WE) ;
                 \draw [postaction={decorate}] (WE) to (EWE) ;
                 \draw [postaction={decorate}] (EWE) to (E) ;
                 \draw [postaction={decorate}] (E) to (NEE) ;
                 \draw [postaction={decorate}] (NEE) to (NE) ;
                 \draw [postaction={decorate}] (NE) to (NNE) ;
                  \draw [postaction={decorate}] (NNE) to (N) ;
                 \draw [postaction={decorate}] (NWN) to (NNE) ;
                 % second row
                 \draw [postaction={decorate}] (NW) to (NWNE) ;
                 \draw [postaction={decorate}] (NWNE) to (NE) ;
                 % third row
                 \draw [postaction={decorate}] (WNW) to (NWWE) ;
                 \draw [postaction={decorate}] (NWWE) to (WENE) ;
                 \draw [postaction={decorate}] (WENE) to (NEE) ;
                 % first column, bottom left to top right
                 \draw [postaction={decorate}] (WEW) to (WNW) ;
                 % second column
                 \draw [postaction={decorate}] (WE) to (NWWE) ;
                 \draw [postaction={decorate}] (NWWE) to (NW) ;
                 % third column
                  \draw [postaction={decorate}] (EWE) to (WENE) ;
                 \draw [postaction={decorate}] (WENE) to (NWNE) ;
                 \draw [postaction={decorate}] (NWNE) to (NWN) ;
                 % first column, bottom right to top left
                 \draw [postaction={decorate}] (NEE) to (EWE) ;
                % second column
                 \draw [postaction={decorate}] (NE) to (WENE) ;
                 \draw [postaction={decorate}] (WENE) to (WE) ;
                 % third column
                 \draw [postaction={decorate}] (NNE) to (NWNE) ;
                 \draw [postaction={decorate}] (NWNE) to (NWWE) ;
                 \draw [postaction={decorate}] (NWWE) to (WEW) ;
               \end {scope}
                \end {tikzpicture}
                </latex-image>
              </image>
            </figure>
          </proof>
        </theorem>
        <corollary xml:id="cor-cauchys-thm">
          <title>Cauchy's Theorem for star-shaped domains</title>
          <statement>
            <p>
              Suppose that <m>U</m> is star-shaped and <m>f\colon U \to \C</m> is analytic on <m>U</m>.
              Then for any closed contour <m>\gamma</m> in <m>U</m>, we have <m>\oint_\gamma f(z)\,dz = 0</m>.
            </p>
          </statement>
          <proof>
            <p>
              Apply <xref ref="thm-cauchy-triangles"/> to conclude that <m>f</m> integrates to <m>0</m> over any triangle in <m>U</m>.
              Then apply <xref ref="prop-triangles-antiderivative"/> to conclude that <m>f</m> has an antiderivative on <m>U</m>.
              Finally, we can apply <xref ref="thm-antiderivative-conditions"/> to conclude that 
              for any closed contour <m>\gamma</m> in <m>U</m>, we have <m>\oint_\gamma f(z)\,dz = 0</m>.
            </p>
          </proof>
        </corollary>
        <p>
          <alert>NB.</alert> Cauchy's Theorem holds for all simply connected domains, not just star-shaped domains.
          But notice that for example <m>\frac{1}{z}</m> integrates to a nonzero value over the unit circle,
          so Cauchy's Theorem does not extend to all domains.
        </p>
        <p>
          For a short proof of Cauchy's Theorem that uses Green's Theorem, see
          <xref ref="thm-Cauchy-green"/>.
        </p>
        <example xml:id="example-cauchy-two">
          <p>
            Suppose that <m>R</m> is the region bounded between two closed curves <m>\gamma_1</m>
          and <m>\gamma_2</m>, each oriented counterclockwise. (E.g. <m>R</m> could be an annulus.
          See <xref ref="fig-cauchy-two-curves"/>.)
          We will show that if <m>f</m> is analytic on <m>R</m> then
          <me>
            \int_{\gamma_1} f(z)\,dz = \int_{\gamma_2} f(z)\,dz.
          </me>
          </p>
          <p>
            Cut the region by <m>\gamma_3</m>, as shown in the figure.
            The slit region enclosed by the curve <m>\gamma_1 + \gamma_3 - \gamma_2 - \gamma_3</m>
            is simply connected, so we can apply Cauchy's Theorem to conclude that
          </p>
          <me>
            \int_{\gamma_1 + \gamma_3 - \gamma_2 - \gamma_3} f(z)\,dz = 0.
          </me>
          <p>
            But we decompose this using <xref ref="lem-integral-basic-props"/>:
          </p>
          <me>
            \int_{\gamma_1 + \gamma_3 - \gamma_2 - \gamma_3} = \int_{\gamma_1} + \int_{\gamma_3} + \int_{-\gamma_2} + \int_{-\gamma_3}
            = \int_{\gamma_1} - \int_{\gamma_2}
          </me>
          <figure width="50%" xml:id="fig-cauchy-two-curves-slit">
                <caption>Picture for <xref ref="example-cauchy-two"/>.</caption>
                <image xml:id="latex-cauchy-two-curves-slit">
                  <description>Picture for <xref ref="example-cauchy-two"/>.</description>
                  <latex-image>
                   \begin {tikzpicture} [outer sep = 0.5ex] 
                   % \clip (-3.1,-3.1) rectangle (3.1,3.1) ;
                    \begin {scope}[decoration={
                    markings,
                    mark=at position 0.2 with {\arrow{latex}},
                    mark=at position 0.55 with {\arrow{latex}},
                    mark=at position 0.85 with {\arrow{latex}},
                   }
                    ]
                     \draw [postaction=decorate] (1,0) circle (3) ;
                     \node [above] at ([shift={(1,0)}] 40 : 3) {$\gamma_1$} ;
                     \end {scope}
                      \begin {scope}[decoration={
                    markings,
                    mark=at position 0.2 with {\arrow{latex reversed}},
                    mark=at position 0.55 with {\arrow{latex reversed}},
                    mark=at position 0.85 with {\arrow{latex reversed}},
                   }
                    ]
                      \draw [postaction=decorate] (0,0) circle (1) ;
                     \node [above] at (40 : 1) {$-\gamma_2$} ;
                    \end {scope}
                     %%% ----- cut off here --------
                    \begin {scope}[decoration={
                    markings,
                    mark=at position 0.3 with {\arrow{latex}}}
                    ]
                     \draw [postaction=decorate] (4,0) to node [pos=0.6,above] {$-\gamma_3$} (1,0) ;
                     \draw [postaction=decorate] (1,0.05) to node [pos=0.6,below] {$\gamma_3$} (4,0.05) ;
                    \end {scope}
                    \draw [white] (1,0.01) -- (1,0.04) ;
                    \draw [white] (4,0.01) -- (4,0.04) ;
                   \end {tikzpicture}
                  </latex-image>
                </image>
              </figure>
        </example>
        <figure width="50%" xml:id="fig-cauchy-two-curves">
              <caption>Picture of curves <m>\gamma_1</m> and <m>\gamma_2</m>.</caption>
              <image xml:id="latex-cauchy-two-curves">
                <description>Picture of curves <m>\gamma_1</m> and <m>\gamma_2</m>.</description>
                <latex-image>
                 \begin {tikzpicture} [outer sep = 0.5ex] 
                 % \clip (-3.1,-3.1) rectangle (3.1,3.1) ;
                  \begin {scope}[decoration={
                  markings,
                  mark=at position 0.2 with {\arrow{latex}},
                  mark=at position 0.55 with {\arrow{latex}},
                  mark=at position 0.85 with {\arrow{latex}},
                 }
                  ]
                   \draw [postaction=decorate] (1,0) circle (3) ;
                   \node [above] at ([shift={(1,0)}] 40 : 3) {$\gamma_1$} ;
                   \end {scope}
                    \begin {scope}[decoration={
                  markings,
                  mark=at position 0.2 with {\arrow{latex}},
                  mark=at position 0.55 with {\arrow{latex}},
                  mark=at position 0.85 with {\arrow{latex}},
                 }
                  ]
                    \draw [postaction=decorate] (0,0) circle (1) ;
                   \node [above] at (40 : 1) {$\gamma_2$} ;
                  \end {scope}
                 \end {tikzpicture}
                </latex-image>
              </image>
            </figure>
          <example>
            <p>
              Let <m>f(z) = \frac{1}{z}</m>, defined on the punctured plane <m>\C \wo \{0\}</m>.
              What values can the integral <m>\int_\gamma f(z)\,dz</m> take on a simple closed curve <m>\gamma</m>?
            </p>
            <p>
              <alert>Case 1:</alert> <m>\gamma</m> does not encircle <m>0</m>.
              Then there is some curve <m>R</m> from the origin to <m>\infty</m> such that <m>\gamma</m> is completely
              contained in the slit plane <m>\C \wo R</m>, and there is a continuous branch of the log
              defined on <m>\C\wo R</m>. So in this case <m>\int_\gamma \frac{1}{z}\,dz = 0</m>,
              by <xref ref="thm-antiderivative-conditions"/>.
            </p>
            <p>
              <alert>Case 2:</alert> <m>\gamma</m> encircles <m>0</m>.
              Let <m>\gamma_\eps</m> be a tiny circle of radius <m>\eps</m> centered at <m>0</m>,
              so tiny that it lies entirely inside <m>\gamma</m> (and does not intersect <m>\gamma</m>).
              By <xref ref="example-cauchy-two"/> we have
              <m>\int_\gamma \frac{1}{z}\,dz = \int_{\gamma_\eps} \frac{1}{z}\,dz</m>, 
              and the latter integral (over the tiny circle) can be computed directly:
            </p>
            <md>
              <mrow> \int_\gamma \frac{1}{z}\,dz \amp = \int_{\gamma_\eps} \frac{1}{z}\,dz </mrow>
              <mrow> \amp = \int_0^{2\pi} \frac{1}{\epsilon e^{i\theta}}i \eps e^{i\theta} \,d\theta </mrow>
              <mrow> \amp = \int_0^{2\pi} i\,d\theta </mrow>
              <mrow> \amp = 2\pi i </mrow>
            </md>
            <p>
              So for a <em>simple</em> closed curve <m>\gamma</m>, the possible values of 
              <m>\int_\gamma \frac{1}{z}\,dz </m> are <m>2\pi i</m> and <m>0</m>, according to whether
              <m>\gamma</m> encircles the origin.
            </p>
            <p>
              But a non-simple curve can be divided into simple pieces!
              And then we can just add up the integrals. So the possible values of 
              <m>\int_\gamma \frac{1}{z}\,dz</m> are <m>2\pi i n</m>, <m>n\in\mathbb{Z}</m>.
              The <m>n</m> in this formula is called the <term>winding number</term> of <m>\gamma</m>
              and is the net number of times that <m>\gamma</m> crosses the positive <m>x</m>-axis.
              (Each time that <m>\gamma</m> crosses the positive <m>x</m>-axis from south to north contributes <m>+1</m>,
              each time that <m>\gamma</m> crosses the positive <m>x</m>-axis from north to south contributes <m>-1</m>.)
            </p>
            
          </example>
      </section>
      <section xml:id="sec-connections-to-multivariable">
        <title>Connections to multivariable calculus</title>
        <p>
          After reading the sections about contour integrals, you probably can't help noticing
          a strong resemblance to the theory of line integrals from multivariable calculus.
          First, notice that unlike a real line integral, the value of a contour integral <m>\int_\gamma f(z)\,dz</m>
          is a complex number, i.e., a point in the plane!
          The key to making connections to multivariable calculus is to decompose this into its real and
          imaginary parts:
        </p>
        <md>
          <mrow> f(\gamma(t))\gamma'(t) \amp = (u + iv)(x' + iy') </mrow>
          <mrow> \amp = (ux' - vy') + i(vx' + uy') </mrow>
          <mrow> \amp = (u(x(t),y(t))x'(t) - v(x(t),y(t))y'(t)) + i(v(x(t),y(t))x'(t) + u(x(t),y(t))y'(t)) </mrow>
        </md>
        <p>
          so we can use this to decompose the contour integral into two multivariable-calculus
          circulation integrals:
        </p>
        <md>
          <mrow> \int_a^b f(\gamma(t))\gamma'(t)\,dt \amp = \int_a^b \Re(f(\gamma(t))\gamma'(t))\,dt + i \int_a^b \Im(f(\gamma(t))\gamma'(t))\,dt </mrow>
          <mrow xml:id="re-im-integral" number="yes"> \amp = \int_a^b u\,dx - v\, dy + i\int_a^b v\,dx + u\,dy </mrow>
          <mrow> \amp = \int_\gamma \angs{u,-v} \cdot d\mathbf{r} + i\int_\gamma \angs{v,u}\cdot d\mathbf{r} </mrow>
        </md>
        <exercise>
          <p>
            Let <m>\bar\bF</m> be the vector field <m>\angs{u,-v}</m> associated to the conjugate of <m>f = u + iv</m>.
            Prove that
            <me>
              \int_\gamma f(z)\,dz = \operatorname{Work}(\bar\bF,\gamma) + i\operatorname{Flux}(\bar\bF,\gamma),
            </me>
            where
          </p>
          <md>
            <mrow> \operatorname{Work}(\bG,\gamma)	\amp =	\int_\gamma (\bG \cdot \bT) \, ds  \quad \text{and}</mrow>
            <mrow> \operatorname{Flux}(\bG,\gamma)	\amp =	\int_\gamma (\bG \cdot \bN) \, ds  </mrow>
          </md>
        </exercise>
        <p>
          Let's give an alternative proof of Cauchy's Theorem using Green's Theorem.
          (The reason for giving a separate, much longer, proof in class is that most of you haven't seen a 
          proof of Green's Theorem!)
        </p>
        <theorem xml:id="thm-Cauchy-green">
          <statement>
            <p>
              If <m>f</m> is analytic on a simply connected domain <m>D</m>, then <m>\int_\gamma f(z)\,dz = 0 </m>
              for every closed path <m>\gamma</m> in <m>D</m>.
            </p>
          </statement>
          <proof>
            <p>
              The key is <xref ref="re-im-integral"/>, which decomposes <m>\int_\gamma f(z)\,dz</m> into its
              real and imaginary parts. Each of those parts is a vector integral to which we can apply
              Green's Theorem. Writing <m>R</m> for the region enclosed by <m>\gamma</m>, we have the following.
            </p>
            <md>
              <mrow> \text{Real part:}\quad \int_\gamma u\,dx - v\,dy \amp = \iint_R (- v_x - u_y)\,dxdy = \iint 0 = 0 </mrow>
              <mrow> \text{Imaginary part:}\quad \int_\gamma v\,dx + u\,dy \amp = \iint_R (u_x - v_y)\,dxdy = \iint 0 = 0 </mrow>
            </md>
            <p>
              (Notice that we used the Cauchy–Riemann Equations in each line.)
              We conclude that <m>\int_\gamma f(z)\,dz = 0+0i = 0 </m>.
            </p>
          </proof>
        </theorem>
        <exercise xml:id="exercise-antiderivative-conditions-multi">
          <p>
            Give a proof along similar lines that a function <m>f\colon \C\to\C</m> that 
            integrates to <m>0</m> along every closed contour must have an antiderivative.
            Use the theorem from multivariable calculus that a circulation-free vector field must have a 
            potential function.
          </p>
        </exercise>
      </section>
      <section xml:id="sec-cauchy-integral-formula">
        <title>Cauchy's Integral Formula</title>
        <theorem xml:id="thm-cauchy-integral-formula">
          <statement>
            <p>
              Suppose that <m>\gamma</m> is a simple closed curve and <m>f</m>
              is analytic that includes <m>\gamma</m> and its interior.
              Assume that <m>\gamma</m> is counterclockwise-oriented.
              Then for all <m>z_0</m> inside <m>\gamma</m>,
            </p>
            <me>
              f(z_0) = \frac{1}{2\pi i} \oint_\gamma \frac{f(z)}{z - z_0} \,dz
            </me>
            or sometimes
            <me>
              f(z) = \frac{1}{2\pi i} \oint_\gamma \frac{f(w)}{w - z} \, dw
            </me>
          </statement>
        </theorem>
        <p>
          Knowing all values of <m>f</m> on <m>\partial D</m> gives you all 
          values of <m>f</m> in <m>D</m>!
          This is an incredible fact, which for the time being we will primarily use to evaluate integrals.
        </p>
        <example>
          <p>
            As a reality check, consider <m>f(z) = 1</m> and let <m>\gamma</m>
            parametrize the unit circle counterclockwise.
          </p>
          <me>
            1 = f(0) = \frac{1}{2\pi i} \int_{\abs{z} = 1} \frac{1}{z-0}\,dz = \frac{1}{2\pi i} 2\pi i
          </me>
        </example>
        <example>
          <p>
            Compute <m>\int_\gamma \frac{e^{z^2}}{z-2}\,dz</m>, for each of the following <m>\gamma</m>.
         </p>
          <p>
            First, suppose that <m>\gamma</m> parametrizes a circle centered at <m>z = 2</m>.
            Notice that <m>f(z) = e^{z^2}</m> is entire, so the Cauchy Integral Formula gives    
          </p>      
          <me>
            e^4 = f(2) = \frac{1}{2\pi i} \int_{\gamma} \frac{e^{z^2}}{z-2}\,dz,
          </me>
          <p>
            which we solve to see that the integral is <m>2\pi i e^4</m>.
          </p>
          <p>
            Next, suppose that <m>\gamma</m> is completely included in the first quadrant <m>\Re(z) > 0,</m> <m>\Im(z) > 0</m>.
            (In fact, the following analysis will apply to any curve <m>\gamma</m> that does not encircle <m>2</m>.)
            Then the integrand <m>\frac{e^{z^2}}{z-2}</m> is analytic on (the star-shaped region) <m>\set{z}{\Re(z) > 0, \Im(z) > 0}</m>,
            so Cauchy's Theorem implies that <m>\int_\gamma \frac{e^{z^2}}{z-2}\,dz = 0</m>.
          </p>
          <p>
            <!--TODO: add figure-->
            Let <m>\gamma</m> be the curve that winds clockwise twice around <m>2</m>, as pictured.
            Then we can divide <m>\gamma</m> into two simple pieces <m>\gamma_1</m> and <m>\gamma_2</m>
            and apply the Cauchy Integral Formula to each piece:
          </p>
          <me>
            \int_\gamma \frac{e^{z^2}}{z-2}\,dz = \int_{\gamma_1} \frac{f(z)}{z-2}\,dz + \int_{\gamma_2} \frac{f(z)}{z-2}\,dz
            = -2\pi i f(2) - 2\pi i f(2) = -4 \pi i e^4.
          </me>
        </example>
        <theorem xml:id="thm-cauchy-improvement">
          <title>Improvement of Cauchy's Theorem</title>
          <statement>
            <p>
              Suppose that <m>D</m> is a simply connected domain, <m>z_0 \in D</m>, and <m>g</m>
              is analytic on <m>D \wo \{z_0\}</m> and continuous at <m>z_0</m>.
              Then <m>\oint_\gamma g(z)\,dz = 0</m> for all closed curves <m>\gamma</m> in <m>D</m>.
            </p>
          </statement>
          <proof>
            <p>
              (In fact, under these hypotheses, <m>g</m> must be analytic at <m>z_0</m>,
              as we will see later in <xref ref="prop-removal-singularities"/>.)
            </p>
            <p>
               Since <m>z_0</m> is inside <m>\gamma</m>, there is a small <m>\eps_0 \gt 0</m>
               such that the disk <m>B_{\eps_0}(z_0)</m> lies completely inside <m>\gamma</m>.
               Since <m>g</m> is continuous, <m>\abs{g(z)}</m> is bounded on the interior 
               of <m>\gamma_{\eps_0}</m>; say <m>\abs{g(z)} \le M</m> on <m>B_\eps(z_0)</m>.
               <aside>
                <p>
                  The point of this <m>\eps_0</m> business is that we need a <em>fixed</em> bound
                  <m>M</m> in order to conclude that <m>ML</m> goes to <m>0</m> as <m>\eps</m>
                  goes to <m>0</m>.
                </p>
               </aside>

               Consider <m>\eps \lt \eps_0</m>.
               <xref ref="example-cauchy-two"/> implies that
               <m>\oint_\gamma g(z)\,dz = \oint_{\gamma_\eps} g(z)\,dz</m>, where
               <m>\gamma_\eps</m> is a circle of radius <m>\eps</m> centered at <m>z_0</m>.
               Now we just do an ML-estimate:
            </p>
            <me>
              \abs{\oint_\gamma g(z)\,dz} \le M(2\pi \eps) \underset{\eps \to 0}{\longrightarrow} 0.
            </me>
            <p>
              This completes the proof.
            </p>
          </proof>
        </theorem>
        <proof>
          <title>Proof of the Cauchy Integral Formula</title>
          <p>
            Consider the following function.
          </p>
          <me>
            g(z) = \begin {cases} \frac{f(z) - f(z_0)}{z - z_0} \amp z \ne z_0 \\
            f'(z_0) \amp z = z_0
            \end {cases}
          </me>
          <p>
            Since <m>f</m> is differentiable at <m>z_0</m>, this function <m>g</m> is 
            continuous at <m>z_0</m>.
            <aside>
              <p>
                This is a common trick used to prove theorems about derivatives
                in real analysis.
              </p>
            </aside>
            By <xref ref="thm-cauchy-improvement"/>, we have 
          </p>
          <me>
            \oint_\gamma g(z)\,dz = \oint_\gamma \frac{f(z) - f(z_0)}{z - z_0} \,dz = 0.
          </me>
          <p>
            Rearrange this to get
          </p>
          <me>
            \oint_\gamma \frac{f(z)}{z - z_0} \,dz 
            = \oint_\gamma \frac{f(z_0)}{z - z_0} \, dz 
            = f(z_0) \oint_\gamma \frac{1}{z-z_0}\,dz
            = f(z_0) \cdot 2\pi i
          </me>
          <p>
            (The last equality follows from our computation of <m>\oint \frac{1}{z} \, dz</m>)
            over a circle centered at the origin; do the substitution <m>u = z - z_0</m>.)
          </p>
        </proof>
        <theorem xml:id="thm-cauchy-integral-formula-deriv">
          <title>The Cauchy Integral Formula for Derivatives</title>
          <statement>
            <p>
              Suppose that <m>\gamma</m> is a simple closed curve and <m>f</m>
              is analytic that includes <m>\gamma</m> and its interior.
              Assume that <m>\gamma</m> is counterclockwise-oriented.
              Then for all <m>z</m> inside <m>\gamma</m>,
              the <m>n</m>th derivative <m>f^{(n)}(z)</m> exists and satisfies the following formula.
            </p>
            <me>
              f^{(n)}(z) = \frac{n!}{2\pi i} \oint_\gamma \frac{f(w)}{(w - z)^{n+1}} \, dw
            </me>
          </statement>
          <proof>
            <p>
              This is the <em>idea</em>:
            </p>
            <me>
              f'(z) = \frac{d}{dz} \left( \frac{1}{2\pi i} \oint_\gamma \frac{f(w)}{w - z}\,dw \right)
              = \frac{1}{2\pi i} \oint_\gamma \frac{d}{dz} \frac{f(w)}{w - z}\,dw
              = \frac{1}{2\pi i} \oint_\gamma \frac{f(w)}{(w - z)^2}
            </me>
            <p>
              And then you iterate to obtain the formula for <m>f^{(n)}(z)</m>.
              But the second equality above requires justification.
            </p>
            <p>
              OK, here's what we actually need to do:
            </p>
            <md>
              <mrow> \frac{f(z+\Delta z) - f(z)}{\Delta z} \amp = \frac{1}{2\pi i \Delta z} \oint_\gamma \frac{f(w)}{w - z - \Delta z} - \frac{f(w)}{w - z} \,dw </mrow>
              <mrow> \amp = \frac{1}{2\pi i} \oint_\gamma \frac{f(w)}{(w - z)^2 - \Delta z(w - z)} \, dw </mrow>
              <mrow> \amp \underset{\Delta z \to 0}{\longrightarrow} \frac{1}{2\pi i} \oint_\gamma \frac{f(w)}{(w - z)^2} \, dw </mrow>
            </md>
            <p>
              (There is no problem taking a limit under the integral sign, since everything is continuous
              and the denominator is nonzero.)
            </p>
          </proof>
        </theorem>
        <corollary xml:id="cor-analytic-derivatives">
          <statement>
            <p>
              If <m>f</m> is analytic on <m>D</m>, then <m>f</m> has derivatives
              of all orders on <m>D</m>!
            </p>
          </statement>
        </corollary>
        <p>
          Now let's do several examples.
        </p>
        <example>
          <me>
            \oint_{\abs{z} = 1} \frac{e^{2z}}{z^4}\,dz = \frac{2\pi i}{3!} \left[\frac{d^3}{d^3z} e^{2z} \right]_{z=0}
            = \frac{8}{3} \pi i.
          </me>
        </example>
        <example>
          <p>
            Compute <m>\oint_\gamma \frac{1}{(z^2 + 4)^2}\, dz</m>.
          </p>
         <figure width="50%" xml:id="CIF-example-1-image">
          <image source="CIF-derivs-1" width="50%">
            <description>Picture of curve for example</description>
          </image>
          <caption>A picture of <m>\gamma</m> for the example.</caption>
         </figure>
         <p>
          We factor <m>(z^2 + 4)^2 = (z+2i)^2 (z-2i)^2</m> and notice that <m>\gamma</m>
          encircles one singularity <m>z = 2i</m> but not the other.
          So we define <m>f(z) = \frac{1}{(z + 2i)^2}</m>, notice that <m>f</m>
          is analytic on <m>\gamma</m> and its interior,
          and apply the Cauchy Integral Formula for Derivatives:
         </p>
         <md>
          <mrow> \oint_\gamma \frac{1}{(z^2 + 4)^2}\,dz \amp = \oint_\gamma \frac{f(z)}{(z - 2i)^2}\,dz </mrow>
          <mrow> \amp = 2\pi i f'(2i) </mrow>
          <mrow> \amp = 2\pi i \left[ \frac{-2}{(z + 2i)^3} \right]_{z = 2i} </mrow>
          <mrow> \amp = \frac{4\pi i}{64 i}  = \frac{\pi}{16}</mrow>
         </md>
        </example>
        <example>
          <p>
            Compute <m>\oint_\gamma \frac{z}{z^2 + 4} \,dz</m>, where <m>\gamma</m> is the 
            curve pictured below.
          </p>
          <image source="CIF-derivs-2" width="50%">
            <description>curve for example</description>
          </image>
          <p>
            Now <m>\gamma</m> encircles both singularities! So we can't just do what we
            did in the previous example.
            So we split the curve in two like this:
          </p>
          <image source="CIF-derivs-2b" width="50%">
            <description>image for example</description>
          </image>
          <p>
            Define <m>f_1(z) = \frac{z}{z + 2i}</m> and <m>f_2(z) = \frac{z}{z-2i}</m>,
            so that
          </p>
          <me>
            f(z) = \frac{z}{z^2 + 4} = \frac{f_1(z)}{z - 2i} = \frac{f_2(z)}{z + 2i}.
          </me>
          <p>
            Now we can split up the integral so that we integrate around the two singularities
            separately:
          </p>
          <md>
            <mrow> \oint_\gamma \frac{z}{z^2 + 4}\,dz \amp = \oint_{\gamma_1 + \gamma_3 - \gamma_3 + \gamma_2} \frac{z}{z^2 + 4}\,dz </mrow>
            <mrow> \amp = \oint_{\gamma_1 + \gamma_2} \frac{f_1(z)}{z - 2i}\,dz + \oint_{\gamma_2 - \gamma_3} \frac{f_2(z)}{z + 2i}\,dz </mrow>
            <mrow> \amp = 2\pi i(f_1(2i) + f_2(2i)) </mrow>
            <mrow> \amp = 2\pi i </mrow>
          </md>
          <p>
            It is worth noting that we could've used partial fractions instead:
            <m>\frac{z}{(z-2i)(z+2i)} = \frac{a}{z - 2i} + \frac{b}{z + 2i}</m>.
            Later, we will see how to do this kind of example much more systematically
            using residue theory.
          </p>
        </example>
      </section>
      <section xml:id="sec-applications-cif">
        <title>Applications of the Cauchy Integral Formula</title>
        <theorem xml:id="thm-cauchy-estimates">
          <statement>
            <p>
              Write <m>C_R</m> for the circle of radius <m>R</m> centered at <m>z_0</m>.
              Suppose that <m>f</m> is analytic on <m>C_R</m> and its interior,
              and put <m>M_R = \max\limits_{z\in C_R} \abs{f(z)}</m>.
              Then, for <m>n =1,2,3,\dots</m>,
            </p>
            <me>
              \abs{ f^{(n)}(z_0)} \le \frac{n! M_R}{R^n}.
            </me>
          </statement>
          <proof>
            <p>
              This is just a matter of combining the Cauchy Integral Formula for Derivatives
              with an ML-estimate:
            </p>
              <md>
                <mrow> \abs{f^{(n)}(z_0)} \amp = \abs{\frac{n!}{2\pi i} \oint_{C_R} \frac{f(z)}{(z-z_0)^{n+1}} \, dz} </mrow>
                <mrow> \amp \le \frac{n!}{2\pi} \oint_{C_R} \frac{\abs{f(z)}}{\abs{z-z_0}^{n+1}}\,\abs{dz} </mrow>
                <mrow> \amp \le \frac{n!}{2\pi} \cdot \frac{M_R}{R^{n+1}} \oint_{C_R} \abs{dz} </mrow>
                <mrow> \amp =  \frac{n!}{2\pi} \cdot \frac{M_R}{R^{n+1}} \cdot 2\pi R </mrow>
                <mrow> \amp = \frac{n! M_R}{R^n} </mrow>
              </md>
          </proof>
        </theorem>
        <definition xml:id="def-bounded">
          <statement>
            <p>
              A function <m>f\colon D\to\C</m> is <term>bounded</term>
              if there is a real number <m>B</m> for which <m>\abs{f(z)} \le B</m> for all <m>z\in D</m>.
            </p>
          </statement>
        </definition>
        <theorem xml:id="thm-liouville">
          <title>Liouville's Theorem</title>
          <statement>
            <p>
              A bounded entire function must be constant.
            </p>
          </statement>
          <proof>
            <p>
              Suppose that <m>\abs{f(z)} \lt M</m> on all of <m>\C</m>.
              Then for every circle <m>C_R</m>, we have by <xref ref="thm-cauchy-estimates"/>
            <me>
              \abs{f'(z_0)} \le \frac{M}{R}
            </me>
          </p>
          <p>
            But then <m>M</m> is fixed, and we could have chosen <m>R</m> to be as large as we like, so <m>f'(z_0) = 0</m>.
            So <xref ref="lem-deriv-zero-constant"/> implies that <m>f</m> must be constant.
          </p>
          </proof>
        </theorem>
        <p>
          <alert>NB.</alert> Polynomials, <m>e^z</m>, sine, cosine (!), etc., are all entire but not bounded.
        </p>
        <corollary xml:id="cor-FTA">
          <title>The Fundamental Theorem of Algebra</title>
          <statement>
            <p>
              Every nonconstant polynomial <m>p(z)</m> with complex coefficients has a root in <m>\C</m>.
            </p>
          </statement>
          <proof>
            <p>
              Write
              <me>
                p(z) = a_n z^n + a_{n-1} z^{n-1} + \cdots + a_1 z + a_0.
              </me>
              Suppose toward a contradiction that <m>p(z)</m> does not have a complex root, so that <m>\frac{1}{p(z)}</m> is entire. 
            </p>
            <claim xml:id="claim-FTA-bounded">
              <statement>
                <p>
                  <m>\frac{1}{p(z)}</m> is bounded.
                </p>
              </statement>
              <proof>
                <p>
                  This is the idea:
                </p>
                <me>
                  \frac{p(z)}{z^n} = a_n + \frac{a_{n-1}}{z} + \frac{a_{n-2}}{z^2} + \cdots + \frac{a_0}{z^n} \underset{\abs{z}\to\infty}{\longrightarrow} a_n.
                </me>
                <p>
                  Here is a bit more detail. Fixing <m>\eps \gt 0</m>, find an <m>R \gt 0</m> for which the inequality
                <me>
                  \abs{\frac{p(z)}{z^n} - a_n} = \abs{ \frac{a_{n-1}}{z} + \frac{a_{n-2}}{z^2} + \cdots + \frac{a_0}{z^n} } \lt \eps
                </me>
                holds for all <m>z</m> with <m>\abs{z} \gt R</m>.
                Notice that now <m>\abs{z} \gt R</m> implies <m>\abs{\frac{1}{p(z)}} \lt \frac{1}{\abs{a_n} R^n} + \eps</m>.
                We have found a bound for <m>\frac{1}{p(z)}</m> for <m>\abs{z} \gt R</m>.
                Now remember that <m>z\mapsto \abs{\frac{1}{p(z)}}</m> is a continuous function on the compact ball <m>\abs{z} \le R</m>
                and is therefore bounded. Combine these two bounds to see that <m>\frac{1}{p(z)}</m> is bounded on <m>\C</m>.
              </p>               
              </proof>
            </claim>
            Now apply <xref ref="thm-liouville"/> to see that <m>\frac{1}{p(z)}</m> must be constant.
            So <m>p(z)</m> must be constant, oops.
          </proof>
        </corollary>

        <theorem xml:id="thm-mean-value">
          <title>The Mean Value Property for Analytic Functions</title>
          <statement>
            <p>
              The value of an analytic function <m>f</m> at <m>z_0</m> is the average value of <m>f</m> on a small circle centered at <m>z_0</m>.
            </p>
            <p>
              More precisely, suppose that <m>f</m> is analytic on a domain that includes the closed disk <m>\abs{z - z_0} \le r</m>.
              Then
            </p>
            <me>
              f(z_0) = \frac{1}{2\pi} \int_0^{2\pi} f(z_0 + re^{i\theta})\,d\theta.
            </me>
          </statement>
          <proof>
            <p>
              This is just what you get by applying the Cauchy Integral Formula to <m>C_r</m>, the circle of radius <m>r</m> centered at <m>z_0</m>,
              and parametrizing the circle to compute the integral:
            </p>
            <md>
              <mrow> f(z_0) \amp = \frac{1}{2\pi i} \oint_{C_r} \frac{f(z)}{z-z_0} \,dz </mrow>
              <mrow> \amp = \frac{1}{2\pi i} \int_0^{2\pi} \frac{f(z+re^{i\theta})}{re^{i\theta}} ire^{i\theta}\,d\theta </mrow>
              <mrow> \amp = \frac{1}{2\pi} \int_0^{2\pi} f(z+re^{i\theta})\,d\theta </mrow>
            </md>
            <p>
              This completes the proof.
            </p>
          </proof>
        </theorem>
          <!--https://www.geogebra.org/calculator/abqahkay-->
          <figure xml:id="fig-geogebra-mean-value">
            <caption>GeoGebra: Parametrization for the Mean Value Property</caption>
            <interactive xml:id="geogebra-mean-value" platform="geogebra" width="80%" aspect="1:1">
                <slate xml:id="mean-value" surface="geogebra" material="https://www.geogebra.org/calculator/abqahkay" aspect="1:1">
                   <!--setCoordSystem(-5,5,-5,5);-->
                  <!-- centerView((0,0)); -->
                  <!--enableShiftDragZoom(false);-->
                </slate>
              <instructions>
                <p> 
                 You can view a larger version of this <url href="https://www.geogebra.org/calculator/abqahkay">here</url>.
                </p>
              </instructions>
            </interactive>
            </figure>
            <subsection xml:id="subsec-mmp">
              <title>The Maximum Modulus Principle</title>
              <lemma xml:id="lem-max-mod">
                <statement>
                  <p>
                    Suppose that <m>f</m> is analytic on <m>B_r(z_0)</m> and <m>\abs{f}</m>
                    achieves its maximum at <m>z_0</m>. Then <m>f</m> must be constant on <m>B_r(z_0)</m>. 
                  </p>
                </statement>
                <aside>
                  <p>
                    <!--TODO: add picture-->
                    So for example an open disk cannot be mapped by <m>f</m>
                    to a non-open set. But this is for a more fundamental reason:
                    nonconstant analytic functions are <term>open mappings</term>.
                  </p>
                </aside>
                <proof>
                  <p>
                    Fix <m>\eps \lt r</m>. Use the Mean Value Property and the fact that
                    <m>\abs{f}</m> achieves its maximum at <m>z_0</m>:
                  </p>
                  <md>
                    <mrow> \abs{f(z_0)} \amp = \abs{ \frac{1}{2\pi} \int_0^{2\pi} f(z_0 + \eps e^{i\theta})\,d\theta } </mrow>
                    <mrow> \amp \le \frac{1}{2\pi} \int_0^{2\pi} \abs{f(z_0 + \eps e^{i\theta})}\,d\theta </mrow>
                    <mrow> \amp \le \frac{1}{2\pi} \int_0^{2\pi} \abs{f(z_0)}\,d\theta </mrow>
                    <mrow> \amp = \frac{1}{2\pi} 2\pi \abs{f(z_0)} </mrow>
                  </md>
                  <p>
                    So <m>\abs{f(z_0)} = \frac{1}{2\pi} \int_0^{2\pi} \abs{f(z_0 + \eps e^{i\theta})}\,d\theta</m>,
                    i.e.,
                  </p>
                  <me>
                    \int_0^{2\pi} \abs{f(z_0+\eps e^{i\theta})} - \abs{f(z_0)}\,d\theta = 0.
                  </me>
                  <p>
                  The integrand <m>\abs{f(z_0+\eps e^{i\theta})} - \abs{f(z_0)}</m> is a continuous
                  nonnegative real-valued function on <m>[0,2\pi]</m> that integrates to <m>0</m>.
                  Thus this function must be <m>0</m>, by a standard argument in real analysis.
                  So <m>\abs{f(z_0)} = \abs{f(z_0 + \eps e^{i\theta})}</m> for all <m>\theta \in [0,2\pi]</m>.
                  </p>
                  <p>
                    Remember that <m>\eps \lt r</m> was arbitrary. So <m>\abs f</m> is constant on <m>B_r(z_0)</m>.
                    So <m>f</m> must be constant on <m>B_r(z_0)</m>, by <xref ref="cor-modulus-const"/>.
                  </p>
                </proof>
              </lemma>
              <theorem xml:id="thm-max-mod-principle">
                <title>The Maximum Modulus Principle</title> 
                <statement>
                  <p>
                    If <m>f</m> is analytic on a domain <m>D</m> and <m>\abs{f}</m>
                    achieves its maximum value on <m>D</m>, i.e., there is <m>z_0 \in D</m>
                    such that <m>\abs{f(z)} \le \abs{f(z_0)}</m>  for all <m>z\in D</m>,
                    then <m>f</m> must be constant.
                  </p>
                </statement>
                <proof>
                  <p>
                    Use <xref ref="lem-max-mod"/> and polygonal paths,
                    imitating part of the proof of <xref ref="lem-deriv-zero-constant"/>.
                  </p>
                </proof>
              </theorem>
              <corollary xml:id="cor-max-mod">
                <statement>
                  <p>
                    Suppose that <m>f</m> is continuous on a closed bounded region <m>R</m>
                    and analytic in the interior of <m>R</m>.
                    Then either <m>f</m> is constant on <m>R</m>, or
                    <m>\abs{f}</m> achieves its maximum (as it must!) on <m>\partial R</m>
                    and never in the interior of <m>R</m>.
                  </p>
                </statement>
                <proof>
                  <p>
                    This is just because the interior of <m>R</m> is a domain.
                    Just apply the previous theorem.
                  </p>
                </proof>
              </corollary>
              <example>
                <p>
                  Find the maximum modulus of <m>e^z</m> on the unit square <m>[0,1]\times[0,1]</m>.
                </p>
                <p>
                  Notice that <m>\abs{e^z} = \abs{e^{x + iy}} = e^x</m> is maximal when <m>x = 1</m>,
                  on the boundary of the square.
                </p>
              </example>
            </subsection>
        
      </section>

    </chapter>
    <chapter xml:id="ch-taylor-laurent-series">
      <title>Taylor and Laurent Series</title>
      <section xml:id="sec-taylor-series">
        <title>Taylor Series</title>
        <p>
          Much of the general theory of series can be imported from real analysis with 
          no material changes.
        </p>
        <theorem xml:id="thm-power-series-basic">
          <statement>
            <p>
              Consider the (complex) power series <m>f(z) = \sum_{n\ge 0} c_n (z-a)^n</m>.
              There is a number <m>R \ge 0</m>, called the <term>radius of convergence</term> of <m>f</m> at <m>a</m>,
              for which the following facts hold.
            </p>
            <ol marker="(i)">
              <li>
                <p>
                  If <m>R \gt 0</m> then the series converges absolutely to an analytic
                  function on <m>B_R(a)</m>, the <term>disk of convergence</term> of <m>f</m> at <m>a</m>.
                </p>
                <aside>
                  <p> And for <m>r \lt R</m> the series converges uniformly to its limiting function.
                    You can ignore this if you haven't seen uniform convergence of functions before.
                  </p>
                </aside>
              </li>
              <li>
                <p>
                  The series diverges for <m>\abs{z - a} \gt R</m>.
                </p>
              </li>
              <li>
                <p>
                  The derivative <m>f'</m> is given on <m>B_R(a)</m> by term-by-term differentiation:
                <me>
                  f'(z) = \sum_{n \ge 1} n c_n (z-a)^{n-1}
                </me>
                and also has radius of convergence <m>R</m>.
              </p> 
              </li>
              <li>
                <p>
                  We can integrate term by term too.
                  If <m>\gamma</m> is a contour inside the disk of convergence, then 
                </p>
                <me>
                  \int_\gamma f(z)\,dz = \sum_{n\ge 0} \int_\gamma c_n (z - a)^n\,dz.
                </me>
              </li>
              <li>
                <p>
                  In fact the radius of convergence is given by the Root Test:
                </p>
                <me>
                  R = \frac{1}{\limsup \sqrt[n]{\abs{c_n}}},
                </me>
                <aside>
                  <p>
                    If you haven't seen limsups before, then take this slightly weaker statement:
                    if <m>\lim \sqrt[n]{\abs{c_n}}</m> exists,
                    then <m>R = \frac{1}{\limsup \sqrt[n]{\abs{c_n}}}</m>.
                  </p>
                </aside>
                <p>
                  (interpreted as <m>0</m> or <m>\infty</m> as appropriate).
                </p>
              </li>
            </ol>
          </statement>
        </theorem>
        <p>
          <alert>NB.</alert> <xref ref="thm-power-series-basic"/> does not give any general information about
          the convergence of the power series on the <em>boundary</em> of its disk of convergence,
          i.e., <m>\abs{z - a} = R</m>.
          Notice also that, unlike in real analysis, the boundary of the disk of convergence includes
          a whole continuum of points, not just two!
        </p>
        
        <theorem xml:id="thm-taylor">
          <title>Taylor's Theorem</title>
          <statement>
            <p>
              Suppose that <m>f\colon B_r(a) \to \C</m> is analytic.
              Then <m>f</m> has, on <m>B_r(a)</m>, a convergent power series expansion
              <me>
                f(z) = \sum_{n\ge 0} c_n (z-a)^n
              </me>
              centered at <m>a</m>, with coefficients given by
              <me>
                c_n = \frac{f^{(n)}(a)}{n!} = \frac{1}{2\pi i} \oint_{\partial B_\rho(a)} \frac{f(w)}{(w-a)^{n+1}}\,dw
              </me>
              for any <m>\rho \lt r</m>.
            </p>
          </statement>
          <proof>
            <p>
              Suppose <m>\rho \lt r</m> and <m>z\in B_\rho(a)</m>. Apply the Cauchy Integral Formula:
            </p>
            <men xml:id="eqn-taylor">
              f(z) = \frac{1}{2\pi i} \oint_{\partial B_\rho(a)} \frac{f(w)}{w - z} \,dw .
            </men>
            <p>
              Now we use a non-obvious trick. Expand the factor <m>\frac{1}{w-z}</m> in the integrand
              into a geometric series, which converges uniformly in <m>w \in \partial B_\rho(a)</m> since <m>\abs{\frac{z-a}{w-a}} = \frac{\abs{z-a}}{\rho} \lt 1</m>:
            </p>
            <me>
              \frac{1}{w-z} = \frac{1}{(w-a)\left( 1 - \frac{z-a}{w-a} \right)} = \frac{1}{w-a} \sum_{n\ge 0} \frac{(z-a)^n}{(w-a)^{n}}
              = \sum_{n\ge 0} \frac{(z-a)^n}{(w-a)^{n+1}}
            </me>
            <p>
              Using this to replace the <m>\frac{1}{w-z}</m> in <xref ref="eqn-taylor"/> with a series
              and using the uniformity of the convergence to interchange a sum and an integral gives the following.
            </p>
            <md>
              <mrow> f(z) \amp = \frac{1}{2\pi i} \oint_{\partial B_\rho(a)} \frac{f(w)}{w - z}\,dz </mrow>
              <mrow> \amp = \frac{1}{2\pi i} \oint_{\partial B_{\rho(a)}} \sum_{n\ge 0} \frac{f(w) (z-a)^n}{(w-a)^{n+1}}\,dw </mrow>
              <mrow> \amp = \sum_{n\ge 0} \left( \frac{1}{2\pi i} \oint_{\partial B_{\rho}(a)} \frac{f(w)}{(w-a)^{n+1}}\,dw \right) (z-a)^n</mrow>
              <mrow> \amp = \sum_{n\ge 0} c_n (z-a)^n </mrow>
            </md>
            <p>
              This is exactly what we wanted to show.
            </p>
          </proof>
        </theorem>
        <corollary xml:id="cor-taylor-coefficients-unique">
          <statement>
            <p>
              If <m>\sum_{n\ge 0} c_n (z-a)^n</m> and <m>\sum_{n\ge 0} d_n (z-a)^n</m> are two power series
              that converge to the same function on an open disk centered at <m>a</m>, then 
              <m>c_n = d_n</m> for all <m>n\ge 0</m>.
            </p>
          </statement>
          <proof>
            <p>
              (This is not really a corollary to the previous theorem. But it is important to note that 
              the Taylor coefficients given in that theorem are unique.)
            </p>
            <p>
              If the two series converge to <m>f</m> on <m>B_r(a)</m>, then (exercise) they are analytic there.
              (You can differentiate term by term.)
              So we must have <m>f(a) = c_0 = d_0</m>, <m>f'(a) = c_1 = d_1</m>, <m>f''(a) = 2c_2 = 2d_2</m>, etc.
              (Proceed by induction.)
            </p>
          </proof>
        </corollary>
        <corollary xml:id="cor-infinitely-differentiable">
          <statement>
            <p>
              If <m>f</m> is analytic on a domain, then it is infinitely differentiable on that domain.
            </p>
          </statement>
        </corollary>
        <corollary xml:id="cor-morera">
          <title>Morera's Theorem</title>
          <aside>
            <p>
              This is a nice part of the theory, but we are much more interested in theorems that
              tell us facts about analytic functions than in those that tell us when a function is analytic.
            </p>
          </aside>
          <statement>
            <p>
              If <m>f</m> is continuous on a domain <m>U</m> and <m>\oint_\gamma f(z)\,dz = 0</m> for all closed contours
              <m>\gamma</m> in <m>U</m>, then <m>f</m> is analytic on <m>U</m>.
            </p>
          </statement>
          <proof>
            <p>
              We can apply <xref ref="thm-antiderivative-conditions"/> to conclude that <m>f</m> has an antiderivative
              <m>F</m> on <m>U</m>. But then <m>F</m> is infinitely differentiable on <m>U</m>, so <m>f</m> is 
              analytic on <m>U</m>.
            </p>
          </proof>
        </corollary>
        <corollary xml:id="cor-roc-distance">
          <statement>
            <p>
              If <m>f</m> is analytic on a domain <m>U</m> and <m>z_0 \in U</m>, then <m>f</m> has a 
              power series expansion centered at <m>z_0</m> with radius of convergence at least the distance
              from <m>z_0</m> to <m>\partial U</m>.
            </p>
          </statement>
        </corollary>
        <p>
          The <term>distance</term> from a point <m>z</m> to a closed set <m>G</m> is defined 
          to be the minimum <m>\min\set{ \abs{w - z} }{ w \in G}</m> when this minimum exists.
          Notice that if <m>z \notin G</m>, then the function <m>w \mapsto \abs{w - z}</m> is continuous
          and takes only positive values so must achieve a positive minimum value if <m>G</m> is compact
          (= closed and bounded).
          </p>
        <example>
          <p>
            Let's compute the Taylor series expansion of the exponential function <m>f(z) = e^z</m> centered
            at <m>a = 0</m>.
            Since the exponential map is entire, we know in advance that the Taylor series will
            have infinite radius of convergence.
          </p>
          <p>
            All derivatives of <m>f</m> are the same: <m>f(z) = f'(z) = \cdots = e^z</m>.
            So the <m>n</m>th Taylor coefficient is <m>\frac{f^{(n)}(0)}{n!} = \frac{1}{n!}</m>, and the series
            is given by
          </p>
          <me>
            e^z = 1 + z + \frac{z^2}{2!} + \frac{z^3}{3!} + \cdots = \sum_{n\ge 0} \frac{z^n}{n!}.
          </me>
          <p>
            Great, this is the same as the series for the real exponential! This is not a coincidence.
          </p>
        </example>
        <example>
          <p>
            Compute the Taylor series expansion of <m>f(z) = z^8 e^{3z}</m> around <m>a = 0</m>.
          </p>
          <p>
            Just plug <m>3z</m> in for <m>z</m> in the Taylor series for <m>e^z</m> and multiply by <m>z^8</m>:
          </p>
          <md>
            <mrow> e^{3z} \amp = \sum_{n\ge 0} \frac{3^n}{n!} z^n </mrow>
            <mrow> f(z) \amp = \sum_{n\ge 0} \frac{3^n}{n!} z^{n+8} </mrow>
          </md>
        </example>
        <example>
          <p>
            Compute the power series expansion of <m>f(z) = \sin(z)</m> centered around <m>a = 0</m>.
          </p>
          <p>
            <alert>Method 1:</alert>
            Compute derivatives of <m>\sin(z)</m>:
          </p>
          <me>
            f^{(n)}(0) = \frac{d^n \sin(z)}{dz^n} = \begin {cases} (-1)^m \amp \text{ if } n = 2m+1 \\ 0 \amp \text{ if }n \text{ is even } \end {cases}
          </me>
          <p>
            Then use the formula.
          </p>
          <p>
            <alert>Method 2:</alert>
            Recall that <m>\sin(z) = \frac{e^{iz} - e^{-iz}}{2i}</m>, so we can use the series for <m>e^z</m>:
          </p>
          <md>
            <mrow> \sin(z) \amp = \frac{1}{2i} \left[ \sum_{n\ge 0} \frac{(iz)^n}{n!} - \sum_{n\ge 0} \frac{(-iz)^n}{n!} \right] </mrow>
            <mrow> \amp = \frac{1}{2i} \sum_{n\ge 0} (1 - (-1)^n) \frac{i^n z^n}{n!} </mrow>
            <mrow> \amp = \sum_{k\ge 0} (-1)^k \frac{z^{2k+1}}{(2k+1)!} </mrow>
          </md>
          <p>
            This series converges for all <m>z</m>. (This follows either from the fact that <m>\sin(z)</m> is entire,
            or from the fact that we built the series from the Taylor series for <m>e^z</m>, which converges everywhere.)
          </p>
        </example>
        <example>
          <p>
            Compute the Taylor series expansion for <m>f(z) = \frac{1}{1 - z}</m> around <m>a = 5</m>.
            We should observe in advance that this series will have radius of convergence <m>4</m>, the distance
            to the nearest singularity at <m>z = 1</m>!
          </p>
          <p>
            You can compute derivatives and use the formula, but it is easier to just recognize that 
            we will get a geometric series and use an algebraic trick:
          </p>
          <me>
            f(z) = \frac{1}{-4(1 + \frac{z-5}{4})} = \frac{-1}{4} \left( 1 - \left( \frac{z-5}{4} \right) + \left( \frac{z-5}{4} \right)^2 - \left( \frac{z-5}{4} \right)^3 + \cdots \right)
          </me>
          <p>
            This series converges iff <m>\abs{\frac{z-5}{4}}\lt 1</m>, i.e., when <m>\abs{z - 5} \lt 4</m>, as predicted.
          </p>
        </example>
        <example>
          <p>
            Compute the Taylor series expansion of <m>f(z) = \Log(1+z)</m> centered at <m>a = 0</m>.
          </p>
          <p>
            We first observe that the branch cut starts at <m>z = -1</m>,
            which is the nearest point (to <m>0</m>) at which <m>f</m> is not analytic.
            So the radius of convergence is <m>1</m>.
          </p>
          <p>
            Next we observe that the derivative of <m>f</m> has a geometric series expansion:
          </p>
          <me>
            f'(z) = \frac{1}{1 + z} = 1 - z + z^2 - z^3 + \cdots
          </me>
          <p>
            Integrating term by term gives a series expansion for <m>f</m>:
          </p>
          <md>
            <mrow> f(z) \amp = a_0 + z - \frac{z^2}{2} + \frac{z^3}{3} - \frac{z^4}{4} + \cdots </mrow>
            <mrow> \amp = a_0 + \sum_{n\ge 1} (-1)^{n+1} \frac{z^n}{n} </mrow>
          </md>
          <p>
            We finish the computation by observing that <m>f(0) = a_0 = \Log(1) = 0</m>.
          </p>
        </example>
        <example>
          <p>
            Consider the function <m>f(x) = \frac{1}{1 + x^2}</m>, a beautiful function of a real variable.
            It has a Taylor series expansion centered at any <m>a\in \R</m>, yet the radius of convergence
            of its series expansion at <m>a = 0</m> is <m>1</m>. Why?! There is no explanation of this
            in real calculus.
          </p>
          <p>
            (Just to refresh your memory:
            <me>
              \frac{1}{1+x^2} = \sum_{n\ge 0} (-x^2)^n = 1 - x^2 + x^4 - x^6 + \cdots
            </me>
            converges when <m>\abs{x^2} \lt 1</m>, i.e., <m>\abs{x} \lt 1</m>.)
          </p>
          <p>
            But now we see what's going on! As a function of a complex variable,
            this function has singularities at <m>\pm i</m>, and <m>1</m> is the distance from <m>0</m>
            to the nearest singularity.
          </p>
        </example>
      </section>
      <section xml:id="sec-zero-singularity">
        <title>Zeros and Singularities</title>
        <alert>Subsections:</alert>
        <list-of elements="subsection" divisions="section" empty="no" scope="section"/>
        <subsection xml:id="subsec-zeros">
          <title>Zeros of analytic functions</title>
        <proposition xml:id="prop-order-zero">
          <statement>
            <p>
              Suppose that <m>f</m> is analytic on a disk <m>B_r(z_0)</m> and is not identically <m>0</m> on that disk.
              Then there is a unique integer <m>k \ge 0</m>, called the <term>order of the zero</term> of <m>f</m> at <m>z_0</m>,
              such that <m>a_k \ne 0</m> and <m>f</m> has Taylor series around <m>z_0</m> given by
            </p>
            <me>
              f(z) = (z-z_0)^k (a_k + a_{k+1}(z-z_0) + \cdots) = (z-z_0)^k \sum_{n\ge k} a_n (z-z_0)^{n-k}.
            </me>
          </statement>
          <proof>
            <p>
              This is an immediately corollary to Taylor's Theorem:
              since <m>f</m> is not identically zero on <m>B_r(z_0)</m>, there is a first nonzero
              coefficient <m>a_k</m> in its power series expansion.
            </p>
          </proof>
        </proposition>
        <p>
          <alert>NB.</alert> We did not assume in the definition that <m>f(z_0) = 0</m>.
          If <m>f(z_0) \ne 0</m>, then <m>f</m> has a zero of order <m>0</m> at <m>z_0</m>.
        </p>
        <exercise>
          <p>
            Show how this generalizes the order of a zero of a polynomial from basic algebra.
            (E.g. the polynomial <m>(x-2)^3 (x + 5)</m> has a zero of order <m>3</m> at <m>x = 2</m>
            and a zero of order <m>1</m> at <m>x = -5</m>.)
          </p>
        </exercise>
        <theorem xml:id="thm-zeros-isolated">
          <title>The zeros of an analytic function are isolated</title>
          <statement>
            <p>
              If <m>f \colon B_r(z_0) \to \C</m> is analytic and not identically zero on <m>B_r(z_0)</m>,
              and <m>f(z_0) = 0</m>,
              then there is a small neighborhood of <m>z_0</m> in which <m>z_0</m> is the only zero of <m>f</m>.
            </p>
          </statement>
        </theorem>
        <proof>
          <p>
            As in <xref ref="prop-order-zero"/>, let <m>k</m> be the order of the zero of <m>f</m> at <m>z_0</m>,
            and let <m>g(z) = a_k + a_{k+1}(z-z_0) + \cdots</m> with <m>a_k \ne 0</m> be the function for which 
            <me>
              f(z) = (z-z_0)^k g(z).
            </me>
            Then <m>g(z_0) = a_k \ne 0</m>, so, since <m>g</m> is continuous on <m>B_r(z_0)</m> we can find a 
            small <m>\eps \gt 0</m> such that <m>g(z) \ne 0</m> for all <m>z \in B_\eps(z_0)</m>.
            On that small neighborhood we have <m>f(z) = (z-z_0)^k g(z) = 0</m> iff <m>z - z_0</m>.
          </p>
        </proof>
        <corollary xml:id="cor-identity-thm">
          <title>The Identity Theorem</title>
          <statement>
            <p>
              Suppose that <m>D\subseteq \C</m> is a domain and that <m>f</m> and <m>g</m> are two analytic functions
              <m>D \to \C</m>. Suppose further that the set <m>S = \set{z \in D}{f(z) = g(z)}</m> contains 
              a <em>non-isolated point</em>, that is, a <m>w\in S</m> such that for all <m>\eps \gt 0</m>
              we have <m>S \cap B_\eps(w) \ne \{w\}</m>.
              Then <m>f = g</m> on <m>D</m>.
            </p>
          </statement>
          <proof>
            <p>
              Look at the function <m>h(z) = f(z) - g(z)</m> on <m>D</m>.
              Then <m>h</m> has a nonisolated zero on <m>D</m>, so there is a small disk <m>B_\eps(w)</m>
              on which <m>h</m> is identically zero.
            </p>
            <p>
              Now we need a topological argument. Look at the following two sets.
            </p>
              <md>
                <mrow> U \amp = \set{ a \in D}{h \equiv 0 \text{ on some neighborhood } B_\eps(a) \text{ of } a \text{ in } D} </mrow>
                <mrow> V \amp = \set{ a \in D}{ \text{there is } n \ge 0 \text{ for which } h^{(n)}(a) \ne 0 }</mrow>
              </md>
            <p>
              Certainly <m>a \in U</m> implies <m>a \notin V</m>; i.e., <m>U \cap V \ne \emptyset</m>. 
              And <m>U \cup V = D</m> by Taylor's Theorem: expand around <m>a</m> and look at the Taylor coefficients.
              But <m>D</m> is (path-)connected, so either <m>U = \emptyset</m> or <m>V = \emptyset</m>.
              We have assumed that <m>w \in U</m>, so <m>V</m> must be empty. Thus <m>h</m> is identically zero
              on all of <m>D</m>.
            </p>
          </proof>
        </corollary>
        <definition xml:id="def-analytic-continuation">
          <statement>
            <p>
              Let <m>D_0 \subseteq D</m> be domains and <m>f_0\colon D_0 \to \C</m> analytic.
              An <term>analytic continuation</term> of <m>f_0</m> (to <m>D</m>) is an analytic function <m>f\colon D\to \C</m>
              that agrees with <m>f_0</m> on <m>D_0</m>: <m>f(z) = f_0(z)</m> for all <m>z\in D_0</m>.
            </p>
          </statement>
        </definition>
        <p>
          An analytic contination of <m>f_0</m> must be unique, if it exists.
        </p>
        <example>
          <p>
            Consider the function
            <me>
              f_0(z) = \sum_{n\ge 0} z^n = 1 + z + z^2 + \cdots
            </me>
            defined on <m>D_0 = B_1(0)</m>.
            This series diverges for <m>\abs{z} > 1</m>, but we know that 
            <m>f(z) = \frac{1}{1-z}</m> is an analytic continuation of <m>f_0</m> defined on <m>\C\wo\{1\}</m>.
          </p>
        </example>
      </subsection>
        <subsection xml:id="subsec-permanence-functional-equations">
          <title>The Principle of Permanence of Functional Equations</title>
          <p>
            This is more trouble than it's worth to state precisely, so we'll just give some examples
            as applications of the Identity Theorem.
          </p>
          <example>
            The equation <m>\sin^2(x) + \cos^2(x) = 1</m> holds for all real numbers <m>x</m>.
            This means that we can apply <xref ref="cor-identity-thm"/> to the functions <m>f(z) = sin^2(z) + \cos^2(z)</m>
            and <m>g(z) = 1</m> on <m>D = \C</m> to conclude that <m>sin^2(z) + \cos^2(z) = 1</m> for all <m>z \in \C</m>.
          </example>
          <example>
            <p>
              Consider the equation <m>e^{x+y} = e^x e^y</m>, which certainly holds for all real numbers <m>x,y</m>.
            </p>
            <p>
              The function <m>F(z,w) = e^{z+w} - e^z e^w</m> is entire in each variable (holding the other one fixed)
              and equals <m>0</m> for all <m>z,w\in \R</m>.
              Since <m>\R</m> has a non-isolated point, this implies by <xref ref="cor-identity-thm"/>
              that <m>F</m> is identically zero, i.e., <m>e^{z + w} = e^z e^w</m> for all <m>z,w\in\C</m>.
            </p>
          </example>
        </subsection>
        <subsection xml:id="subsec-singularities">
          <title>Singularities</title>
          <definition xml:id="def-singularity">
            <statement>
              <p>
                A function <m>f</m> is <term>singular</term> at <m>z_0</m> if <m>f</m> is not analytic at <m>z_0</m>.
                If <m>f</m> is singular at <m>z_0</m> but analytic on <m>\set{z }{ 0 \lt \abs{z-z_0} \lt r}</m>,
                then we say that <m>f</m> has an <term>isolated singularity</term> at <m>z_0</m>.
              </p>
            </statement>
          </definition>
          <example>
            <ol marker="(i)">
              <li>
                <p>
                  The function <m>\frac{z+1}{z^3(z^2+i)}</m> has isolated singularities at <m>0,\pm i</m>.
                </p>
              </li>
              <li>
                <p>
                  The function <m>e^{1/z}</m> has an isolated singularity at <m>z = 0</m>.
                </p>
              </li>
              <li>
                <p>
                  The principal branch <m>\Log(z)</m> of the log has a singularity at <m>z = 0</m>,
                  but it is not isolated because of the branch cut.
                </p>
              </li>
              <li>
                <p>
                  <m>\frac{1}{\sin(\pi/z)}</m> has singularities where <m>\sin(\pi/z) = 0</m>,
                  in particular at <m>z = 0</m> and at <m>z = 1/n</m> for <m>n\in\mathbb{Z}</m>.
                  The singularities at <m>1/n</m> are isolated, but the singularity at <m>0</m> is not.
                </p>
              </li>
            </ol>
          </example>
          <proposition xml:id="prop-removal-singularities">
            <title>Removal of singularities</title>
            <statement>
              <p>
                Suppose that <m>D</m> is a domain and <m>z_0 \in D</m>.
                If <m>f\colon D\wo \{z_0\} \to \C</m> is analytic and bounded near <m>z_0</m>,
                then <m>f</m> can be continuously extended to <m>D</m>,
                say <m>\lim\limits_{z \to z_0} f(z) = b</m>. In fact, if we define
                <me>
                  f^*(z) = \begin {cases} f(z) \amp \text{if } z \in D \wo \{z_0\} \\
                   b \amp \text{if } z = z_0 \end {cases},
                </me>
                then <m>f^*</m> is analytic on <m>D</m>.
              </p>
            </statement>
            <proof>
              <p>
                Define <m>h \colon D\to \C</m> as follows.
              </p>
              <me>
                h(z) = \begin {cases} (z- z_0)^2 f(z) \amp \text{if } z \ne z_0 \\
                  0 \amp \text{if } z = z_0
                  \end {cases}
              </me>
              <p>
                Our assumption is that there are <m>M</m> and <m>\eps</m> such that <m>\abs{f(z)} \lt M</m>
                for all <m>z \in B_\eps(z_0) \wo \{z_0\}</m>. Let's estimate the difference quotient of <m>h</m>
                near <m>z_0</m>:
              </p>
              <me>
                \abs{ \frac{h(z) - h(z_0)}{z - z_0}} = \frac{\abs{(z-z_0)^2 f(z)}}{\abs{z - z_0}} = \abs{z - z_0} \abs{f(z)}
                \le \abs{z - z_0} M,
              </me>
              <p>
                which tends to <m>0</m> as <m>z</m> tends to <m>z_0</m>.
                So <m>h</m> is differentiable at <m>z_0</m>, in addition to being differentiable near <m>z_0</m>.
                So by <xref ref="thm-taylor"/> <m>h</m> has a power series expansion in a neighborhood
                <m>B_\rho(z_0)</m> of <m>z_0</m>:
              </p>
              <me>
                h(z) = \sum_{n\ge 0} a_n (z - z_0)^n = a_0 + a_1(z - z_0) + a_2(z-a_0)^2 + \cdots
              </me>
              <p>
                We must have <m>a_0 = a_1 = 0</m>, so we can define
              <me>
                g(z) = \sum_{n\ge 0} a_{n+2} (z-z_0)^n = a_2 + a_3 (z-z_0) + a_4 (z - z_0)^2 + \cdots
              </me>
              We have <m>g(z) = \frac{h(z)}{(z-z_0)^2} = f(z)</m> for <m>z \in B_\rho(z_0)\wo \{z_0\}</m>.
              And <m>g(z) \to a_2</m> as <m>z \to z_0</m>, so <m>f(z) \to a_2</m> as <m>z \to z_0</m>.
            </p>
            </proof>
          </proposition>
          <p>
            The moral of <xref ref="prop-removal-singularities"/> is that the only way a function can fail to be
            analytic is because it blows up, not because of some weird (real-analysis-like) failure of continuity.
          </p>
          <p>
            A function like <m>\frac{e^z}{(z-\pi)^5}</m> has a singularity at <m>z = \pi</m>,
            and there should be some sense in which the singularity has <q>order</q> <m>5</m>.
            The next proposition makes that precise.
          </p>
          <proposition xml:id="prop-poles-exist">
            <statement>
              <p>
                Suppose that <m>D</m> is a domain, <m>z_0 \in D</m>, and 
                <m>f\colon D \wo \{z_0\} \to \C</m> is analytic.
                Suppose also that <m>\abs{f(z)} \to \infty</m> as <m>z\to z_0</m>.
                Then there are (unique) <m>k\in \{1,2,3,\dots\}</m> and (unique)
                analytic <m>g\colon D \to \C</m> for which <m>g(z_0) \ne 0</m>
                and <m>f(z) = \frac{g(z)}{(z-z_0)^k}</m>.
              </p>
              <p>
                In this case we say that <m>f</m> has a <term>pole of order</term> <m>k</m> at <m>z_0</m>.
              </p>
            </statement>
            <proof>
              <p>
                We begin by constructing <m>g</m> in a small neighborhood of <m>z_0</m>.
                By our assumption, there is a <m>\delta \gt 0</m> such that <m>\abs{f(z)}\ge 1</m>
                for all <m>z\in B_\delta(z_0) \wo \{z_0\}</m>.
                In particular, <m>f</m> is nonzero on <m>z\in B_\delta(z_0) \wo \{z_0\}</m>.
                Define <m>h\colon B_\delta(z_0) \wo \{z_0\}</m> as follows.
              </p>
              <me>
                h(z) = \begin {cases} \frac{1}{f(z)} \amp \text{if } z \in B_{\delta}(z_0)\wo\{z_0\} \\
                0 \amp \text{if } z = z_0
                \end {cases}
              </me>
              <p>
                Then, since <m>\abs{f(z)} \to \infty</m> as <m>z\to z_0</m>, this new function <m>h</m>
                is continuous on <m>B_\delta(z_0)</m> (notice that <m>h</m> is defined there, since <m>f</m>
                is nonzero) and therefore analytic on <m>B_\delta(z_0)</m> 
                by <xref ref="prop-removal-singularities">Removal of Singularities</xref>.
              </p>
              <p>
                Since <m>h(z_0) = 0</m> but <m>h</m> is not identically <m>0</m> on <m>B_\delta(z_0)</m>,
                this zero must (by <xref ref="prop-order-zero"/>) have an order:
                there must be <m>k\in \{1,2,3,\dots\}</m> and an analytic function <m>l \colon B_\delta(z_0) \to \C</m>
                for which <m>l(z_0) \ne 0</m>.
                By the continuity of <m>l</m>, there is <m>\eps \in (0,\delta)</m> such that <m>l(z) \ne 0</m>
                for all <m>z\in B_\eps(z_0)</m>.
                Define <m>g\colon B_\eps(z_0) \to \C</m> by <m>g(z) = \frac{1}{l(z)}</m>.
                So <m>g</m> is analytic on <m>B_\eps(z_0)</m> and satisfies the following equation
                for all <m>z\in B_\eps(z_0)</m>.
              </p>
              <men xml:id="eqn-poles-prop">
                g(z) = \frac{1}{l(z)} = \frac{1}{h(z)} \cdot (z - z_0)^k = (z-z_0)^k f(z).
              </men>
              <p>
                But now we can observe that <xref ref="eqn-poles-prop"/> makes sense for all <m>z\in D</m>, 
                so <m>g</m> has an analytic continuation to all of <m>D</m>.
                So we have found our order <m>k</m> and function <m>g</m>.
              </p>
            </proof>
          </proposition>
          <definition xml:id="def-singularity-types">
            <statement>
              <p>
                A isolated singularity of <m>f</m> at <m>z_0</m> is ...
              </p>
                <ul>
                  <li>
                    <p>
                      <term>removable</term> if <m>f</m> is bounded
                      near <m>z_0</m> (as in <xref ref="prop-removal-singularities"/>);
                    </p>
                  </li>
                  <li>
                    <p>
                      a <term>pole</term> (of order <m>k</m>) if it
                satisfies the hypotheses of <xref ref="prop-poles-exist"/>;
                    </p>
                  </li>
                  <li>
                    <p>
                      an <term>isolated essential singularity</term> if it is an isolated singularity
                      that is neither removable nor a pole.
                    </p>
                  </li>
                </ul>
            </statement>
          </definition>
          <example>
            The function <m>z\mapsto e^{1/z}</m> has an isolated essential singularity at <m>z = 0</m>, 
            as we will see.
          </example>
          <exercise>
            <p>
              Suppose that <m>f</m>  has a zero of order <m>m</m> at <m>a</m> and <m>g</m> has a zero of 
              order <m>n</m> at <m>a</m>. Then <m>\frac{f(z)}{g(z)}</m> has a <q>pole of order <m>n-m</m>
              at <m>a</m></q>, by which we mean:
            </p>
            <ul>
              <li>
                <p>
                  If <m>n \gt m</m> then <m>f/g</m> has a pole of order <m>n-m</m> at <m>a</m>;
                </p>
              </li>
              <li>
                <p>
                  If <m>n \lt m</m> then <m>f/g</m> has a zero of order <m>m-n</m> at <m>a</m>;
                </p>
              </li>
              <li>
                <p>
                  If <m>m = n</m> then <m>f/g</m> is nonzero and analytic at <m>a</m>.
                </p>
              </li>
            </ul>
          </exercise>
          <solution>
            <mdn>
              <mrow number="no"> \frac{f(z)}{g(z)} \amp = \frac{c_m (z-a)^m + c_{m+1}(z-a)^{m+1} + \cdots}{d_n (z-a)^n + d_{n+1}(z-a)^{n+1} + \cdots}</mrow>
              <mrow number="no"> \amp = \frac{1}{(z-a)^{n-m}} \left( \frac{c_m(z-a)^m + c_{m+1}(z-a)^{m+1} + \cdots}{d_n (z-a)^m + d_{n+1}(z-a)^{m+1} + \cdots} \right)</mrow>
              <mrow xml:id="eqn-poles"> \amp = \frac{1}{(z-a)^{n-m}} \left( \frac{c_m + c_{m+1}(z-a) + \cdots}{d_n + d_{n+1}(z-a) + \cdots} \right)</mrow>
            </mdn>
            <p>
              Notice that 
              <me>
                \frac{1}{(z-a)^{n-m}} = \begin {cases} \frac{1}{(z-a)^{n-m}} \amp \text{if } m \lt n \\
              (z-a)^{m-n} \amp \text{if } m \gt n \end {cases},
              </me>
              and that the second factor of <xref ref="eqn-poles"/> is nonzero at <m>z=a</m>.
            </p>
          </solution>
        </subsection>
      </section>
      <section xml:id="sec-laurent-series">
        <title>Laurent series</title>
        <p>
          An analytic function has a Taylor series in a neighborhood of a non-singularity;
          what about a neighborhood of a singularity?
        </p>
        <theorem xml:id="thm-laurent">
          <title>Laurent's Theorem</title>
          <statement>
            <p>
              Suppose that <m>0 \le r \lt R \lt \infty</m> and consider the annulus 
              <m>A = \set{ z\in \C }{ r \lt \abs{z - a} \lt R }</m>.
              Suppose that <m>f\colon A \to \C</m> is analytic. Then <m>f</m> has a (unique) convergent
              series (its <term>Laurent expansion</term>)
            <me>
              f(z) = \sum_{-\infty \lt n \lt \infty} c_n (z-a)^n
              = \cdots \frac{c_{-2}}{(z-a)^2} + \frac{c_{-1}}{z-a} + c_0 + c_1(z-a) + \cdots
            </me>
              that converges for <m>z \in A</m>.
            </p>
            <p>
              The coefficients <m>c_n</m> can be computed for <m>\rho \in (r,R)</m> by the following formula.
            </p>
            <me>
              c_n = \frac{1}{2\pi i} \oint_{\abs{z - a} = \rho} \frac{f(z)}{(z-a)^{n+1}}\,dz
            </me>
          </statement>
        </theorem>
        <p>
          In the case <m>r = 0</m> (a particularly important one), there are three cases:
        </p>
        <ol>
          <li>
            <p>
              <alert>Case 1:</alert> All the negative coefficients are zero: <m>0 = c_{-1} = c_{-2} = \cdots</m>.
              Then <m>f</m> is bounded near <m>a</m> and therefore has a removable singularity there.
            </p>
          </li>
          <li>
            <p>
              <alert>Case 2:</alert> Only finitely many negative coefficients are nonzero:
              <me>
                f(z) = \frac{c_{-k}}{(z-a)^k} + \cdots + \frac{c_{-1}}{z-a} + c_0 + \cdots
              </me>
              Then <m>f</m> has a pole of order <m>k</m> at <m>a</m>.
              (We see this by writing <m>f(z) = \frac{1}{(z-a)^k}(c_{-k} + c_{-k+1}(z-a) + \cdots)</m>.)
            </p>
          </li>
          <li>
            <p>
              <alert>Case 3:</alert> Infinitely many of the negative coefficients are nonzero.
              In this case, <m>f</m> has an isolated essential singularity. 
            </p>
          </li>
        </ol>
        <remark>
          <p>
            In <xref ref="thm-laurent"/>, the Laurent series can be decomposed into an 
            <term>analytic part</term> <m>\sum_{n\ge 0} c_n (z-a)^n</m>, which converges to an analytic
            function on <m>\abs{z-a} \lt R</m>,
            and a <term>singular part</term> <m>\sum_{k\ge 0} \frac{c_{-k}}{(z-a)^k}</m>, which
            converges to an analytic function on <m>\abs{z-a} \gt r</m>.
            Their sum is <m>f</m>, which is analytic on the common region of convergence of the two
            series, i.e., <m>r \lt \abs{z-a} \lt R</m>.
          </p>
        </remark>
        <!--https://www.geogebra.org/calculator/cdeeqmhd-->
        <figure xml:id="fig-geogebra-laurent-parts">
        <caption>GeoGebra: Laurent parts</caption>
        <interactive xml:id="geogebra-laurent-parts" platform="geogebra" width="80%" aspect="1:1">
            <slate xml:id="laurent-parts" surface="geogebra" material="cdeeqmhd" aspect="1:1">
              setCoordSystem(-7,7,-7,7);
              <!-- centerView((0,0)); -->
              <!--enableShiftDragZoom(false);-->
            </slate>
          <instructions>
            <p> 
             You can view a larger version of this <url href="https://www.geogebra.org/calculator/cdeeqmhd">here</url>.
            </p>
          </instructions>
        </interactive>
        </figure>
        <example>
              <p>
                The function <m>f(z) = \frac{z+1}{z}</m> has Laurent series <m>1 + \frac{1}{z}</m> that converges
                on <m>0 \lt \abs{z} \lt \infty</m>.
              </p>
        </example>
        <example>
          <p>
            We can find the Laurent series of the function <m>\frac{z}{z^2 + 1}</m> using partial fractions:
          </p>
          <me>
            f(z) = \frac{1}{2} \cdot \frac{1}{z-i} + \frac{1}{2} \cdot \frac{1}{z+i}
          </me>
          <p>
            Note that <m>\frac{1}{z+i}</m> is analytic at <m>z=i</m> and has Taylor series expansion
            that can be found using geometric series:
          </p>
          <me>
            \frac{1}{z+i} = \frac{1}{2i} \frac{1}{1 + \frac{z-i}{2i}} = \frac{1}{2i} \sum_{n\ge 0} \left(- \frac{z-i}{2i}\right)^n
          </me>
          <p>
            The Laurent series is 
          <me>
            f(z) = \frac12 \cdot \frac{1}{z-i} + \frac{1}{4i} \sum_{n\ge 0} \left( - \frac{z-i}{2i} \right)^n
          </me>
          and converges for <m>0 \lt \abs{z-i} \lt 2</m>.
         </p>
         <p>
          (Ooh, but what if we'd considered the function on the annulus <m>0 \lt \abs{z-i} \lt \infty</m> instead? Stay tuned!)
         </p>
        </example>
        <example>
          <p>
            Find the Laurent series for <m>f(z) = \frac{z+1}{z^3(z^2+1)}</m> on <m>A = \set{ z\in \C }{\abs{z}\in (0,1)}</m>.
          </p>
          <p>
            Notice that <m>f</m> has isolated singularities at <m>0</m> and <m>\pi i</m>. It is analytic on <m>A</m>.
            Here is the Laurent series:
          </p>
          <me>
            f(z) = \frac{1}{z^3} (1+z) (1 - z^2 + z^4 - z^6 + \cdots)
            = \frac{1}{z^3} + \frac{1}{z^2} - \frac{1}{z} - 1 + z - z^2 - z^3 + \cdots
          </me>
        </example>
        <example>
          <p>
            <alert>NB.</alert> The Laurent series can depend on the region!
          </p>
          <p>
            Find the Laurent series for <m>f(z) = \frac{1}{z(z-1)}</m> around <m>a = 0</m> for
            <ol marker="(a)">
              <li>
                <p>
                  <m>A = \set{ z\in \C }{ \abs{z} \in (0,1) }</m>
                </p>
              </li>
              <li>
                <p>
                  <m>A = \set{ z\in \C }{ \abs{z} \in (1,\infty)}</m>
                </p>
              </li>
            </ol>
          </p>
          <p>
            For the first part:
          </p>
          <me>
            f(z) = \frac{-1}{z} \cdot \frac{1}{1-z} = \frac{-1}{z} (1 + z + z^2 + \cdots)
            = \frac{-1}{z} - 1 - z - z^2 - \cdots
          </me>
          <p>
            For the second part, notice that <m>\frac{1}{1-z}</m> is not convergent on <m>A</m>,
            so we use an algebraic trick using the fact that <m>\abs{1/z} \lt 1</m> on this <m>A</m>:
          </p>
          <me>
            f(z) = \frac{1}{z} \cdot \frac{1}{z(1-1/z)} = \frac{1}{z^2}\left( 1 + \frac{1}{z} + \frac{1}{z^2} + \cdots \right)
          </me>
        </example>
        <proof>
          <title>Proof of <xref ref="thm-laurent"/></title>
          <figure width="50%" xml:id="fig-laurents-thm">
          <image source="laurents-thm" width="50%">
            <description>Picture of curve for the proof of Laurent's Theorem.</description>
          </image>
          <caption>Picture of curve for the proof of Laurent's Theorem.</caption>
         </figure>
          <p>
            Fix <m>z\in A</m>. Find circles <m>C_1</m> and <m>C_3</m> so that <m>z</m> lies in the smaller
            slit annulus <m>C_1 + C_2 - C_3 - C_2</m>, as shown in the figure (TO BE ADDED).
            Then Cauchy's Integral Formula applies to <m>z</m> and the closed curve <m>C_1 + C_2 - C_3 - C_2</m>
            that encircles it:
          </p>
          <md>
            <mrow> f(z) \amp = \frac{1}{2\pi i} \oint_{C_1 + C_2 - C_3 - C_2} \frac{f(w)}{w - z} \, dw </mrow>
            <mrow> \amp = \frac{1}{2\pi i} \oint_{C_1 - C_3} \frac{f(w)}{w - z}\,dw  </mrow>
            <mrow> \amp = \frac{1}{2\pi i} \oint_{C_1} \frac{f(w)}{w - z}\,dw - \frac{1}{2\pi i} \oint_{C_3} \frac{f(w)}{w-z}\,dw </mrow>
          </md>          
          <p>
            As in the proof of the Cauchy Integral Formula, we manipulate to get a geometric series:
          </p>
          <men xml:id="eqn-laurent-1">
            \frac{f(w)}{w-z} = \frac{f(w)}{w-a} \cdot \frac{1}{1- \frac{z-a}{w-a}} = \sum_{n\ge 0} \frac{f(w) (z-a)^n}{(w-a)^{n+1}}
          </men>
          <p>
            holds for <m>\abs{z - a} \lt \abs{w-a}</m>, e.g. on <m>C_1</m>. And:
          </p>
          <men xml:id="eqn-laurent-2">
            \frac{f(w)}{w-z} = \frac{-f(w)}{z-w} = - \frac{f(w)}{z-a} \cdot \frac{1}{1 - \frac{w-a}{z-a}}
            = - \sum_{n\ge 0} \frac{f(w)(w-a)^{n}}{(z-a)^{n+1}}
          </men>
          <p>
            holds for <m>\abs{w-a} \lt \abs{z-a}</m>, e.g. on <m>C_3</m>.
          </p>
          <p>
            Put all this together:
          </p>
          <mdn>
            <mrow number="no"> \frac{1}{2\pi i} \oint_{C_1} \frac{f(w)}{w-z}\,dw \amp = \frac{1}{2\pi i} \oint_{C_1} \sum_{n\ge 0} \frac{f(w)(z-a)^n}{(w-a)^{n+1}}\, dw </mrow>
            <mrow number="no"> \amp = \sum_{n\ge 0} \frac{1}{2\pi i} \left( \oint_{C_1} \frac{f(w)}{(w-a)^{n+1}}\,dw \right) (z-a)^n </mrow>
            <mrow xml:id="eqn-laurent-3"> \amp = \sum_{n\ge 0} c_n (z-a)^n </mrow>
          </mdn>
          <mdn>
            <mrow number="no"> - \frac{1}{2\pi i} \oint_{C_3} \frac{f(w)}{w-z}\,dw \amp = \frac{1}{2\pi i} \oint_{C_3} \sum_{n\ge 0} \frac{f(w)(w-a)^n}{(z-a)^{n+1}}\, dw</mrow>
            <mrow number="no"> \amp = \sum_{n\ge 0} \frac{1}{2\pi i} \left( \oint_{C_3} f(w)(w-a)^n\,dw \right) \frac{1}{(z-a)^{n+1}}</mrow>
            <mrow xml:id="eqn-laurent-4"> \amp = \sum_{n\ge 0} \frac{c_n}{(z-a)^{n+1}} </mrow>
          </mdn>
          <p>
            The sum, <m>f(z)</m> is <xref ref="eqn-laurent-3"/> <m>+</m> <xref ref="eqn-laurent-4"/>.
          </p>
          <p>
            Notice that the sum in <xref ref="eqn-laurent-3"/> converges for <m>\abs{z-a} \lt R</m>,
            and the sum in <xref ref="eqn-laurent-4"/> converges for <m>r \lt \abs{z-a}</m>.
          </p>
        </proof>
      </section>
        </chapter>
    <chapter xml:id="ch-residue">
      <title>The Residue Calculus</title>
      <section xml:id="sec-residues">
        <title>Residues</title>
        <p>
          If <m>f(z)</m> has an isolated singularity at <m>z = 0</m> and its Laurent series on <m>0 \lt \abs{z} \lt r</m>
          is given by
          <me>
            f(z) = \cdots + \frac{c_{-2}}{z^2} + \frac{c_{-1}}{z} + c_0 + c_1 z + c_2 z^2 + \cdots
          </me>
          then what is <m>\oint_\gamma f(z)\,dz</m> around a small simple closed curve encircling <m>0</m>?
        </p>
        <p>
          Integrate the Laurent series termwise:
        </p>
        <me>
          \oint_\gamma f(z)\,dz = \sum_{n=2}^\infty \oint_\gamma \frac{c_{-n}}{z^n} \, dz + \oint_\gamma \frac{c_{-1}}{z}\,dz + \sum_{n=0}^\infty c_n z^n \,dz
        </me>
        <p>
          The only term in this sum that survives integration is the one involving <m>c_{-1}</m>.
          (Notice that e.g. <m>\oint_\gamma \frac{c_{-2}}{z^2}\,dz = 2\pi i \left[ \frac{d}{dz} c_{-2} \right]_{z = 0} = 0</m>.)
          So <m>\oint_\gamma f(z)\,dz = 2\pi i c_{-1}</m>.
        </p>
        <definition xml:id="def-residue">
          <statement>
            <p>
              When <m>f</m> has an isolated singularity at <m>z = a</m>, then the <term>residue</term> of <m>f</m> 
              at <m>a</m> is defined to be <m>c_{-1}</m>, the coefficient of <m>\frac{1}{z-a}</m> in the Laurent series
              of <m>f</m> defined on <m>B_\eps(a)\wo\{a\}</m>. The residue is denoted
              <me>
                \Res_{z=a} f(z) = c_{-1}.
              </me>
            </p>
          </statement>
        </definition>
        <p>
          Note that the residue of <m>f</m> at <m>a</m> could alternatively be defined by
        <me>
          \Res_{z=a}f(z) = \frac{1}{2\pi i} \oint\limits_{\abs{z-a} = \eps} f(z)\,dz.
        </me>
        </p>
        <example>
          <p>
            The function <m>f(z) = \frac{1}{z^3} + \frac{2}{z^2} + \frac{4}{z} + 5 + 6z</m>
            has a pole of order <m>3</m> at <m>z = 0</m> and <m>\Res\limits_{z=0} f(z) = 4</m>.
          </p>
        </example>
        <example>
          <p>
            Suppose that <m>f(z) = \frac{2}{z} + g(z)</m> where <m>g</m> is any function analytic at <m>z = 0</m>.
            Then <m>f</m> has a simple pole at <m>z = 0</m> and <m>\Res\limits_{z = 0} f(z) = 2</m>.
          </p>
        </example>
        <example>
          <p>The function <m>f(z) = \cos(z) = 1 - \frac{z^2}{2!} + \frac{z^4}{4!} + \cdots</m>
          is analytic at <m>z = 0</m> with <m>\Res\limits_{z=0} \cos(z) = 0</m>.</p>
        </example>
        <example>
          <p>
            The function 
            <me>
              f(z) = \frac{\sin(z)}{z} = \frac{1}{z}\left( z - \frac{z^3}{3!} + \frac{z^5}{5!} - \cdots \right)
              = 1 - \frac{z^2}{3!} + \cdots
            </me>
            has a removable singularity at <m>z = 0</m> and <m>\Res\limits_{z=0} f(z) = 0</m>.
          </p>
        </example>
        <example>
        <statement>
          <p>
            Consider <m>f(z) = \frac{z}{z^2 + 1}</m>. Find all poles and residues of the poles.
          </p>
        </statement>
        <solution>
          <p>
            Expand <m>f</m> by partial fractions:
          </p>
          <me>
            f(z) = \frac{z}{(z+i)(z-i)} = \frac{1/2}{z-i} + \frac{1/2}{z+i}.
          </me>
          <p>
            Now around <m>z = i</m> we have
           <me>
             f(z) = \frac{1}{2} \cdot \frac{1}{z-i} + (\text{something analytic at } z=i),
           </me>
            so <m>f</m> has a simple pole at <m>z = i</m> with <m>\Res\limits_{z=i}f(z) = 1/2</m>.
          </p>
          <p>
            The calculation at <m>z = -i</m> is similiar. There is a simple pole at which the residue
            is <m>1/2</m>.
          </p>
        </solution>
        </example>
        <example>
        <statement>
          <p>
            Find the Laurent series of <m>f(z) = \frac{1}{z(z-1)}</m> on 
          </p>
          <ol marker="(a)">
           <li><m>0 \lt \abs{z} \lt 1</m> </li>
           <li><m>1 \lt \abs{z} \lt \infty </m> </li>
          </ol>
          <p>
            Then find the residue at <m>z = 0</m>.
          </p>
          </statement>
          <solution>
          <p>
            On the annulus defined by <m>0 \lt \abs{z} \lt 1</m>, we have the following expression for <m>f(z)</m>.
            <men xml:id="eqn-residue-example">
              f(z) = -\frac{1}{z} \cdot \frac{1}{1-z} = -\frac{1}{z}(1 + z + z^2 + \cdots)
            </men>
          </p>
          <p>
            On the annulus defined by <m>1 \lt \abs{z} \lt \infty</m>, we have the following expression for <m>f(z)</m>.
          </p>
          <me>
            f(z) = \frac{1}{z^2} \cdot \frac{1}{1 - \frac{1}{z}} = \frac{1}{z^2}\left( 1 + \frac{1}{z} + \frac{1}{z^2} + \cdots \right)
          </me>
          <p>
            <alert>Warning:</alert> We must use <xref ref="eqn-residue-example"/> to find the residue!
            The function <m>f</m> has a simple pole at <m>z=0</m> with <m>\Res\limits_{z=0} f(z) = -1</m>.
          </p>
        </solution>
        </example>
        
        <example>
          <p>
            Consider the function <m>f(z) = \Log(1+z)</m>. It has a singularity at <m>z=-1</m> but it isn't isolated.
            Not a pole so no residue.
          </p>
        </example>

        <theorem xml:id="thm-residue">
          <title>The Residue Theorem</title>
          <statement>
            <p>
              Suppose that <m>f</m> is analytic except at a set of isolated singularities.
              Suppose that <m>\gamma</m> is a counterclockwise-oriented curve that does
              not go through any of the singularities of <m>f</m>. Then
              <me>
                \oint_\gamma f(z)\,dz = 2\pi i \sum \Res\limits_{z = a} f(z),
              </me>
              where the sum is taken over all singularities <m>a</m> of <m>f</m> inside <m>\gamma</m>.
            </p>
          </statement>
          <proof>
            <p>
              We will do the case where <m>\gamma</m> encircles two
              singularities of <m>f</m>, at <m>a</m> and <m>b</m>.
              Let <m>C_3</m> be a tiny circle around <m>a</m>,
              <m>C_6</m> be a tiny circle around <m>b</m>,
              and connect <m>C_6</m> and <m>C_3</m> as in the figure.
              By Cauchy's Theorem, the function integrates to <m>0</m>
              over the big curve:
            </p>
            <me>
              \oint\limits_{C_1 + C_2 - C_3 - C_2 + C_4 + C_5 - C_6 - C_5}
              f(z)\,dz = 0 = \oint_{C_1 + C_4} f(z)\,dz + \oint_{-C_3 - C_6}f(z)\,dz
            </me>
            <p>
              So the integral reduces to the sum of integrals over <m>C_3</m> and <m>C_6</m>,
              each of which can be computed as <m>2\pi i</m> times the residue:
            </p>
            <md>
              <mrow> \oint_\gamma f(z)\,dz \amp = \oint_{C_3 + C_6} f(z)\,dz </mrow>
              <mrow> \amp = \oint_{C_3} f(z)\,dz + \oint_{C_6}f(z)\,dz </mrow>
              <mrow> \amp = 2\pi i \Res\limits_{z = b} f(z) + 2\pi i \Res\limits_{z = a} f(z) </mrow>
              <mrow> \amp = 2\pi i\left( \Res\limits_{z = b} f(z) + \Res\limits_{z = a} f(z)\right) </mrow>
            </md>
            <p>
              The proof of the general case (with more than two singularities inside <m>\gamma</m>)
              is similar.
            </p>
          </proof>
        </theorem>
        <figure xml:id="fig-residue-thm">
          <caption>Picture of so-called keyhole contours for the proof of <xref ref="thm-residue"/>.</caption>
          <image source="residue-thm" width="70%">
            <description>Picture of keyhole contours for the proof of the Residue Theorem.</description>
          </image>
        </figure>
        <figure xml:id="fig-residue-example">
        <caption>Circles for the Example.</caption>
          <image width="60%" xml:id="image-residue-example">
          <description>Curves for the Example.</description>
            <latex-image>
                \begin {tikzpicture}	[scale = 2, outer sep = 0.5ex]
                \draw [draw=none] (0,0.7) circle (2.1) ;
               \draw [black, thick, -latex] (0,-2) to (0,3) ;
              \draw [black, thick, -latex] (-2,0) to (2,0) ;
              \fill [black] (0,1) circle (1pt) node [left] {$i$};
              \fill [black] (0,-1) circle (1pt) node [left] {$-i$} ;
              \fill [black] (0,0) circle (1pt) ;
              \draw [blue!50!black, thick] (0.5,1.5) circle (0.4) ;
              \draw [red!50!black, thick] (0.3,1.3) circle (1) ;
              \draw [green!40!black, thick] (0.2,1) circle (1.5) ;
              \draw [yellow!40!red, thick] (0,0.7) circle (2) ;
              \node [blue!50!black] at (0.5,1.25) {$C_1$} ;
              \node [red!50!black] at (0.4,0.5) {$C_2$} ;
              \node [green!40!black] at (0.4,-0.3) {$C_3$} ;
              \node [yellow!40!red] at (0.4,-1.1) {$C_4$} ;
              \end {tikzpicture}
            </latex-image>
            </image>
            </figure>
        <example>
          <statement>
            <p>
              Let <m>f(z) = \frac{1}{z(z^2 + 1)}</m>.
              Compute <m>\oint f(z)\,dz</m> over <m>C_1,C_2,C_3,</m> and <m>C_4</m>, as in the figure.
            </p>
          </statement>
          <solution>
            <p>
              The poles of <m>f</m> occur at <m>z = 0,\pm i</m>.
              In light of the Residue Theorem, we just need to compute
              the residues at each of these poles.
              We are about to devote a section to computing residues
              like this, but for the impatient reader here are the answers:
            </p>
            <md>
              <mrow> \oint_{C_1} f(z)\,dz \amp = 0 \text{ (doesn't encircle any singularities)} </mrow>
              <mrow> \oint_{C_2} f(z)\,dz \amp = 2\pi i \Res\limits_{z = i}f(z) = -\pi i </mrow>
              <mrow> \oint_{C_3} f(z)\,dz \amp = 2\pi i (\Res\limits_{z = i}f(z) + \Res\limits_{z = 0}f(z)) = 2\pi i(-\frac12 + 1) </mrow>
              <mrow> \oint_{C_4} f(z)\,dz \amp = 2\pi i(\Res\limits_{z=i}f(z) + \Res\limits_{z = 0}f(z) + \Res\limits_{z = -i}f(z)) = 2\pi i(-\tfrac12 + 1 + -\tfrac12) = 0 </mrow>
            </md>
          </solution>
        </example>
        <subsection xml:id="subsec-residues-simple-poles">
          <title>Computing Residues at Simple Poles</title>
          <p>
            Recall that a <term>simple pole</term> is a pole of order <m>1</m>.
            We devote some effort toward understanding how to compute residues at simple poles.
          </p>
          <proposition xml:id="prop-residues-simple-poles-basic">
            <title>Basic properties of residues at simple poles</title>
            <statement>
              <ol marker="(a)">
                <li>
                  <p>
                    If the Laurent series of <m>f</m> near <m>a</m> takes the form 
                    <me>
                      \frac{c_{-1}}{z-a} + c_0 + c_1(z-a) + \cdots,
                    </me>
                    then <m>f</m> has a simple pole at <m>z = a</m>
                    and <m>\Res\limits_{z=a}f(z) =  c_{-1}</m>.
                  </p>
                </li>
                <li>
                  <p>
                    If <m>g(z) = (z-a)f(z)</m> is analytic at <m>a</m>,
                    then <m>f</m> has either a removable singularity or a simple
                    pole at <m>z = a</m>. In either case,
                    <m>\Res\limits_{z=a}f(z) = g(a)</m> (<m>=0</m> if <m>f</m> has a removable singularity).
                  </p>
                </li>
                <li>
                  <p>
                    If <m>f</m> has a simple pole at <m>a</m> then
                    <me>
                      \lim_{z\to a} (z-a)f(z) = \Res\limits_{z=a}f(z).
                    </me>
                    (That is, the limit exists and equals the residue.
                    The converse is also true: if the limit exists then <m>f</m> either has a simple pole at <m>a</m> or is analytic at <m>a</m>.)
                  </p>
                </li>
                <li>
                  <p>
                    If <m>f</m> has a simple pole at <m>a</m> and <m>g</m> is analytic at <m>a</m>,
                    then
                    <me>
                      \Res\limits_{z=a} f(z) g(z) = g(a) \Res\limits_{z=a} f(z).
                    </me>
                    If <m>g(a) \ne 0</m> then also
                    <me>
                      \Res\limits_{z=a} \frac{f(z)}{g(z)} = \frac{1}{g(a)} \Res_{z=a} f(z).
                    </me>
                  </p>
                </li>
                <li>
                  <p>
                    If <m>g</m> has a simple zero at <m>a</m> then <m>1/g</m> has a simple pole at <m>a</m> and
                    <me>
                      \Res_{z=a} \frac{1}{g(z)} = \frac{1}{g'(a)}.
                    </me>
                  </p>
                </li>
              </ol>
            </statement>
          </proposition>
          <example>
            <statement>
              <p>
                Consider the following function.
                <me>
                  f(z) = \frac{2 + z + z^2}{(z-2)(z-3)(z-4)(z-5)}.
                </me>
                Show that all the poles are simple and compute their residues.
              </p>
            </statement>
            <hint>
              <p>
                The poles occur at <m>z = 2,3,4,5</m>.
                For <m>z = 2</m>, multiply by <m>z-2</m> to get
                <me>
                  g(z) = (z-2)f(z) = \frac{2+z+z^2}{(z-3)(z-4)(z-5)}.
                </me>
                This function is analytic at <m>z = 2</m> and satisfies
                <m>g(2) = -4/3</m>, so the pole at <m>z=2</m> is simple and the residue there is
                <m>-4/3</m>.
                The others are similar.
              </p>
            </hint>
          </example>
          <example>
            <statement>
              <p>
                Consider the function <m>f(z) = \csc(z) = \frac{1}{\sin(z)}</m>.
                Find all its poles and compute its residue at each pole.
              </p>
            </statement>
            <solution>
              <p>
                As we've seen before, the complex zeros of sine occur at <m>n\pi</m> for <m>n</m> an integer.
                Since the derivative <m>\sin'(n\pi) = \cos(n\pi)</m> is nonzero at each pole,
                the zeros of sine are simple. So, by the Proposition,
                <me>\Res\limits_{z=n\pi} f(z) = \frac{1}{\cos(n\pi)} = (-1)^n</me>.
              </p>
            </solution>
          </example>
        </subsection>
      </section>

    </chapter>
    <backmatter xml:id="backmatter">
      <title>Backmatter</title>

      <colophon>
        <p> This book was authored in <pretext />. </p>
      </colophon>

    </backmatter>

  </book>
</pretext>
